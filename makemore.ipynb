{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt').read().splitlines()\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e m\n",
      "m m\n",
      "m a\n"
     ]
    }
   ],
   "source": [
    "for word in words[:1]:\n",
    "    for char, char1 in zip(word, word[1:]):\n",
    "        print(char, char1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(letters)}\n",
    "stoi['.'] = 0\n",
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 0: '.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = torch.zeros((27,27), dtype=torch.int64)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "for word in words:\n",
    "    w_start_end = '.' + word + '.'\n",
    "    for char, char1 in zip(w_start_end, w_start_end[1:]):\n",
    "        counts[(char, char1)] = counts.get((char, char1), 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 556, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "         1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "          134,  535,  929],\n",
       "        [6640,  556,  541,  470, 1042,  692,  134,  168, 2332, 1650,  175,  568,\n",
       "         2528, 1634, 5438,   63,   82,   60, 3264, 1118,  687,  381,  834,  161,\n",
       "          182, 2050,  435],\n",
       "        [ 114,  321,   38,    1,   65,  655,    2,  664,   41,  217,    1,  116,\n",
       "          103,    0,    4,  105,   11,   76,  842,    8,    2,   45,    0,    3,\n",
       "          104,   83,    0],\n",
       "        [  97,  815,    3,   42,    1,  551,   25,    2,  664,  271,    3,  316,\n",
       "          116,   31,  378,  380,    1,   11,   76,    5,   35,   35,   23,    0,\n",
       "            3,  104,    4],\n",
       "        [ 516, 1303,    1,    3,  149, 1283,    5,   25,  118,  674,    9,    3,\n",
       "           60,   30,   31,  378,   14,    1,  424,   29,    4,   92,   17,   23,\n",
       "         1070,  317,    1],\n",
       "        [3983,  679,  121,  153,  384, 1271,   82,  125,  152,  818,   55,  178,\n",
       "         3248,  769, 2675,  269,   83,   14, 1958,  861,  580,   69,  463,   50,\n",
       "          132, 1070,  181],\n",
       "        [  80,  242,    0,   19,  334,  123,   44,    1,    1,  160,    0,    2,\n",
       "           20,   27,    4,   60,    0,  201,  114,    6,   18,   10,   26,    4,\n",
       "           31,   14,    2],\n",
       "        [ 108,  330,    3,   24,   19,  334,    1,   25,  360,  190,    3,  185,\n",
       "           32,    6,   27,   83,    1,  204,  201,   30,   31,   85,    1,   26,\n",
       "          213,   31,    1],\n",
       "        [2409, 2244,    8,    2,   24,  674,    2,    2,    1,  729,    9,   29,\n",
       "          185,  117,  138,  287,    1,    1,  204,   31,   71,  166,   39,   10,\n",
       "          779,  213,   20],\n",
       "        [2489, 2445,  110,  509,  440, 1653,  101,  428,   95,   82,   76,  445,\n",
       "         1345,  427, 2126,  588,   53,   52,  849, 1316,  541,  109,  269,    8,\n",
       "           89,  779,  277],\n",
       "        [  71, 1473,    1,    4,    4,  440,    0,  307,   45,  119,    2,    2,\n",
       "            9,    5,    2,  479,    1,  109,   11,    7,    2,  202,    5,    6,\n",
       "          379,   10,    0],\n",
       "        [ 363, 1731,    2,    2,    2,  895,    1,   19,  307,  509,    2,   20,\n",
       "          139,    9,   26,  344,    3,   18,  109,   95,   17,   50,    2,   34,\n",
       "         1588,  379,    2],\n",
       "        [1314, 2623,   52,   25,  138, 2921,   22,    6,   19, 2480,    6,   24,\n",
       "         1345,   60,   14,  692,   15,    3,   18,   94,   77,  324,   72,   16,\n",
       "          287, 1588,   10],\n",
       "        [ 516, 2590,  112,   51,   24,  818,    1,   26,    5, 1256,    7,    1,\n",
       "            5,  168,   20,  452,   38,   44,   97,   35,    4,  139,    3,    2,\n",
       "          465,  287,   11],\n",
       "        [6763, 2977,    8,  213,  704, 1359,   11,  273,   26, 1725,   44,   58,\n",
       "          195,   19, 1906,  496,    5,    2,   44,  278,  443,   96,   55,   11,\n",
       "            6,  465,  145],\n",
       "        [ 855,  149,  140,  114,  190,  132,   34,   44,  171,   69,   16,   68,\n",
       "          619,  261, 2411,  115,   95,    3, 1059,  504,  118,  275,  176,  114,\n",
       "           45,  103,   54],\n",
       "        [  33,  209,    2,    1,    1,  197,    1,    0,  204,   61,    1,    1,\n",
       "           16,    1,    1,   59,   39,    1,  151,   16,   17,    4,    3,    0,\n",
       "            0,   12,    0],\n",
       "        [  28,   13,   99,  187, 1697,    1,   76,  121, 3033,   13,   90,  413,\n",
       "            1,    2,  869,    2,   16,  425,    1,    2,  252,  206,   21,    3,\n",
       "          773,   23,    0],\n",
       "        [1377, 2356,   41,   99,  187, 1697,    9,   76,  121, 3033,   25,   90,\n",
       "          413,  162,  140,  869,   14,   16,  425,  190,  208,  252,   80,   21,\n",
       "            3,  773,   23],\n",
       "        [1169, 1201,   21,   60,    9,  884,    2,    2, 1285,  684,    2,   82,\n",
       "          279,   90,   24,  531,   51,    1,   55,  461,  765,  185,   14,   24,\n",
       "          341,  215,   10],\n",
       "        [ 483, 1027,    1,   17,  169,  716,    2,    2,  647,  532,    3,  301,\n",
       "          134,    4,   22,  667,   10,  414,  352,   35,  374,   78,   15,   11,\n",
       "            2,  341,  105],\n",
       "        [ 155,  163,  103,  103,  136,  169,   19,   47,   58,  121,   14,   93,\n",
       "          301,  154,  275,   10,   16,   10,  414,  474,   82,    3,   37,   86,\n",
       "           34,   13,   45],\n",
       "        [  88,  642,    1,    8,    1,  568,    1,   23,    1,  911,    6,    3,\n",
       "           14,   58,    8,  153,    0,   22,   48,    8,   25,    7,    7,    0,\n",
       "           73,  121,    0],\n",
       "        [  51,  280,    1,    5,    8,  149,    2,    1,   23,  148,    0,    6,\n",
       "           13,    2,   58,   36,    0,    0,   22,   20,    8,   25,    3,    2,\n",
       "           30,   73,    1],\n",
       "        [ 164,  103,    1,    4,    5,   36,    3,   22,    1,  102,   86, 1104,\n",
       "           39,    1,    1,   41,    6,  291,  401,   31,   70,    5,    4,    3,\n",
       "           38,   30,   19],\n",
       "        [2007, 2143,   27,  115,  272,  301,   12,   30,   22,  192,   23,   86,\n",
       "         1104,  148, 1826,  271,   15,    6,  291,  401,  104,  141,  106,    4,\n",
       "           28,   23,   78],\n",
       "        [ 160,  860,    4,    2,    2,  373,    0,    1,   43,  364,    2,    2,\n",
       "          123,   35,    4,  110,    2,    0,   32,    4,    4,   73,    2,    3,\n",
       "            1,  147,   45]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for pair, freq in counts.items():\n",
    "    i_one = stoi[pair[0]]\n",
    "    i_two = stoi[pair[1]]\n",
    "    N[i_one, i_two] = freq\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.2417e-03, 1.7781e-02, 5.2657e-03, 6.2172e-03, 6.8139e-03, 6.1728e-03,\n",
       "         1.6813e-03, 2.6973e-03, 3.5239e-03, 2.3829e-03, 9.7653e-03, 1.1947e-02,\n",
       "         6.3381e-03, 1.0233e-02, 4.6206e-03, 1.5886e-03, 2.0764e-03, 3.7093e-04,\n",
       "         6.6083e-03, 8.2856e-03, 5.2737e-03, 3.1449e-04, 1.5160e-03, 1.2378e-03,\n",
       "         5.4027e-04, 2.1571e-03, 3.7456e-03],\n",
       "        [2.6772e-02, 2.2417e-03, 2.1813e-03, 1.8950e-03, 4.2012e-03, 2.7901e-03,\n",
       "         5.4027e-04, 6.7736e-04, 9.4024e-03, 6.6526e-03, 7.0558e-04, 2.2901e-03,\n",
       "         1.0193e-02, 6.5881e-03, 2.1925e-02, 2.5401e-04, 3.3062e-04, 2.4191e-04,\n",
       "         1.3160e-02, 4.5077e-03, 2.7699e-03, 1.5362e-03, 3.3626e-03, 6.4914e-04,\n",
       "         7.3381e-04, 8.2654e-03, 1.7539e-03],\n",
       "        [4.5964e-04, 1.2942e-03, 1.5321e-04, 4.0319e-06, 2.6207e-04, 2.6409e-03,\n",
       "         8.0638e-06, 2.6772e-03, 1.6531e-04, 8.7492e-04, 4.0319e-06, 4.6770e-04,\n",
       "         4.1529e-04, 0.0000e+00, 1.6128e-05, 4.2335e-04, 4.4351e-05, 3.0642e-04,\n",
       "         3.3949e-03, 3.2255e-05, 8.0638e-06, 1.8144e-04, 0.0000e+00, 1.2096e-05,\n",
       "         4.1932e-04, 3.3465e-04, 0.0000e+00],\n",
       "        [3.9109e-04, 3.2860e-03, 1.2096e-05, 1.6934e-04, 4.0319e-06, 2.2216e-03,\n",
       "         1.0080e-04, 8.0638e-06, 2.6772e-03, 1.0926e-03, 1.2096e-05, 1.2741e-03,\n",
       "         4.6770e-04, 1.2499e-04, 1.5241e-03, 1.5321e-03, 4.0319e-06, 4.4351e-05,\n",
       "         3.0642e-04, 2.0160e-05, 1.4112e-04, 1.4112e-04, 9.2734e-05, 0.0000e+00,\n",
       "         1.2096e-05, 4.1932e-04, 1.6128e-05],\n",
       "        [2.0805e-03, 5.2536e-03, 4.0319e-06, 1.2096e-05, 6.0075e-04, 5.1729e-03,\n",
       "         2.0160e-05, 1.0080e-04, 4.7576e-04, 2.7175e-03, 3.6287e-05, 1.2096e-05,\n",
       "         2.4191e-04, 1.2096e-04, 1.2499e-04, 1.5241e-03, 5.6447e-05, 4.0319e-06,\n",
       "         1.7095e-03, 1.1693e-04, 1.6128e-05, 3.7093e-04, 6.8542e-05, 9.2734e-05,\n",
       "         4.3141e-03, 1.2781e-03, 4.0319e-06],\n",
       "        [1.6059e-02, 2.7377e-03, 4.8786e-04, 6.1688e-04, 1.5482e-03, 5.1245e-03,\n",
       "         3.3062e-04, 5.0399e-04, 6.1285e-04, 3.2981e-03, 2.2175e-04, 7.1768e-04,\n",
       "         1.3096e-02, 3.1005e-03, 1.0785e-02, 1.0846e-03, 3.3465e-04, 5.6447e-05,\n",
       "         7.8945e-03, 3.4715e-03, 2.3385e-03, 2.7820e-04, 1.8668e-03, 2.0160e-04,\n",
       "         5.3221e-04, 4.3141e-03, 7.2977e-04],\n",
       "        [3.2255e-04, 9.7572e-04, 0.0000e+00, 7.6606e-05, 1.3467e-03, 4.9592e-04,\n",
       "         1.7740e-04, 4.0319e-06, 4.0319e-06, 6.4510e-04, 0.0000e+00, 8.0638e-06,\n",
       "         8.0638e-05, 1.0886e-04, 1.6128e-05, 2.4191e-04, 0.0000e+00, 8.1041e-04,\n",
       "         4.5964e-04, 2.4191e-05, 7.2574e-05, 4.0319e-05, 1.0483e-04, 1.6128e-05,\n",
       "         1.2499e-04, 5.6447e-05, 8.0638e-06],\n",
       "        [4.3545e-04, 1.3305e-03, 1.2096e-05, 9.6766e-05, 7.6606e-05, 1.3467e-03,\n",
       "         4.0319e-06, 1.0080e-04, 1.4515e-03, 7.6606e-04, 1.2096e-05, 7.4590e-04,\n",
       "         1.2902e-04, 2.4191e-05, 1.0886e-04, 3.3465e-04, 4.0319e-06, 8.2251e-04,\n",
       "         8.1041e-04, 1.2096e-04, 1.2499e-04, 3.4271e-04, 4.0319e-06, 1.0483e-04,\n",
       "         8.5879e-04, 1.2499e-04, 4.0319e-06],\n",
       "        [9.7128e-03, 9.0476e-03, 3.2255e-05, 8.0638e-06, 9.6766e-05, 2.7175e-03,\n",
       "         8.0638e-06, 8.0638e-06, 4.0319e-06, 2.9393e-03, 3.6287e-05, 1.1693e-04,\n",
       "         7.4590e-04, 4.7173e-04, 5.5640e-04, 1.1572e-03, 4.0319e-06, 4.0319e-06,\n",
       "         8.2251e-04, 1.2499e-04, 2.8626e-04, 6.6930e-04, 1.5724e-04, 4.0319e-05,\n",
       "         3.1409e-03, 8.5879e-04, 8.0638e-05],\n",
       "        [1.0035e-02, 9.8580e-03, 4.4351e-04, 2.0522e-03, 1.7740e-03, 6.6647e-03,\n",
       "         4.0722e-04, 1.7257e-03, 3.8303e-04, 3.3062e-04, 3.0642e-04, 1.7942e-03,\n",
       "         5.4229e-03, 1.7216e-03, 8.5718e-03, 2.3708e-03, 2.1369e-04, 2.0966e-04,\n",
       "         3.4231e-03, 5.3060e-03, 2.1813e-03, 4.3948e-04, 1.0846e-03, 3.2255e-05,\n",
       "         3.5884e-04, 3.1409e-03, 1.1168e-03],\n",
       "        [2.8626e-04, 5.9390e-03, 4.0319e-06, 1.6128e-05, 1.6128e-05, 1.7740e-03,\n",
       "         0.0000e+00, 1.2378e-03, 1.8144e-04, 4.7980e-04, 8.0638e-06, 8.0638e-06,\n",
       "         3.6287e-05, 2.0160e-05, 8.0638e-06, 1.9313e-03, 4.0319e-06, 4.3948e-04,\n",
       "         4.4351e-05, 2.8223e-05, 8.0638e-06, 8.1444e-04, 2.0160e-05, 2.4191e-05,\n",
       "         1.5281e-03, 4.0319e-05, 0.0000e+00],\n",
       "        [1.4636e-03, 6.9792e-03, 8.0638e-06, 8.0638e-06, 8.0638e-06, 3.6086e-03,\n",
       "         4.0319e-06, 7.6606e-05, 1.2378e-03, 2.0522e-03, 8.0638e-06, 8.0638e-05,\n",
       "         5.6043e-04, 3.6287e-05, 1.0483e-04, 1.3870e-03, 1.2096e-05, 7.2574e-05,\n",
       "         4.3948e-04, 3.8303e-04, 6.8542e-05, 2.0160e-04, 8.0638e-06, 1.3708e-04,\n",
       "         6.4027e-03, 1.5281e-03, 8.0638e-06],\n",
       "        [5.2979e-03, 1.0576e-02, 2.0966e-04, 1.0080e-04, 5.5640e-04, 1.1777e-02,\n",
       "         8.8702e-05, 2.4191e-05, 7.6606e-05, 9.9991e-03, 2.4191e-05, 9.6766e-05,\n",
       "         5.4229e-03, 2.4191e-04, 5.6447e-05, 2.7901e-03, 6.0479e-05, 1.2096e-05,\n",
       "         7.2574e-05, 3.7900e-04, 3.1046e-04, 1.3063e-03, 2.9030e-04, 6.4510e-05,\n",
       "         1.1572e-03, 6.4027e-03, 4.0319e-05],\n",
       "        [2.0805e-03, 1.0443e-02, 4.5157e-04, 2.0563e-04, 9.6766e-05, 3.2981e-03,\n",
       "         4.0319e-06, 1.0483e-04, 2.0160e-05, 5.0641e-03, 2.8223e-05, 4.0319e-06,\n",
       "         2.0160e-05, 6.7736e-04, 8.0638e-05, 1.8224e-03, 1.5321e-04, 1.7740e-04,\n",
       "         3.9109e-04, 1.4112e-04, 1.6128e-05, 5.6043e-04, 1.2096e-05, 8.0638e-06,\n",
       "         1.8748e-03, 1.1572e-03, 4.4351e-05],\n",
       "        [2.7268e-02, 1.2003e-02, 3.2255e-05, 8.5879e-04, 2.8385e-03, 5.4794e-03,\n",
       "         4.4351e-05, 1.1007e-03, 1.0483e-04, 6.9550e-03, 1.7740e-04, 2.3385e-04,\n",
       "         7.8622e-04, 7.6606e-05, 7.6848e-03, 1.9998e-03, 2.0160e-05, 8.0638e-06,\n",
       "         1.7740e-04, 1.1209e-03, 1.7861e-03, 3.8706e-04, 2.2175e-04, 4.4351e-05,\n",
       "         2.4191e-05, 1.8748e-03, 5.8463e-04],\n",
       "        [3.4473e-03, 6.0075e-04, 5.6447e-04, 4.5964e-04, 7.6606e-04, 5.3221e-04,\n",
       "         1.3708e-04, 1.7740e-04, 6.8945e-04, 2.7820e-04, 6.4510e-05, 2.7417e-04,\n",
       "         2.4957e-03, 1.0523e-03, 9.7209e-03, 4.6367e-04, 3.8303e-04, 1.2096e-05,\n",
       "         4.2698e-03, 2.0321e-03, 4.7576e-04, 1.1088e-03, 7.0961e-04, 4.5964e-04,\n",
       "         1.8144e-04, 4.1529e-04, 2.1772e-04],\n",
       "        [1.3305e-04, 8.4267e-04, 8.0638e-06, 4.0319e-06, 4.0319e-06, 7.9428e-04,\n",
       "         4.0319e-06, 0.0000e+00, 8.2251e-04, 2.4595e-04, 4.0319e-06, 4.0319e-06,\n",
       "         6.4510e-05, 4.0319e-06, 4.0319e-06, 2.3788e-04, 1.5724e-04, 4.0319e-06,\n",
       "         6.0882e-04, 6.4510e-05, 6.8542e-05, 1.6128e-05, 1.2096e-05, 0.0000e+00,\n",
       "         0.0000e+00, 4.8383e-05, 0.0000e+00],\n",
       "        [1.1289e-04, 5.2415e-05, 3.9916e-04, 7.5397e-04, 6.8421e-03, 4.0319e-06,\n",
       "         3.0642e-04, 4.8786e-04, 1.2229e-02, 5.2415e-05, 3.6287e-04, 1.6652e-03,\n",
       "         4.0319e-06, 8.0638e-06, 3.5037e-03, 8.0638e-06, 6.4510e-05, 1.7136e-03,\n",
       "         4.0319e-06, 8.0638e-06, 1.0160e-03, 8.3057e-04, 8.4670e-05, 1.2096e-05,\n",
       "         3.1167e-03, 9.2734e-05, 0.0000e+00],\n",
       "        [5.5519e-03, 9.4992e-03, 1.6531e-04, 3.9916e-04, 7.5397e-04, 6.8421e-03,\n",
       "         3.6287e-05, 3.0642e-04, 4.8786e-04, 1.2229e-02, 1.0080e-04, 3.6287e-04,\n",
       "         1.6652e-03, 6.5317e-04, 5.6447e-04, 3.5037e-03, 5.6447e-05, 6.4510e-05,\n",
       "         1.7136e-03, 7.6606e-04, 8.3864e-04, 1.0160e-03, 3.2255e-04, 8.4670e-05,\n",
       "         1.2096e-05, 3.1167e-03, 9.2734e-05],\n",
       "        [4.7133e-03, 4.8423e-03, 8.4670e-05, 2.4191e-04, 3.6287e-05, 3.5642e-03,\n",
       "         8.0638e-06, 8.0638e-06, 5.1810e-03, 2.7578e-03, 8.0638e-06, 3.3062e-04,\n",
       "         1.1249e-03, 3.6287e-04, 9.6766e-05, 2.1409e-03, 2.0563e-04, 4.0319e-06,\n",
       "         2.2175e-04, 1.8587e-03, 3.0844e-03, 7.4590e-04, 5.6447e-05, 9.6766e-05,\n",
       "         1.3749e-03, 8.6686e-04, 4.0319e-05],\n",
       "        [1.9474e-03, 4.1408e-03, 4.0319e-06, 6.8542e-05, 6.8139e-04, 2.8868e-03,\n",
       "         8.0638e-06, 8.0638e-06, 2.6086e-03, 2.1450e-03, 1.2096e-05, 1.2136e-03,\n",
       "         5.4027e-04, 1.6128e-05, 8.8702e-05, 2.6893e-03, 4.0319e-05, 1.6692e-03,\n",
       "         1.4192e-03, 1.4112e-04, 1.5079e-03, 3.1449e-04, 6.0479e-05, 4.4351e-05,\n",
       "         8.0638e-06, 1.3749e-03, 4.2335e-04],\n",
       "        [6.2494e-04, 6.5720e-04, 4.1529e-04, 4.1529e-04, 5.4834e-04, 6.8139e-04,\n",
       "         7.6606e-05, 1.8950e-04, 2.3385e-04, 4.8786e-04, 5.6447e-05, 3.7497e-04,\n",
       "         1.2136e-03, 6.2091e-04, 1.1088e-03, 4.0319e-05, 6.4510e-05, 4.0319e-05,\n",
       "         1.6692e-03, 1.9111e-03, 3.3062e-04, 1.2096e-05, 1.4918e-04, 3.4674e-04,\n",
       "         1.3708e-04, 5.2415e-05, 1.8144e-04],\n",
       "        [3.5481e-04, 2.5885e-03, 4.0319e-06, 3.2255e-05, 4.0319e-06, 2.2901e-03,\n",
       "         4.0319e-06, 9.2734e-05, 4.0319e-06, 3.6731e-03, 2.4191e-05, 1.2096e-05,\n",
       "         5.6447e-05, 2.3385e-04, 3.2255e-05, 6.1688e-04, 0.0000e+00, 8.8702e-05,\n",
       "         1.9353e-04, 3.2255e-05, 1.0080e-04, 2.8223e-05, 2.8223e-05, 0.0000e+00,\n",
       "         2.9433e-04, 4.8786e-04, 0.0000e+00],\n",
       "        [2.0563e-04, 1.1289e-03, 4.0319e-06, 2.0160e-05, 3.2255e-05, 6.0075e-04,\n",
       "         8.0638e-06, 4.0319e-06, 9.2734e-05, 5.9672e-04, 0.0000e+00, 2.4191e-05,\n",
       "         5.2415e-05, 8.0638e-06, 2.3385e-04, 1.4515e-04, 0.0000e+00, 0.0000e+00,\n",
       "         8.8702e-05, 8.0638e-05, 3.2255e-05, 1.0080e-04, 1.2096e-05, 8.0638e-06,\n",
       "         1.2096e-04, 2.9433e-04, 4.0319e-06],\n",
       "        [6.6123e-04, 4.1529e-04, 4.0319e-06, 1.6128e-05, 2.0160e-05, 1.4515e-04,\n",
       "         1.2096e-05, 8.8702e-05, 4.0319e-06, 4.1125e-04, 3.4674e-04, 4.4512e-03,\n",
       "         1.5724e-04, 4.0319e-06, 4.0319e-06, 1.6531e-04, 2.4191e-05, 1.1733e-03,\n",
       "         1.6168e-03, 1.2499e-04, 2.8223e-04, 2.0160e-05, 1.6128e-05, 1.2096e-05,\n",
       "         1.5321e-04, 1.2096e-04, 7.6606e-05],\n",
       "        [8.0920e-03, 8.6404e-03, 1.0886e-04, 4.6367e-04, 1.0967e-03, 1.2136e-03,\n",
       "         4.8383e-05, 1.2096e-04, 8.8702e-05, 7.7412e-04, 9.2734e-05, 3.4674e-04,\n",
       "         4.4512e-03, 5.9672e-04, 7.3623e-03, 1.0926e-03, 6.0479e-05, 2.4191e-05,\n",
       "         1.1733e-03, 1.6168e-03, 4.1932e-04, 5.6850e-04, 4.2738e-04, 1.6128e-05,\n",
       "         1.1289e-04, 9.2734e-05, 3.1449e-04],\n",
       "        [6.4510e-04, 3.4674e-03, 1.6128e-05, 8.0638e-06, 8.0638e-06, 1.5039e-03,\n",
       "         0.0000e+00, 4.0319e-06, 1.7337e-04, 1.4676e-03, 8.0638e-06, 8.0638e-06,\n",
       "         4.9592e-04, 1.4112e-04, 1.6128e-05, 4.4351e-04, 8.0638e-06, 0.0000e+00,\n",
       "         1.2902e-04, 1.6128e-05, 1.6128e-05, 2.9433e-04, 8.0638e-06, 1.2096e-05,\n",
       "         4.0319e-06, 5.9269e-04, 1.8144e-04]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N / N.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20,  1, 14, 11, 20, 11,  1,  4, 13, 10],\n",
       "        [ 0, 14, 14, 18, 18,  8, 25,  1, 18,  0],\n",
       "        [18, 18, 18, 17,  7,  4, 18,  0,  5,  7],\n",
       "        [ 1,  1,  9,  5, 12,  5,  5, 15,  8,  1],\n",
       "        [ 5,  0, 18, 12,  8,  9,  5,  5, 24,  1],\n",
       "        [12,  0,  5, 12,  0, 14,  1, 12, 12, 18],\n",
       "        [19,  6,  9,  9,  1,  4,  4,  9,  5, 18],\n",
       "        [ 5, 11, 24,  8, 24, 20, 12, 15,  1, 17],\n",
       "        [ 1,  1,  0,  9,  0, 11,  5,  1,  1, 24],\n",
       "        [12, 14,  1, 13, 12, 12, 13, 14,  0, 14],\n",
       "        [ 1,  1,  7,  5,  5, 15,  1,  0,  7,  1],\n",
       "        [ 1, 21, 15,  1,  1,  1,  1, 24, 24,  0],\n",
       "        [ 1,  9,  5,  1,  5,  1, 25, 25,  9,  9],\n",
       "        [ 1,  1,  1, 24,  2,  1, 15,  5,  1,  1],\n",
       "        [ 1,  9,  0,  0,  0,  1,  0, 26,  0,  0],\n",
       "        [13, 14, 14, 19, 22, 14,  0, 12, 22, 14],\n",
       "        [ 8,  8,  0, 16,  1,  1,  8,  1,  1,  8],\n",
       "        [ 8, 14, 21, 14,  4, 24,  8,  8, 14,  8],\n",
       "        [ 9,  0,  9, 18, 15,  0,  9, 18,  3,  9],\n",
       "        [ 0,  1, 15,  0,  5,  5,  1, 21,  8,  1],\n",
       "        [ 9,  8,  1,  9, 15, 17,  1, 15,  1, 17],\n",
       "        [12,  4,  1, 19,  0, 12, 18, 19, 14, 20],\n",
       "        [ 5,  5,  5,  5,  5,  9,  1,  5,  9, 20],\n",
       "        [ 1,  9,  5,  1, 14, 20,  8, 14,  5,  1],\n",
       "        [18, 10, 18,  1, 11,  0,  0, 11, 11, 11],\n",
       "        [14,  0, 12, 12,  3,  1, 18,  1,  1, 14],\n",
       "        [ 5, 25, 13,  1,  9, 18,  0,  5,  1,  1]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2)\n",
    "samples = torch.multinomial(p, 10, replacement=True, generator=g)\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lens = [len(w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 556, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "         1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "          134,  535,  929],\n",
       "        [6640,  556,  541,  470, 1042,  692,  134,  168, 2332, 1650,  175,  568,\n",
       "         2528, 1634, 5438,   63,   82,   60, 3264, 1118,  687,  381,  834,  161,\n",
       "          182, 2050,  435],\n",
       "        [ 114,  321,   38,    1,   65,  655,    2,  664,   41,  217,    1,  116,\n",
       "          103,    0,    4,  105,   11,   76,  842,    8,    2,   45,    0,    3,\n",
       "          104,   83,    0],\n",
       "        [  97,  815,    3,   42,    1,  551,   25,    2,  664,  271,    3,  316,\n",
       "          116,   31,  378,  380,    1,   11,   76,    5,   35,   35,   23,    0,\n",
       "            3,  104,    4],\n",
       "        [ 516, 1303,    1,    3,  149, 1283,    5,   25,  118,  674,    9,    3,\n",
       "           60,   30,   31,  378,   14,    1,  424,   29,    4,   92,   17,   23,\n",
       "         1070,  317,    1],\n",
       "        [3983,  679,  121,  153,  384, 1271,   82,  125,  152,  818,   55,  178,\n",
       "         3248,  769, 2675,  269,   83,   14, 1958,  861,  580,   69,  463,   50,\n",
       "          132, 1070,  181],\n",
       "        [  80,  242,    0,   19,  334,  123,   44,    1,    1,  160,    0,    2,\n",
       "           20,   27,    4,   60,    0,  201,  114,    6,   18,   10,   26,    4,\n",
       "           31,   14,    2],\n",
       "        [ 108,  330,    3,   24,   19,  334,    1,   25,  360,  190,    3,  185,\n",
       "           32,    6,   27,   83,    1,  204,  201,   30,   31,   85,    1,   26,\n",
       "          213,   31,    1],\n",
       "        [2409, 2244,    8,    2,   24,  674,    2,    2,    1,  729,    9,   29,\n",
       "          185,  117,  138,  287,    1,    1,  204,   31,   71,  166,   39,   10,\n",
       "          779,  213,   20],\n",
       "        [2489, 2445,  110,  509,  440, 1653,  101,  428,   95,   82,   76,  445,\n",
       "         1345,  427, 2126,  588,   53,   52,  849, 1316,  541,  109,  269,    8,\n",
       "           89,  779,  277],\n",
       "        [  71, 1473,    1,    4,    4,  440,    0,  307,   45,  119,    2,    2,\n",
       "            9,    5,    2,  479,    1,  109,   11,    7,    2,  202,    5,    6,\n",
       "          379,   10,    0],\n",
       "        [ 363, 1731,    2,    2,    2,  895,    1,   19,  307,  509,    2,   20,\n",
       "          139,    9,   26,  344,    3,   18,  109,   95,   17,   50,    2,   34,\n",
       "         1588,  379,    2],\n",
       "        [1314, 2623,   52,   25,  138, 2921,   22,    6,   19, 2480,    6,   24,\n",
       "         1345,   60,   14,  692,   15,    3,   18,   94,   77,  324,   72,   16,\n",
       "          287, 1588,   10],\n",
       "        [ 516, 2590,  112,   51,   24,  818,    1,   26,    5, 1256,    7,    1,\n",
       "            5,  168,   20,  452,   38,   44,   97,   35,    4,  139,    3,    2,\n",
       "          465,  287,   11],\n",
       "        [6763, 2977,    8,  213,  704, 1359,   11,  273,   26, 1725,   44,   58,\n",
       "          195,   19, 1906,  496,    5,    2,   44,  278,  443,   96,   55,   11,\n",
       "            6,  465,  145],\n",
       "        [ 855,  149,  140,  114,  190,  132,   34,   44,  171,   69,   16,   68,\n",
       "          619,  261, 2411,  115,   95,    3, 1059,  504,  118,  275,  176,  114,\n",
       "           45,  103,   54],\n",
       "        [  33,  209,    2,    1,    1,  197,    1,    0,  204,   61,    1,    1,\n",
       "           16,    1,    1,   59,   39,    1,  151,   16,   17,    4,    3,    0,\n",
       "            0,   12,    0],\n",
       "        [  28,   13,   99,  187, 1697,    1,   76,  121, 3033,   13,   90,  413,\n",
       "            1,    2,  869,    2,   16,  425,    1,    2,  252,  206,   21,    3,\n",
       "          773,   23,    0],\n",
       "        [1377, 2356,   41,   99,  187, 1697,    9,   76,  121, 3033,   25,   90,\n",
       "          413,  162,  140,  869,   14,   16,  425,  190,  208,  252,   80,   21,\n",
       "            3,  773,   23],\n",
       "        [1169, 1201,   21,   60,    9,  884,    2,    2, 1285,  684,    2,   82,\n",
       "          279,   90,   24,  531,   51,    1,   55,  461,  765,  185,   14,   24,\n",
       "          341,  215,   10],\n",
       "        [ 483, 1027,    1,   17,  169,  716,    2,    2,  647,  532,    3,  301,\n",
       "          134,    4,   22,  667,   10,  414,  352,   35,  374,   78,   15,   11,\n",
       "            2,  341,  105],\n",
       "        [ 155,  163,  103,  103,  136,  169,   19,   47,   58,  121,   14,   93,\n",
       "          301,  154,  275,   10,   16,   10,  414,  474,   82,    3,   37,   86,\n",
       "           34,   13,   45],\n",
       "        [  88,  642,    1,    8,    1,  568,    1,   23,    1,  911,    6,    3,\n",
       "           14,   58,    8,  153,    0,   22,   48,    8,   25,    7,    7,    0,\n",
       "           73,  121,    0],\n",
       "        [  51,  280,    1,    5,    8,  149,    2,    1,   23,  148,    0,    6,\n",
       "           13,    2,   58,   36,    0,    0,   22,   20,    8,   25,    3,    2,\n",
       "           30,   73,    1],\n",
       "        [ 164,  103,    1,    4,    5,   36,    3,   22,    1,  102,   86, 1104,\n",
       "           39,    1,    1,   41,    6,  291,  401,   31,   70,    5,    4,    3,\n",
       "           38,   30,   19],\n",
       "        [2007, 2143,   27,  115,  272,  301,   12,   30,   22,  192,   23,   86,\n",
       "         1104,  148, 1826,  271,   15,    6,  291,  401,  104,  141,  106,    4,\n",
       "           28,   23,   78],\n",
       "        [ 160,  860,    4,    2,    2,  373,    0,    1,   43,  364,    2,    2,\n",
       "          123,   35,    4,  110,    2,    0,   32,    4,    4,   73,    2,    3,\n",
       "            1,  147,   45]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [2., 2., 2., 2.]]),\n",
       " tensor([[4.],\n",
       "         [8.]]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(4)\n",
    "twos = torch.ones(4) * 2\n",
    "test = torch.stack([ones, twos])\n",
    "test, test.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = N.float()\n",
    "P /= P.sum(dim=1, keepdim=True)\n",
    "P[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide\n",
      "janasah\n",
      "p\n",
      "cfqh\n",
      "a\n",
      "nn\n",
      "kxi\n",
      "ritolian\n",
      "jgee\n",
      "kxqhnaauranilevias\n",
      "dedainrwieta\n",
      "ssonielylarte\n",
      "faveumerifontume\n",
      "phynslenaruani\n",
      "core\n",
      "yaenon\n",
      "ka\n",
      "jabdinerimikimaynin\n",
      "anaasn\n",
      "ssorionsushxdxossmitqn\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "words_to_gen = 20\n",
    "for wi in range(words_to_gen):\n",
    "    # word_len = torch.randint(min(word_lens), max(word_lens), (1,)).item()\n",
    "    # for i in range(int(word_len)):\n",
    "    li = 0\n",
    "    next_letter = ''\n",
    "    genned_word = '.'\n",
    "    while next_letter != '.':\n",
    "        prior_letter = genned_word[li]\n",
    "        prior_letter_i = stoi[prior_letter]\n",
    "        next_sample_p = P[prior_letter_i]\n",
    "        next_letter_idx = torch.multinomial(\n",
    "                next_sample_p, 1, replacement=True, generator=g\n",
    "            ).item()\n",
    "        next_letter = itos[next_letter_idx]\n",
    "        genned_word += next_letter\n",
    "        li += 1\n",
    "    print(genned_word.strip('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg log likelihood: 570686.625\n",
      "avg neg log likelhood: 2.5014097690582275\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "log_likelihood = 0\n",
    "for word in words:\n",
    "    w_start_end = '.' + word + '.'\n",
    "    for char, char1 in zip(w_start_end, w_start_end[1:]):\n",
    "        prob = P[stoi[char], stoi[char1]]\n",
    "        log_likelihood += torch.log(prob)\n",
    "        n += 1\n",
    "        # print(f'{char}{char1}: {prob:.4f}')\n",
    "\n",
    "print(f\"neg log likelihood: {-log_likelihood}\")\n",
    "print(f\"avg neg log likelhood: {-log_likelihood / n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.e',\n",
       " 'em',\n",
       " 'mm',\n",
       " 'ma',\n",
       " 'a.',\n",
       " '.o',\n",
       " 'ol',\n",
       " 'li',\n",
       " 'iv',\n",
       " 'vi',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.a',\n",
       " 'av',\n",
       " 'va',\n",
       " 'a.',\n",
       " '.i',\n",
       " 'is',\n",
       " 'sa',\n",
       " 'ab',\n",
       " 'be',\n",
       " 'el',\n",
       " 'll',\n",
       " 'la',\n",
       " 'a.',\n",
       " '.s',\n",
       " 'so',\n",
       " 'op',\n",
       " 'ph',\n",
       " 'hi',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.c',\n",
       " 'ch',\n",
       " 'ha',\n",
       " 'ar',\n",
       " 'rl',\n",
       " 'lo',\n",
       " 'ot',\n",
       " 'tt',\n",
       " 'te',\n",
       " 'e.',\n",
       " '.m',\n",
       " 'mi',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.a',\n",
       " 'am',\n",
       " 'me',\n",
       " 'el',\n",
       " 'li',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.h',\n",
       " 'ha',\n",
       " 'ar',\n",
       " 'rp',\n",
       " 'pe',\n",
       " 'er',\n",
       " 'r.',\n",
       " '.e',\n",
       " 'ev',\n",
       " 've',\n",
       " 'el',\n",
       " 'ly',\n",
       " 'yn',\n",
       " 'n.',\n",
       " '.a',\n",
       " 'ab',\n",
       " 'bi',\n",
       " 'ig',\n",
       " 'ga',\n",
       " 'ai',\n",
       " 'il',\n",
       " 'l.',\n",
       " '.e',\n",
       " 'em',\n",
       " 'mi',\n",
       " 'il',\n",
       " 'ly',\n",
       " 'y.',\n",
       " '.e',\n",
       " 'el',\n",
       " 'li',\n",
       " 'iz',\n",
       " 'za',\n",
       " 'ab',\n",
       " 'be',\n",
       " 'et',\n",
       " 'th',\n",
       " 'h.',\n",
       " '.m',\n",
       " 'mi',\n",
       " 'il',\n",
       " 'la',\n",
       " 'a.',\n",
       " '.e',\n",
       " 'el',\n",
       " 'll',\n",
       " 'la',\n",
       " 'a.',\n",
       " '.a',\n",
       " 'av',\n",
       " 've',\n",
       " 'er',\n",
       " 'ry',\n",
       " 'y.',\n",
       " '.s',\n",
       " 'so',\n",
       " 'of',\n",
       " 'fi',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.c',\n",
       " 'ca',\n",
       " 'am',\n",
       " 'mi',\n",
       " 'il',\n",
       " 'la',\n",
       " 'a.',\n",
       " '.a',\n",
       " 'ar',\n",
       " 'ri',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.s',\n",
       " 'sc',\n",
       " 'ca',\n",
       " 'ar',\n",
       " 'rl',\n",
       " 'le',\n",
       " 'et',\n",
       " 'tt',\n",
       " 't.',\n",
       " '.v',\n",
       " 'vi',\n",
       " 'ic',\n",
       " 'ct',\n",
       " 'to',\n",
       " 'or',\n",
       " 'ri',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.m',\n",
       " 'ma',\n",
       " 'ad',\n",
       " 'di',\n",
       " 'is',\n",
       " 'so',\n",
       " 'on',\n",
       " 'n.',\n",
       " '.l',\n",
       " 'lu',\n",
       " 'un',\n",
       " 'na',\n",
       " 'a.',\n",
       " '.g',\n",
       " 'gr',\n",
       " 'ra',\n",
       " 'ac',\n",
       " 'ce',\n",
       " 'e.',\n",
       " '.c',\n",
       " 'ch',\n",
       " 'hl',\n",
       " 'lo',\n",
       " 'oe',\n",
       " 'e.',\n",
       " '.p',\n",
       " 'pe',\n",
       " 'en',\n",
       " 'ne',\n",
       " 'el',\n",
       " 'lo',\n",
       " 'op',\n",
       " 'pe',\n",
       " 'e.',\n",
       " '.l',\n",
       " 'la',\n",
       " 'ay',\n",
       " 'yl',\n",
       " 'la',\n",
       " 'a.',\n",
       " '.r',\n",
       " 'ri',\n",
       " 'il',\n",
       " 'le',\n",
       " 'ey',\n",
       " 'y.',\n",
       " '.z',\n",
       " 'zo',\n",
       " 'oe',\n",
       " 'ey',\n",
       " 'y.',\n",
       " '.n',\n",
       " 'no',\n",
       " 'or',\n",
       " 'ra',\n",
       " 'a.',\n",
       " '.l',\n",
       " 'li',\n",
       " 'il',\n",
       " 'ly',\n",
       " 'y.',\n",
       " '.e',\n",
       " 'el',\n",
       " 'le',\n",
       " 'ea',\n",
       " 'an',\n",
       " 'no',\n",
       " 'or',\n",
       " 'r.',\n",
       " '.h',\n",
       " 'ha',\n",
       " 'an',\n",
       " 'nn',\n",
       " 'na',\n",
       " 'ah',\n",
       " 'h.',\n",
       " '.l',\n",
       " 'li',\n",
       " 'il',\n",
       " 'll',\n",
       " 'li',\n",
       " 'ia',\n",
       " 'an',\n",
       " 'n.',\n",
       " '.a',\n",
       " 'ad',\n",
       " 'dd',\n",
       " 'di',\n",
       " 'is',\n",
       " 'so',\n",
       " 'on',\n",
       " 'n.',\n",
       " '.a',\n",
       " 'au',\n",
       " 'ub',\n",
       " 'br',\n",
       " 're',\n",
       " 'ey',\n",
       " 'y.',\n",
       " '.e',\n",
       " 'el',\n",
       " 'll',\n",
       " 'li',\n",
       " 'ie',\n",
       " 'e.',\n",
       " '.s',\n",
       " 'st',\n",
       " 'te',\n",
       " 'el',\n",
       " 'll',\n",
       " 'la',\n",
       " 'a.',\n",
       " '.n',\n",
       " 'na',\n",
       " 'at',\n",
       " 'ta',\n",
       " 'al',\n",
       " 'li',\n",
       " 'ie',\n",
       " 'e.',\n",
       " '.z',\n",
       " 'zo',\n",
       " 'oe',\n",
       " 'e.',\n",
       " '.l',\n",
       " 'le',\n",
       " 'ea',\n",
       " 'ah',\n",
       " 'h.',\n",
       " '.h',\n",
       " 'ha',\n",
       " 'az',\n",
       " 'ze',\n",
       " 'el',\n",
       " 'l.',\n",
       " '.v',\n",
       " 'vi',\n",
       " 'io',\n",
       " 'ol',\n",
       " 'le',\n",
       " 'et',\n",
       " 't.',\n",
       " '.a',\n",
       " 'au',\n",
       " 'ur',\n",
       " 'ro',\n",
       " 'or',\n",
       " 'ra',\n",
       " 'a.',\n",
       " '.s',\n",
       " 'sa',\n",
       " 'av',\n",
       " 'va',\n",
       " 'an',\n",
       " 'nn',\n",
       " 'na',\n",
       " 'ah',\n",
       " 'h.',\n",
       " '.a',\n",
       " 'au',\n",
       " 'ud',\n",
       " 'dr',\n",
       " 're',\n",
       " 'ey',\n",
       " 'y.',\n",
       " '.b',\n",
       " 'br',\n",
       " 'ro',\n",
       " 'oo',\n",
       " 'ok',\n",
       " 'kl',\n",
       " 'ly',\n",
       " 'yn',\n",
       " 'n.',\n",
       " '.b',\n",
       " 'be',\n",
       " 'el',\n",
       " 'll',\n",
       " 'la',\n",
       " 'a.',\n",
       " '.c',\n",
       " 'cl',\n",
       " 'la',\n",
       " 'ai',\n",
       " 'ir',\n",
       " 're',\n",
       " 'e.',\n",
       " '.s',\n",
       " 'sk',\n",
       " 'ky',\n",
       " 'yl',\n",
       " 'la',\n",
       " 'ar',\n",
       " 'r.',\n",
       " '.l',\n",
       " 'lu',\n",
       " 'uc',\n",
       " 'cy',\n",
       " 'y.',\n",
       " '.p',\n",
       " 'pa',\n",
       " 'ai',\n",
       " 'is',\n",
       " 'sl',\n",
       " 'le',\n",
       " 'ey',\n",
       " 'y.',\n",
       " '.e',\n",
       " 'ev',\n",
       " 've',\n",
       " 'er',\n",
       " 'rl',\n",
       " 'ly',\n",
       " 'y.',\n",
       " '.a',\n",
       " 'an',\n",
       " 'nn',\n",
       " 'na',\n",
       " 'a.',\n",
       " '.c',\n",
       " 'ca',\n",
       " 'ar',\n",
       " 'ro',\n",
       " 'ol',\n",
       " 'li',\n",
       " 'in',\n",
       " 'ne',\n",
       " 'e.',\n",
       " '.n',\n",
       " 'no',\n",
       " 'ov',\n",
       " 'va',\n",
       " 'a.',\n",
       " '.g',\n",
       " 'ge',\n",
       " 'en',\n",
       " 'ne',\n",
       " 'es',\n",
       " 'si',\n",
       " 'is',\n",
       " 's.',\n",
       " '.e',\n",
       " 'em',\n",
       " 'mi',\n",
       " 'il',\n",
       " 'li',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.k',\n",
       " 'ke',\n",
       " 'en',\n",
       " 'nn',\n",
       " 'ne',\n",
       " 'ed',\n",
       " 'dy',\n",
       " 'y.',\n",
       " '.s',\n",
       " 'sa',\n",
       " 'am',\n",
       " 'ma',\n",
       " 'an',\n",
       " 'nt',\n",
       " 'th',\n",
       " 'ha',\n",
       " 'a.',\n",
       " '.m',\n",
       " 'ma',\n",
       " 'ay',\n",
       " 'ya',\n",
       " 'a.',\n",
       " '.w',\n",
       " 'wi',\n",
       " 'il',\n",
       " 'll',\n",
       " 'lo',\n",
       " 'ow',\n",
       " 'w.',\n",
       " '.k',\n",
       " 'ki',\n",
       " 'in',\n",
       " 'ns',\n",
       " 'sl',\n",
       " 'le',\n",
       " 'ey',\n",
       " 'y.',\n",
       " '.n',\n",
       " 'na',\n",
       " 'ao',\n",
       " 'om',\n",
       " 'mi',\n",
       " 'i.',\n",
       " '.a',\n",
       " 'aa',\n",
       " 'al',\n",
       " 'li',\n",
       " 'iy',\n",
       " 'ya',\n",
       " 'ah',\n",
       " 'h.',\n",
       " '.e',\n",
       " 'el',\n",
       " 'le',\n",
       " 'en',\n",
       " 'na',\n",
       " 'a.',\n",
       " '.s',\n",
       " 'sa',\n",
       " 'ar',\n",
       " 'ra',\n",
       " 'ah',\n",
       " 'h.',\n",
       " '.a',\n",
       " 'ar',\n",
       " 'ri',\n",
       " 'ia',\n",
       " 'an',\n",
       " 'na',\n",
       " 'a.',\n",
       " '.a',\n",
       " 'al',\n",
       " 'll',\n",
       " 'li',\n",
       " 'is',\n",
       " 'so',\n",
       " 'on',\n",
       " 'n.',\n",
       " '.g',\n",
       " 'ga',\n",
       " 'ab',\n",
       " 'br',\n",
       " 'ri',\n",
       " 'ie',\n",
       " 'el',\n",
       " 'll',\n",
       " 'la',\n",
       " 'a.',\n",
       " '.a',\n",
       " 'al',\n",
       " 'li',\n",
       " 'ic',\n",
       " 'ce',\n",
       " 'e.',\n",
       " '.m',\n",
       " 'ma',\n",
       " 'ad',\n",
       " 'de',\n",
       " 'el',\n",
       " 'ly',\n",
       " 'yn',\n",
       " 'n.',\n",
       " '.c',\n",
       " 'co',\n",
       " 'or',\n",
       " 'ra',\n",
       " 'a.',\n",
       " '.r',\n",
       " 'ru',\n",
       " 'ub',\n",
       " 'by',\n",
       " 'y.',\n",
       " '.e',\n",
       " 'ev',\n",
       " 'va',\n",
       " 'a.',\n",
       " '.s',\n",
       " 'se',\n",
       " 'er',\n",
       " 're',\n",
       " 'en',\n",
       " 'ni',\n",
       " 'it',\n",
       " 'ty',\n",
       " 'y.',\n",
       " '.a',\n",
       " 'au',\n",
       " 'ut',\n",
       " 'tu',\n",
       " 'um',\n",
       " 'mn',\n",
       " 'n.',\n",
       " '.a',\n",
       " 'ad',\n",
       " 'de',\n",
       " 'el',\n",
       " 'li',\n",
       " 'in',\n",
       " 'ne',\n",
       " 'e.',\n",
       " '.h',\n",
       " 'ha',\n",
       " 'ai',\n",
       " 'il',\n",
       " 'le',\n",
       " 'ey',\n",
       " 'y.',\n",
       " '.g',\n",
       " 'gi',\n",
       " 'ia',\n",
       " 'an',\n",
       " 'nn',\n",
       " 'na',\n",
       " 'a.',\n",
       " '.v',\n",
       " 'va',\n",
       " 'al',\n",
       " 'le',\n",
       " 'en',\n",
       " 'nt',\n",
       " 'ti',\n",
       " 'in',\n",
       " 'na',\n",
       " 'a.',\n",
       " '.i',\n",
       " 'is',\n",
       " 'sl',\n",
       " 'la',\n",
       " 'a.',\n",
       " '.e',\n",
       " 'el',\n",
       " 'li',\n",
       " 'ia',\n",
       " 'an',\n",
       " 'na',\n",
       " 'a.',\n",
       " '.q',\n",
       " 'qu',\n",
       " 'ui',\n",
       " 'in',\n",
       " 'nn',\n",
       " 'n.',\n",
       " '.n',\n",
       " 'ne',\n",
       " 'ev',\n",
       " 'va',\n",
       " 'ae',\n",
       " 'eh',\n",
       " 'h.',\n",
       " '.i',\n",
       " 'iv',\n",
       " 'vy',\n",
       " 'y.',\n",
       " '.s',\n",
       " 'sa',\n",
       " 'ad',\n",
       " 'di',\n",
       " 'ie',\n",
       " 'e.',\n",
       " '.p',\n",
       " 'pi',\n",
       " 'ip',\n",
       " 'pe',\n",
       " 'er',\n",
       " 'r.',\n",
       " '.l',\n",
       " 'ly',\n",
       " 'yd',\n",
       " 'di',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.a',\n",
       " 'al',\n",
       " 'le',\n",
       " 'ex',\n",
       " 'xa',\n",
       " 'a.',\n",
       " '.j',\n",
       " 'jo',\n",
       " 'os',\n",
       " 'se',\n",
       " 'ep',\n",
       " 'ph',\n",
       " 'hi',\n",
       " 'in',\n",
       " 'ne',\n",
       " 'e.',\n",
       " '.e',\n",
       " 'em',\n",
       " 'me',\n",
       " 'er',\n",
       " 'ry',\n",
       " 'y.',\n",
       " '.j',\n",
       " 'ju',\n",
       " 'ul',\n",
       " 'li',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.d',\n",
       " 'de',\n",
       " 'el',\n",
       " 'li',\n",
       " 'il',\n",
       " 'la',\n",
       " 'ah',\n",
       " 'h.',\n",
       " '.a',\n",
       " 'ar',\n",
       " 'ri',\n",
       " 'ia',\n",
       " 'an',\n",
       " 'nn',\n",
       " 'na',\n",
       " 'a.',\n",
       " '.v',\n",
       " 'vi',\n",
       " 'iv',\n",
       " 'vi',\n",
       " 'ia',\n",
       " 'an',\n",
       " 'n.',\n",
       " '.k',\n",
       " 'ka',\n",
       " 'ay',\n",
       " 'yl',\n",
       " 'le',\n",
       " 'ee',\n",
       " 'e.',\n",
       " '.s',\n",
       " 'so',\n",
       " 'op',\n",
       " 'ph',\n",
       " 'hi',\n",
       " 'ie',\n",
       " 'e.',\n",
       " '.b',\n",
       " 'br',\n",
       " 'ri',\n",
       " 'ie',\n",
       " 'el',\n",
       " 'll',\n",
       " 'le',\n",
       " 'e.',\n",
       " '.m',\n",
       " 'ma',\n",
       " 'ad',\n",
       " 'de',\n",
       " 'el',\n",
       " 'li',\n",
       " 'in',\n",
       " 'ne',\n",
       " 'e.',\n",
       " '.p',\n",
       " 'pe',\n",
       " 'ey',\n",
       " 'yt',\n",
       " 'to',\n",
       " 'on',\n",
       " 'n.',\n",
       " '.r',\n",
       " 'ry',\n",
       " 'yl',\n",
       " 'le',\n",
       " 'ee',\n",
       " 'e.',\n",
       " '.c',\n",
       " 'cl',\n",
       " 'la',\n",
       " 'ar',\n",
       " 'ra',\n",
       " 'a.',\n",
       " '.h',\n",
       " 'ha',\n",
       " 'ad',\n",
       " 'dl',\n",
       " 'le',\n",
       " 'ey',\n",
       " 'y.',\n",
       " '.m',\n",
       " 'me',\n",
       " 'el',\n",
       " 'la',\n",
       " 'an',\n",
       " 'ni',\n",
       " 'ie',\n",
       " 'e.',\n",
       " '.m',\n",
       " 'ma',\n",
       " 'ac',\n",
       " 'ck',\n",
       " 'ke',\n",
       " 'en',\n",
       " 'nz',\n",
       " 'zi',\n",
       " 'ie',\n",
       " 'e.',\n",
       " '.r',\n",
       " 're',\n",
       " 'ea',\n",
       " 'ag',\n",
       " 'ga',\n",
       " 'an',\n",
       " 'n.',\n",
       " '.a',\n",
       " 'ad',\n",
       " 'da',\n",
       " 'al',\n",
       " 'ly',\n",
       " 'yn',\n",
       " 'nn',\n",
       " 'n.',\n",
       " '.l',\n",
       " 'li',\n",
       " 'il',\n",
       " 'li',\n",
       " 'ia',\n",
       " 'an',\n",
       " 'na',\n",
       " 'a.',\n",
       " '.a',\n",
       " 'au',\n",
       " 'ub',\n",
       " 'br',\n",
       " 're',\n",
       " 'ee',\n",
       " 'e.',\n",
       " '.j',\n",
       " 'ja',\n",
       " 'ad',\n",
       " 'de',\n",
       " 'e.',\n",
       " '.k',\n",
       " 'ka',\n",
       " 'at',\n",
       " 'th',\n",
       " 'he',\n",
       " 'er',\n",
       " 'ri',\n",
       " 'in',\n",
       " 'ne',\n",
       " 'e.',\n",
       " '.i',\n",
       " 'is',\n",
       " 'sa',\n",
       " 'ab',\n",
       " 'be',\n",
       " 'el',\n",
       " 'll',\n",
       " 'le',\n",
       " 'e.',\n",
       " '.n',\n",
       " 'na',\n",
       " 'at',\n",
       " 'ta',\n",
       " 'al',\n",
       " 'li',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.r',\n",
       " 'ra',\n",
       " 'ae',\n",
       " 'el',\n",
       " 'ly',\n",
       " 'yn',\n",
       " 'nn',\n",
       " 'n.',\n",
       " '.m',\n",
       " 'ma',\n",
       " 'ar',\n",
       " 'ri',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.a',\n",
       " 'at',\n",
       " 'th',\n",
       " 'he',\n",
       " 'en',\n",
       " 'na',\n",
       " 'a.',\n",
       " '.x',\n",
       " 'xi',\n",
       " 'im',\n",
       " 'me',\n",
       " 'en',\n",
       " 'na',\n",
       " 'a.',\n",
       " '.a',\n",
       " 'ar',\n",
       " 'ry',\n",
       " 'ya',\n",
       " 'a.',\n",
       " '.l',\n",
       " 'le',\n",
       " 'ei',\n",
       " 'il',\n",
       " 'la',\n",
       " 'an',\n",
       " 'ni',\n",
       " 'i.',\n",
       " '.t',\n",
       " 'ta',\n",
       " 'ay',\n",
       " 'yl',\n",
       " 'lo',\n",
       " 'or',\n",
       " 'r.',\n",
       " '.f',\n",
       " 'fa',\n",
       " 'ai',\n",
       " 'it',\n",
       " 'th',\n",
       " 'h.',\n",
       " '.r',\n",
       " 'ro',\n",
       " 'os',\n",
       " 'se',\n",
       " 'e.',\n",
       " '.k',\n",
       " 'ky',\n",
       " 'yl',\n",
       " 'li',\n",
       " 'ie',\n",
       " 'e.',\n",
       " '.a',\n",
       " 'al',\n",
       " 'le',\n",
       " 'ex',\n",
       " 'xa',\n",
       " 'an',\n",
       " 'nd',\n",
       " 'dr',\n",
       " 'ra',\n",
       " 'a.',\n",
       " '.m',\n",
       " 'ma',\n",
       " 'ar',\n",
       " 'ry',\n",
       " 'y.',\n",
       " '.m',\n",
       " 'ma',\n",
       " 'ar',\n",
       " 'rg',\n",
       " 'ga',\n",
       " 'ar',\n",
       " 're',\n",
       " 'et',\n",
       " 't.',\n",
       " '.l',\n",
       " 'ly',\n",
       " 'yl',\n",
       " 'la',\n",
       " 'a.',\n",
       " '.a',\n",
       " 'as',\n",
       " 'sh',\n",
       " 'hl',\n",
       " 'le',\n",
       " 'ey',\n",
       " 'y.',\n",
       " '.a',\n",
       " 'am',\n",
       " 'ma',\n",
       " 'ay',\n",
       " 'ya',\n",
       " 'a.',\n",
       " '.e',\n",
       " 'el',\n",
       " 'li',\n",
       " 'iz',\n",
       " 'za',\n",
       " 'a.',\n",
       " '.b',\n",
       " 'br',\n",
       " 'ri',\n",
       " 'ia',\n",
       " 'an',\n",
       " 'nn',\n",
       " 'na',\n",
       " 'a.',\n",
       " '.b',\n",
       " 'ba',\n",
       " 'ai',\n",
       " 'il',\n",
       " 'le',\n",
       " 'ey',\n",
       " 'y.',\n",
       " '.a',\n",
       " 'an',\n",
       " 'nd',\n",
       " 'dr',\n",
       " 're',\n",
       " 'ea',\n",
       " 'a.',\n",
       " '.k',\n",
       " 'kh',\n",
       " 'hl',\n",
       " 'lo',\n",
       " 'oe',\n",
       " 'e.',\n",
       " '.j',\n",
       " 'ja',\n",
       " 'as',\n",
       " 'sm',\n",
       " 'mi',\n",
       " 'in',\n",
       " 'ne',\n",
       " 'e.',\n",
       " '.m',\n",
       " 'me',\n",
       " 'el',\n",
       " 'lo',\n",
       " 'od',\n",
       " 'dy',\n",
       " 'y.',\n",
       " '.i',\n",
       " 'ir',\n",
       " 'ri',\n",
       " 'is',\n",
       " 's.',\n",
       " '.i',\n",
       " 'is',\n",
       " 'sa',\n",
       " 'ab',\n",
       " 'be',\n",
       " 'el',\n",
       " 'l.',\n",
       " '.n',\n",
       " 'no',\n",
       " 'or',\n",
       " 'ra',\n",
       " 'ah',\n",
       " 'h.',\n",
       " '.a',\n",
       " 'an',\n",
       " 'nn',\n",
       " 'na',\n",
       " 'ab',\n",
       " 'be',\n",
       " 'el',\n",
       " 'll',\n",
       " 'le',\n",
       " 'e.',\n",
       " '.v',\n",
       " 'va',\n",
       " 'al',\n",
       " 'le',\n",
       " 'er',\n",
       " 'ri',\n",
       " 'ia',\n",
       " 'a.',\n",
       " '.e',\n",
       " 'em',\n",
       " 'me',\n",
       " 'er',\n",
       " 'rs',\n",
       " 'so',\n",
       " 'on',\n",
       " 'n.',\n",
       " '.a',\n",
       " 'ad',\n",
       " 'da',\n",
       " 'al',\n",
       " 'ly',\n",
       " 'yn',\n",
       " 'n.',\n",
       " '.r',\n",
       " 'ry',\n",
       " 'yl',\n",
       " ...]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[char for char in w for w in words]\n",
    "[f'{c}{c1}' for w in words for c, c1 in zip(f'.{w}.', f'.{w}.'[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  5.],\n",
       "        [ 5., 13.],\n",
       "        [13., 13.],\n",
       "        ...,\n",
       "        [25., 26.],\n",
       "        [26., 24.],\n",
       "        [24.,  0.]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs = torch.tensor(\n",
    "    [[stoi[c], stoi[c1]] for w in words for c, c1 in zip(f'.{w}.', f'.{w}.'[1:])]\n",
    ").float()\n",
    "word_pairs\n",
    "# xs = torch.tensor(xs).float()\n",
    "# xs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.],\n",
       "         [ 5.],\n",
       "         [13.],\n",
       "         ...,\n",
       "         [25.],\n",
       "         [26.],\n",
       "         [24.]]),\n",
       " tensor([[ 5.],\n",
       "         [13.],\n",
       "         [13.],\n",
       "         ...,\n",
       "         [26.],\n",
       "         [24.],\n",
       "         [ 0.]]))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = word_pairs[:,:1]\n",
    "ys = word_pairs[:,1:]\n",
    "xs,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = 100\n",
    "predictable_chars = len(letters) + 1\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, predictable_chars),\n",
    "    torch.nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daynil/mambaforge-pypy3/envs/ai-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 27]),\n",
       " tensor([[3.6331e-02, 4.2283e-02, 2.6865e-02,  ..., 6.9518e-02, 4.0645e-02,\n",
       "          4.6356e-02],\n",
       "         [1.2353e-02, 2.9820e-02, 1.5131e-02,  ..., 5.5166e-03, 5.5027e-02,\n",
       "          1.0606e-01],\n",
       "         [3.1652e-04, 4.7240e-03, 6.8943e-04,  ..., 1.7975e-05, 7.4913e-03,\n",
       "          1.3982e-01],\n",
       "         ...,\n",
       "         [5.3601e-07, 1.3013e-04, 2.6604e-06,  ..., 1.3688e-09, 1.5724e-04,\n",
       "          9.4873e-02],\n",
       "         [3.1181e-07, 9.5391e-05, 1.6579e-06,  ..., 6.1497e-10, 1.1272e-04,\n",
       "          9.0825e-02],\n",
       "         [9.2065e-07, 1.7737e-04, 4.2655e-06,  ..., 3.0443e-09, 2.1915e-04,\n",
       "          9.9017e-02]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = model(xs)\n",
    "test_preds.shape, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0695, grad_fn=<MaxBackward1>),\n",
       " tensor([0.0363, 0.0423, 0.0269, 0.0517, 0.0351, 0.0348, 0.0326, 0.0354, 0.0337,\n",
       "         0.0281, 0.0306, 0.0683, 0.0330, 0.0371, 0.0187, 0.0365, 0.0233, 0.0478,\n",
       "         0.0226, 0.0310, 0.0381, 0.0333, 0.0393, 0.0270, 0.0695, 0.0406, 0.0464],\n",
       "        grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds[0].max(), test_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0695, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.0695, 0.2577, 0.5700,  ..., 0.7608, 0.7715, 0.7496],\n",
       "       grad_fn=<MaxBackward0>),\n",
       "indices=tensor([24, 11, 11,  ..., 11, 11, 11]))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228146"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(preds: torch.Tensor):\n",
    "    return (-torch.log(preds.max(dim=1).values).sum()) / test_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2578, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0219, 0.0348, 0.0533, 0.0416, 0.0252, 0.0760, 0.0333, 0.0720, 0.0300,\n",
       "        0.0654, 0.0357, 0.0850, 0.0332, 0.0318, 0.0059, 0.0129, 0.0217, 0.0211,\n",
       "        0.0780, 0.0352, 0.0114, 0.0077, 0.0165, 0.0219, 0.0156, 0.0724, 0.0403],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2794, grad_fn=<DivBackward0>)\n",
      "tensor(0.0179, grad_fn=<DivBackward0>)\n",
      "tensor(0.0165, grad_fn=<DivBackward0>)\n",
      "tensor(0.0154, grad_fn=<DivBackward0>)\n",
      "tensor(0.0143, grad_fn=<DivBackward0>)\n",
      "tensor(0.0134, grad_fn=<DivBackward0>)\n",
      "tensor(0.0126, grad_fn=<DivBackward0>)\n",
      "tensor(0.0119, grad_fn=<DivBackward0>)\n",
      "tensor(0.0113, grad_fn=<DivBackward0>)\n",
      "tensor(0.0107, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hidden_neurons = 100\n",
    "predictable_chars = len(letters) + 1\n",
    "\n",
    "epochs = 10\n",
    "lr = 0.2\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, predictable_chars),\n",
    "    torch.nn.Softmax()\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "\n",
    "def train_step(xb):\n",
    "    preds = model(xb)\n",
    "    loss = loss_fn(preds)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss\n",
    "\n",
    "def valid_step(xb):\n",
    "    preds = model(xb)\n",
    "    loss = loss_fn(preds)\n",
    "    return loss\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss = train_step(xs)\n",
    "    print(loss)\n",
    "    # for batch in dls.train:\n",
    "    #     xb, yb = batch\n",
    "    #     xb = to_bw_flattened(xb)\n",
    "    #     xb, yb = to_torch_tensor(xb, yb)\n",
    "    #     loss, acc = train_step(xb, yb)\n",
    "\n",
    "    # print(f\"Avg loss: {tot_loss / valid_batches}, Avg acc: {tot_acc / valid_batches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinking about it, the above is actually wrong because what I'm calculating loss on doesn't make sense. I'm basically giving it the first letter, then calculating loss on the confidence of whatever it predicts as the second.\n",
    "\n",
    "What I need to do is cross entropy loss - give it the xs and the labels, and calculate cross entropy loss on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.],\n",
       "         [ 5.],\n",
       "         [13.],\n",
       "         ...,\n",
       "         [25.],\n",
       "         [26.],\n",
       "         [24.]]),\n",
       " tensor([[ 5.],\n",
       "         [13.],\n",
       "         [13.],\n",
       "         ...,\n",
       "         [26.],\n",
       "         [24.],\n",
       "         [ 0.]]))"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.],\n",
       "         [ 5.],\n",
       "         [13.],\n",
       "         ...,\n",
       "         [25.],\n",
       "         [26.],\n",
       "         [24.]]),\n",
       " tensor([ 5., 13., 13.,  ..., 26., 24.,  0.]))"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0],\n",
       "        [ 5],\n",
       "        [13],\n",
       "        ...,\n",
       "        [25],\n",
       "        [26],\n",
       "        [24]], dtype=torch.int32)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13,  ..., 25, 26, 24], dtype=torch.int32)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.to(torch.int64).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  ..., 26, 24,  0])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.to(torch.int64).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 1, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(xs.squeeze().to(torch.int64), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 1, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(ys.squeeze().to(torch.int64), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3066, grad_fn=<DivBackward1>)\n",
      "tensor(3.0894, grad_fn=<DivBackward1>)\n",
      "tensor(2.9425, grad_fn=<DivBackward1>)\n",
      "tensor(2.8668, grad_fn=<DivBackward1>)\n",
      "tensor(2.8288, grad_fn=<DivBackward1>)\n",
      "tensor(2.8046, grad_fn=<DivBackward1>)\n",
      "tensor(2.7865, grad_fn=<DivBackward1>)\n",
      "tensor(2.7711, grad_fn=<DivBackward1>)\n",
      "tensor(2.7569, grad_fn=<DivBackward1>)\n",
      "tensor(2.7435, grad_fn=<DivBackward1>)\n",
      "tensor(2.7306, grad_fn=<DivBackward1>)\n",
      "tensor(2.7179, grad_fn=<DivBackward1>)\n",
      "tensor(2.7058, grad_fn=<DivBackward1>)\n",
      "tensor(2.6938, grad_fn=<DivBackward1>)\n",
      "tensor(2.6828, grad_fn=<DivBackward1>)\n",
      "tensor(2.6719, grad_fn=<DivBackward1>)\n",
      "tensor(2.6621, grad_fn=<DivBackward1>)\n",
      "tensor(2.6541, grad_fn=<DivBackward1>)\n",
      "tensor(2.6500, grad_fn=<DivBackward1>)\n",
      "tensor(2.6603, grad_fn=<DivBackward1>)\n",
      "tensor(2.7022, grad_fn=<DivBackward1>)\n",
      "tensor(2.7783, grad_fn=<DivBackward1>)\n",
      "tensor(2.7740, grad_fn=<DivBackward1>)\n",
      "tensor(2.6420, grad_fn=<DivBackward1>)\n",
      "tensor(2.6152, grad_fn=<DivBackward1>)\n",
      "tensor(2.6088, grad_fn=<DivBackward1>)\n",
      "tensor(2.6025, grad_fn=<DivBackward1>)\n",
      "tensor(2.6039, grad_fn=<DivBackward1>)\n",
      "tensor(2.6071, grad_fn=<DivBackward1>)\n",
      "tensor(2.6207, grad_fn=<DivBackward1>)\n",
      "tensor(2.6328, grad_fn=<DivBackward1>)\n",
      "tensor(2.6316, grad_fn=<DivBackward1>)\n",
      "tensor(2.6217, grad_fn=<DivBackward1>)\n",
      "tensor(2.6018, grad_fn=<DivBackward1>)\n",
      "tensor(2.5935, grad_fn=<DivBackward1>)\n",
      "tensor(2.5859, grad_fn=<DivBackward1>)\n",
      "tensor(2.5828, grad_fn=<DivBackward1>)\n",
      "tensor(2.5794, grad_fn=<DivBackward1>)\n",
      "tensor(2.5773, grad_fn=<DivBackward1>)\n",
      "tensor(2.5745, grad_fn=<DivBackward1>)\n",
      "tensor(2.5742, grad_fn=<DivBackward1>)\n",
      "tensor(2.5707, grad_fn=<DivBackward1>)\n",
      "tensor(2.5678, grad_fn=<DivBackward1>)\n",
      "tensor(2.5651, grad_fn=<DivBackward1>)\n",
      "tensor(2.5623, grad_fn=<DivBackward1>)\n",
      "tensor(2.5606, grad_fn=<DivBackward1>)\n",
      "tensor(2.5587, grad_fn=<DivBackward1>)\n",
      "tensor(2.5559, grad_fn=<DivBackward1>)\n",
      "tensor(2.5549, grad_fn=<DivBackward1>)\n",
      "tensor(2.5520, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "hidden_neurons = 100\n",
    "predictable_chars = len(letters) + 1\n",
    "\n",
    "epochs = 50\n",
    "lr = 3\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(27, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, predictable_chars),\n",
    "    # cross entropy loss expects raw unnormalized logits\n",
    "    # torch.nn.Softmax()\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "\n",
    "def train_step(xb, yb):\n",
    "    preds = model(xb)\n",
    "    loss = loss_fn(preds, yb)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss\n",
    "\n",
    "# def valid_step(xb):\n",
    "#     preds = model(xb)\n",
    "#     loss = loss_fn(preds)\n",
    "#     return loss\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss = train_step(\n",
    "        F.one_hot(xs.squeeze().to(torch.int64), 27).float(), \n",
    "        F.one_hot(ys.squeeze().to(torch.int64), 27).float()\n",
    "    )\n",
    "    print(loss)\n",
    "    # for batch in dls.train:\n",
    "    #     xb, yb = batch\n",
    "    #     xb = to_bw_flattened(xb)\n",
    "    #     xb, yb = to_torch_tensor(xb, yb)\n",
    "    #     loss, acc = train_step(xb, yb)\n",
    "\n",
    "    # print(f\"Avg loss: {tot_loss / valid_batches}, Avg acc: {tot_acc / valid_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.6328, -0.0816, -0.4266, -0.3451,  0.4298,  0.1665, -1.5470, -1.0255,\n",
       "         1.2468,  0.7366, -1.3115, -0.2626,  1.4293,  0.8547,  2.3013, -0.5743,\n",
       "        -1.5736, -2.0400,  1.6903,  0.7525,  0.2714, -0.3738,  0.0182, -1.4725,\n",
       "        -1.6215,  1.0940, -0.5529], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_a = torch.zeros(27)\n",
    "letter_a[1] = 1\n",
    "single_pred_logits = model(letter_a)\n",
    "single_pred_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daynil/mambaforge-pypy3/envs/ai-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_pred = torch.nn.Softmax()(single_pred_logits)\n",
    "single_pred.argmax(dim=0)\n",
    "# itos[single_pred.argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keen\n",
      "aely\n",
      "droma\n",
      "lien\n",
      "\n",
      "b\n",
      "miacun\n",
      "ble\n",
      "crtya\n",
      "kin\n",
      "lhrinnyledel\n",
      "wesadalauhaon\n",
      "gevesch\n",
      "pmilipnren\n",
      "anlealtisn\n",
      "com\n",
      "dllslefsi\n",
      "tant\n",
      "ryi\n",
      "san\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "words_to_gen = 20\n",
    "for wi in range(words_to_gen):\n",
    "    # word_len = torch.randint(min(word_lens), max(word_lens), (1,)).item()\n",
    "    # for i in range(int(word_len)):\n",
    "    li = 0\n",
    "    next_letter = ''\n",
    "    genned_word = '.'\n",
    "    while next_letter != '.' and len(genned_word) < max(word_lens):\n",
    "        prior_letter = genned_word[li]\n",
    "        prior_letter_i = stoi[prior_letter]\n",
    "        prior_letter_i_one_hot = F.one_hot(\n",
    "            torch.tensor(prior_letter_i), 27\n",
    "        ).float()\n",
    "\n",
    "        probs = torch.nn.Softmax()(model(prior_letter_i_one_hot))\n",
    "        pred = torch.multinomial(probs, 1, replacement=True).item()\n",
    "        next_letter = itos[int(pred)]\n",
    "\n",
    "        # next_sample_p = P[prior_letter_i]\n",
    "        # next_letter_idx = torch.multinomial(\n",
    "        #         next_sample_p, 1, replacement=True, generator=g\n",
    "        #     ).item()\n",
    "        # next_letter = itos[next_letter_idx]\n",
    "        genned_word += next_letter\n",
    "        li += 1\n",
    "    print(genned_word.strip('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karpathy:\n",
    "Update: I added some suggested exercises to the description of the video. imo learning requires in-person tinkering and work, watching a video is not enough. If you complete the exercises please feel free to link your work here. (+Feel free to suggest other good exercises!)\n",
    "\n",
    "E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?\n",
    "\n",
    "E02: split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?\n",
    "\n",
    "E03: use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?\n",
    "\n",
    "E04: we saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?\n",
    "\n",
    "E05: look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead?\n",
    "\n",
    "E06: meta-exercise! Think of a fun/interesting exercise and complete it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train a trigram language model\n",
    "E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create a new vocab. The neural net wouldn't know what to do with 2 letters passed individually - we can't one hot encode 2 different answers. So to create a trigram, we create a vocab of all possible 2 letter combos with indices.\n",
    "\n",
    "Note that we have to generate this from the alphabet rather than the vocab since we may come up with novel word pairs that didn't exist in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '.']"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letters + ['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'..': 0,\n",
       " '.a': 1,\n",
       " '.b': 2,\n",
       " '.c': 3,\n",
       " '.d': 4,\n",
       " '.e': 5,\n",
       " '.f': 6,\n",
       " '.g': 7,\n",
       " '.h': 8,\n",
       " '.i': 9,\n",
       " '.j': 10,\n",
       " '.k': 11,\n",
       " '.l': 12,\n",
       " '.m': 13,\n",
       " '.n': 14,\n",
       " '.o': 15,\n",
       " '.p': 16,\n",
       " '.q': 17,\n",
       " '.r': 18,\n",
       " '.s': 19,\n",
       " '.t': 20,\n",
       " '.u': 21,\n",
       " '.v': 22,\n",
       " '.w': 23,\n",
       " '.x': 24,\n",
       " '.y': 25,\n",
       " '.z': 26,\n",
       " 'a.': 27,\n",
       " 'aa': 28,\n",
       " 'ab': 29,\n",
       " 'ac': 30,\n",
       " 'ad': 31,\n",
       " 'ae': 32,\n",
       " 'af': 33,\n",
       " 'ag': 34,\n",
       " 'ah': 35,\n",
       " 'ai': 36,\n",
       " 'aj': 37,\n",
       " 'ak': 38,\n",
       " 'al': 39,\n",
       " 'am': 40,\n",
       " 'an': 41,\n",
       " 'ao': 42,\n",
       " 'ap': 43,\n",
       " 'aq': 44,\n",
       " 'ar': 45,\n",
       " 'as': 46,\n",
       " 'at': 47,\n",
       " 'au': 48,\n",
       " 'av': 49,\n",
       " 'aw': 50,\n",
       " 'ax': 51,\n",
       " 'ay': 52,\n",
       " 'az': 53,\n",
       " 'b.': 54,\n",
       " 'ba': 55,\n",
       " 'bb': 56,\n",
       " 'bc': 57,\n",
       " 'bd': 58,\n",
       " 'be': 59,\n",
       " 'bf': 60,\n",
       " 'bg': 61,\n",
       " 'bh': 62,\n",
       " 'bi': 63,\n",
       " 'bj': 64,\n",
       " 'bk': 65,\n",
       " 'bl': 66,\n",
       " 'bm': 67,\n",
       " 'bn': 68,\n",
       " 'bo': 69,\n",
       " 'bp': 70,\n",
       " 'bq': 71,\n",
       " 'br': 72,\n",
       " 'bs': 73,\n",
       " 'bt': 74,\n",
       " 'bu': 75,\n",
       " 'bv': 76,\n",
       " 'bw': 77,\n",
       " 'bx': 78,\n",
       " 'by': 79,\n",
       " 'bz': 80,\n",
       " 'c.': 81,\n",
       " 'ca': 82,\n",
       " 'cb': 83,\n",
       " 'cc': 84,\n",
       " 'cd': 85,\n",
       " 'ce': 86,\n",
       " 'cf': 87,\n",
       " 'cg': 88,\n",
       " 'ch': 89,\n",
       " 'ci': 90,\n",
       " 'cj': 91,\n",
       " 'ck': 92,\n",
       " 'cl': 93,\n",
       " 'cm': 94,\n",
       " 'cn': 95,\n",
       " 'co': 96,\n",
       " 'cp': 97,\n",
       " 'cq': 98,\n",
       " 'cr': 99,\n",
       " 'cs': 100,\n",
       " 'ct': 101,\n",
       " 'cu': 102,\n",
       " 'cv': 103,\n",
       " 'cw': 104,\n",
       " 'cx': 105,\n",
       " 'cy': 106,\n",
       " 'cz': 107,\n",
       " 'd.': 108,\n",
       " 'da': 109,\n",
       " 'db': 110,\n",
       " 'dc': 111,\n",
       " 'dd': 112,\n",
       " 'de': 113,\n",
       " 'df': 114,\n",
       " 'dg': 115,\n",
       " 'dh': 116,\n",
       " 'di': 117,\n",
       " 'dj': 118,\n",
       " 'dk': 119,\n",
       " 'dl': 120,\n",
       " 'dm': 121,\n",
       " 'dn': 122,\n",
       " 'do': 123,\n",
       " 'dp': 124,\n",
       " 'dq': 125,\n",
       " 'dr': 126,\n",
       " 'ds': 127,\n",
       " 'dt': 128,\n",
       " 'du': 129,\n",
       " 'dv': 130,\n",
       " 'dw': 131,\n",
       " 'dx': 132,\n",
       " 'dy': 133,\n",
       " 'dz': 134,\n",
       " 'e.': 135,\n",
       " 'ea': 136,\n",
       " 'eb': 137,\n",
       " 'ec': 138,\n",
       " 'ed': 139,\n",
       " 'ee': 140,\n",
       " 'ef': 141,\n",
       " 'eg': 142,\n",
       " 'eh': 143,\n",
       " 'ei': 144,\n",
       " 'ej': 145,\n",
       " 'ek': 146,\n",
       " 'el': 147,\n",
       " 'em': 148,\n",
       " 'en': 149,\n",
       " 'eo': 150,\n",
       " 'ep': 151,\n",
       " 'eq': 152,\n",
       " 'er': 153,\n",
       " 'es': 154,\n",
       " 'et': 155,\n",
       " 'eu': 156,\n",
       " 'ev': 157,\n",
       " 'ew': 158,\n",
       " 'ex': 159,\n",
       " 'ey': 160,\n",
       " 'ez': 161,\n",
       " 'f.': 162,\n",
       " 'fa': 163,\n",
       " 'fb': 164,\n",
       " 'fc': 165,\n",
       " 'fd': 166,\n",
       " 'fe': 167,\n",
       " 'ff': 168,\n",
       " 'fg': 169,\n",
       " 'fh': 170,\n",
       " 'fi': 171,\n",
       " 'fj': 172,\n",
       " 'fk': 173,\n",
       " 'fl': 174,\n",
       " 'fm': 175,\n",
       " 'fn': 176,\n",
       " 'fo': 177,\n",
       " 'fp': 178,\n",
       " 'fq': 179,\n",
       " 'fr': 180,\n",
       " 'fs': 181,\n",
       " 'ft': 182,\n",
       " 'fu': 183,\n",
       " 'fv': 184,\n",
       " 'fw': 185,\n",
       " 'fx': 186,\n",
       " 'fy': 187,\n",
       " 'fz': 188,\n",
       " 'g.': 189,\n",
       " 'ga': 190,\n",
       " 'gb': 191,\n",
       " 'gc': 192,\n",
       " 'gd': 193,\n",
       " 'ge': 194,\n",
       " 'gf': 195,\n",
       " 'gg': 196,\n",
       " 'gh': 197,\n",
       " 'gi': 198,\n",
       " 'gj': 199,\n",
       " 'gk': 200,\n",
       " 'gl': 201,\n",
       " 'gm': 202,\n",
       " 'gn': 203,\n",
       " 'go': 204,\n",
       " 'gp': 205,\n",
       " 'gq': 206,\n",
       " 'gr': 207,\n",
       " 'gs': 208,\n",
       " 'gt': 209,\n",
       " 'gu': 210,\n",
       " 'gv': 211,\n",
       " 'gw': 212,\n",
       " 'gx': 213,\n",
       " 'gy': 214,\n",
       " 'gz': 215,\n",
       " 'h.': 216,\n",
       " 'ha': 217,\n",
       " 'hb': 218,\n",
       " 'hc': 219,\n",
       " 'hd': 220,\n",
       " 'he': 221,\n",
       " 'hf': 222,\n",
       " 'hg': 223,\n",
       " 'hh': 224,\n",
       " 'hi': 225,\n",
       " 'hj': 226,\n",
       " 'hk': 227,\n",
       " 'hl': 228,\n",
       " 'hm': 229,\n",
       " 'hn': 230,\n",
       " 'ho': 231,\n",
       " 'hp': 232,\n",
       " 'hq': 233,\n",
       " 'hr': 234,\n",
       " 'hs': 235,\n",
       " 'ht': 236,\n",
       " 'hu': 237,\n",
       " 'hv': 238,\n",
       " 'hw': 239,\n",
       " 'hx': 240,\n",
       " 'hy': 241,\n",
       " 'hz': 242,\n",
       " 'i.': 243,\n",
       " 'ia': 244,\n",
       " 'ib': 245,\n",
       " 'ic': 246,\n",
       " 'id': 247,\n",
       " 'ie': 248,\n",
       " 'if': 249,\n",
       " 'ig': 250,\n",
       " 'ih': 251,\n",
       " 'ii': 252,\n",
       " 'ij': 253,\n",
       " 'ik': 254,\n",
       " 'il': 255,\n",
       " 'im': 256,\n",
       " 'in': 257,\n",
       " 'io': 258,\n",
       " 'ip': 259,\n",
       " 'iq': 260,\n",
       " 'ir': 261,\n",
       " 'is': 262,\n",
       " 'it': 263,\n",
       " 'iu': 264,\n",
       " 'iv': 265,\n",
       " 'iw': 266,\n",
       " 'ix': 267,\n",
       " 'iy': 268,\n",
       " 'iz': 269,\n",
       " 'j.': 270,\n",
       " 'ja': 271,\n",
       " 'jb': 272,\n",
       " 'jc': 273,\n",
       " 'jd': 274,\n",
       " 'je': 275,\n",
       " 'jf': 276,\n",
       " 'jg': 277,\n",
       " 'jh': 278,\n",
       " 'ji': 279,\n",
       " 'jj': 280,\n",
       " 'jk': 281,\n",
       " 'jl': 282,\n",
       " 'jm': 283,\n",
       " 'jn': 284,\n",
       " 'jo': 285,\n",
       " 'jp': 286,\n",
       " 'jq': 287,\n",
       " 'jr': 288,\n",
       " 'js': 289,\n",
       " 'jt': 290,\n",
       " 'ju': 291,\n",
       " 'jv': 292,\n",
       " 'jw': 293,\n",
       " 'jx': 294,\n",
       " 'jy': 295,\n",
       " 'jz': 296,\n",
       " 'k.': 297,\n",
       " 'ka': 298,\n",
       " 'kb': 299,\n",
       " 'kc': 300,\n",
       " 'kd': 301,\n",
       " 'ke': 302,\n",
       " 'kf': 303,\n",
       " 'kg': 304,\n",
       " 'kh': 305,\n",
       " 'ki': 306,\n",
       " 'kj': 307,\n",
       " 'kk': 308,\n",
       " 'kl': 309,\n",
       " 'km': 310,\n",
       " 'kn': 311,\n",
       " 'ko': 312,\n",
       " 'kp': 313,\n",
       " 'kq': 314,\n",
       " 'kr': 315,\n",
       " 'ks': 316,\n",
       " 'kt': 317,\n",
       " 'ku': 318,\n",
       " 'kv': 319,\n",
       " 'kw': 320,\n",
       " 'kx': 321,\n",
       " 'ky': 322,\n",
       " 'kz': 323,\n",
       " 'l.': 324,\n",
       " 'la': 325,\n",
       " 'lb': 326,\n",
       " 'lc': 327,\n",
       " 'ld': 328,\n",
       " 'le': 329,\n",
       " 'lf': 330,\n",
       " 'lg': 331,\n",
       " 'lh': 332,\n",
       " 'li': 333,\n",
       " 'lj': 334,\n",
       " 'lk': 335,\n",
       " 'll': 336,\n",
       " 'lm': 337,\n",
       " 'ln': 338,\n",
       " 'lo': 339,\n",
       " 'lp': 340,\n",
       " 'lq': 341,\n",
       " 'lr': 342,\n",
       " 'ls': 343,\n",
       " 'lt': 344,\n",
       " 'lu': 345,\n",
       " 'lv': 346,\n",
       " 'lw': 347,\n",
       " 'lx': 348,\n",
       " 'ly': 349,\n",
       " 'lz': 350,\n",
       " 'm.': 351,\n",
       " 'ma': 352,\n",
       " 'mb': 353,\n",
       " 'mc': 354,\n",
       " 'md': 355,\n",
       " 'me': 356,\n",
       " 'mf': 357,\n",
       " 'mg': 358,\n",
       " 'mh': 359,\n",
       " 'mi': 360,\n",
       " 'mj': 361,\n",
       " 'mk': 362,\n",
       " 'ml': 363,\n",
       " 'mm': 364,\n",
       " 'mn': 365,\n",
       " 'mo': 366,\n",
       " 'mp': 367,\n",
       " 'mq': 368,\n",
       " 'mr': 369,\n",
       " 'ms': 370,\n",
       " 'mt': 371,\n",
       " 'mu': 372,\n",
       " 'mv': 373,\n",
       " 'mw': 374,\n",
       " 'mx': 375,\n",
       " 'my': 376,\n",
       " 'mz': 377,\n",
       " 'n.': 378,\n",
       " 'na': 379,\n",
       " 'nb': 380,\n",
       " 'nc': 381,\n",
       " 'nd': 382,\n",
       " 'ne': 383,\n",
       " 'nf': 384,\n",
       " 'ng': 385,\n",
       " 'nh': 386,\n",
       " 'ni': 387,\n",
       " 'nj': 388,\n",
       " 'nk': 389,\n",
       " 'nl': 390,\n",
       " 'nm': 391,\n",
       " 'nn': 392,\n",
       " 'no': 393,\n",
       " 'np': 394,\n",
       " 'nq': 395,\n",
       " 'nr': 396,\n",
       " 'ns': 397,\n",
       " 'nt': 398,\n",
       " 'nu': 399,\n",
       " 'nv': 400,\n",
       " 'nw': 401,\n",
       " 'nx': 402,\n",
       " 'ny': 403,\n",
       " 'nz': 404,\n",
       " 'o.': 405,\n",
       " 'oa': 406,\n",
       " 'ob': 407,\n",
       " 'oc': 408,\n",
       " 'od': 409,\n",
       " 'oe': 410,\n",
       " 'of': 411,\n",
       " 'og': 412,\n",
       " 'oh': 413,\n",
       " 'oi': 414,\n",
       " 'oj': 415,\n",
       " 'ok': 416,\n",
       " 'ol': 417,\n",
       " 'om': 418,\n",
       " 'on': 419,\n",
       " 'oo': 420,\n",
       " 'op': 421,\n",
       " 'oq': 422,\n",
       " 'or': 423,\n",
       " 'os': 424,\n",
       " 'ot': 425,\n",
       " 'ou': 426,\n",
       " 'ov': 427,\n",
       " 'ow': 428,\n",
       " 'ox': 429,\n",
       " 'oy': 430,\n",
       " 'oz': 431,\n",
       " 'p.': 432,\n",
       " 'pa': 433,\n",
       " 'pb': 434,\n",
       " 'pc': 435,\n",
       " 'pd': 436,\n",
       " 'pe': 437,\n",
       " 'pf': 438,\n",
       " 'pg': 439,\n",
       " 'ph': 440,\n",
       " 'pi': 441,\n",
       " 'pj': 442,\n",
       " 'pk': 443,\n",
       " 'pl': 444,\n",
       " 'pm': 445,\n",
       " 'pn': 446,\n",
       " 'po': 447,\n",
       " 'pp': 448,\n",
       " 'pq': 449,\n",
       " 'pr': 450,\n",
       " 'ps': 451,\n",
       " 'pt': 452,\n",
       " 'pu': 453,\n",
       " 'pv': 454,\n",
       " 'pw': 455,\n",
       " 'px': 456,\n",
       " 'py': 457,\n",
       " 'pz': 458,\n",
       " 'q.': 459,\n",
       " 'qa': 460,\n",
       " 'qb': 461,\n",
       " 'qc': 462,\n",
       " 'qd': 463,\n",
       " 'qe': 464,\n",
       " 'qf': 465,\n",
       " 'qg': 466,\n",
       " 'qh': 467,\n",
       " 'qi': 468,\n",
       " 'qj': 469,\n",
       " 'qk': 470,\n",
       " 'ql': 471,\n",
       " 'qm': 472,\n",
       " 'qn': 473,\n",
       " 'qo': 474,\n",
       " 'qp': 475,\n",
       " 'qq': 476,\n",
       " 'qr': 477,\n",
       " 'qs': 478,\n",
       " 'qt': 479,\n",
       " 'qu': 480,\n",
       " 'qv': 481,\n",
       " 'qw': 482,\n",
       " 'qx': 483,\n",
       " 'qy': 484,\n",
       " 'qz': 485,\n",
       " 'r.': 486,\n",
       " 'ra': 487,\n",
       " 'rb': 488,\n",
       " 'rc': 489,\n",
       " 'rd': 490,\n",
       " 're': 491,\n",
       " 'rf': 492,\n",
       " 'rg': 493,\n",
       " 'rh': 494,\n",
       " 'ri': 495,\n",
       " 'rj': 496,\n",
       " 'rk': 497,\n",
       " 'rl': 498,\n",
       " 'rm': 499,\n",
       " 'rn': 500,\n",
       " 'ro': 501,\n",
       " 'rp': 502,\n",
       " 'rq': 503,\n",
       " 'rr': 504,\n",
       " 'rs': 505,\n",
       " 'rt': 506,\n",
       " 'ru': 507,\n",
       " 'rv': 508,\n",
       " 'rw': 509,\n",
       " 'rx': 510,\n",
       " 'ry': 511,\n",
       " 'rz': 512,\n",
       " 's.': 513,\n",
       " 'sa': 514,\n",
       " 'sb': 515,\n",
       " 'sc': 516,\n",
       " 'sd': 517,\n",
       " 'se': 518,\n",
       " 'sf': 519,\n",
       " 'sg': 520,\n",
       " 'sh': 521,\n",
       " 'si': 522,\n",
       " 'sj': 523,\n",
       " 'sk': 524,\n",
       " 'sl': 525,\n",
       " 'sm': 526,\n",
       " 'sn': 527,\n",
       " 'so': 528,\n",
       " 'sp': 529,\n",
       " 'sq': 530,\n",
       " 'sr': 531,\n",
       " 'ss': 532,\n",
       " 'st': 533,\n",
       " 'su': 534,\n",
       " 'sv': 535,\n",
       " 'sw': 536,\n",
       " 'sx': 537,\n",
       " 'sy': 538,\n",
       " 'sz': 539,\n",
       " 't.': 540,\n",
       " 'ta': 541,\n",
       " 'tb': 542,\n",
       " 'tc': 543,\n",
       " 'td': 544,\n",
       " 'te': 545,\n",
       " 'tf': 546,\n",
       " 'tg': 547,\n",
       " 'th': 548,\n",
       " 'ti': 549,\n",
       " 'tj': 550,\n",
       " 'tk': 551,\n",
       " 'tl': 552,\n",
       " 'tm': 553,\n",
       " 'tn': 554,\n",
       " 'to': 555,\n",
       " 'tp': 556,\n",
       " 'tq': 557,\n",
       " 'tr': 558,\n",
       " 'ts': 559,\n",
       " 'tt': 560,\n",
       " 'tu': 561,\n",
       " 'tv': 562,\n",
       " 'tw': 563,\n",
       " 'tx': 564,\n",
       " 'ty': 565,\n",
       " 'tz': 566,\n",
       " 'u.': 567,\n",
       " 'ua': 568,\n",
       " 'ub': 569,\n",
       " 'uc': 570,\n",
       " 'ud': 571,\n",
       " 'ue': 572,\n",
       " 'uf': 573,\n",
       " 'ug': 574,\n",
       " 'uh': 575,\n",
       " 'ui': 576,\n",
       " 'uj': 577,\n",
       " 'uk': 578,\n",
       " 'ul': 579,\n",
       " 'um': 580,\n",
       " 'un': 581,\n",
       " 'uo': 582,\n",
       " 'up': 583,\n",
       " 'uq': 584,\n",
       " 'ur': 585,\n",
       " 'us': 586,\n",
       " 'ut': 587,\n",
       " 'uu': 588,\n",
       " 'uv': 589,\n",
       " 'uw': 590,\n",
       " 'ux': 591,\n",
       " 'uy': 592,\n",
       " 'uz': 593,\n",
       " 'v.': 594,\n",
       " 'va': 595,\n",
       " 'vb': 596,\n",
       " 'vc': 597,\n",
       " 'vd': 598,\n",
       " 've': 599,\n",
       " 'vf': 600,\n",
       " 'vg': 601,\n",
       " 'vh': 602,\n",
       " 'vi': 603,\n",
       " 'vj': 604,\n",
       " 'vk': 605,\n",
       " 'vl': 606,\n",
       " 'vm': 607,\n",
       " 'vn': 608,\n",
       " 'vo': 609,\n",
       " 'vp': 610,\n",
       " 'vq': 611,\n",
       " 'vr': 612,\n",
       " 'vs': 613,\n",
       " 'vt': 614,\n",
       " 'vu': 615,\n",
       " 'vv': 616,\n",
       " 'vw': 617,\n",
       " 'vx': 618,\n",
       " 'vy': 619,\n",
       " 'vz': 620,\n",
       " 'w.': 621,\n",
       " 'wa': 622,\n",
       " 'wb': 623,\n",
       " 'wc': 624,\n",
       " 'wd': 625,\n",
       " 'we': 626,\n",
       " 'wf': 627,\n",
       " 'wg': 628,\n",
       " 'wh': 629,\n",
       " 'wi': 630,\n",
       " 'wj': 631,\n",
       " 'wk': 632,\n",
       " 'wl': 633,\n",
       " 'wm': 634,\n",
       " 'wn': 635,\n",
       " 'wo': 636,\n",
       " 'wp': 637,\n",
       " 'wq': 638,\n",
       " 'wr': 639,\n",
       " 'ws': 640,\n",
       " 'wt': 641,\n",
       " 'wu': 642,\n",
       " 'wv': 643,\n",
       " 'ww': 644,\n",
       " 'wx': 645,\n",
       " 'wy': 646,\n",
       " 'wz': 647,\n",
       " 'x.': 648,\n",
       " 'xa': 649,\n",
       " 'xb': 650,\n",
       " 'xc': 651,\n",
       " 'xd': 652,\n",
       " 'xe': 653,\n",
       " 'xf': 654,\n",
       " 'xg': 655,\n",
       " 'xh': 656,\n",
       " 'xi': 657,\n",
       " 'xj': 658,\n",
       " 'xk': 659,\n",
       " 'xl': 660,\n",
       " 'xm': 661,\n",
       " 'xn': 662,\n",
       " 'xo': 663,\n",
       " 'xp': 664,\n",
       " 'xq': 665,\n",
       " 'xr': 666,\n",
       " 'xs': 667,\n",
       " 'xt': 668,\n",
       " 'xu': 669,\n",
       " 'xv': 670,\n",
       " 'xw': 671,\n",
       " 'xx': 672,\n",
       " 'xy': 673,\n",
       " 'xz': 674,\n",
       " 'y.': 675,\n",
       " 'ya': 676,\n",
       " 'yb': 677,\n",
       " 'yc': 678,\n",
       " 'yd': 679,\n",
       " 'ye': 680,\n",
       " 'yf': 681,\n",
       " 'yg': 682,\n",
       " 'yh': 683,\n",
       " 'yi': 684,\n",
       " 'yj': 685,\n",
       " 'yk': 686,\n",
       " 'yl': 687,\n",
       " 'ym': 688,\n",
       " 'yn': 689,\n",
       " 'yo': 690,\n",
       " 'yp': 691,\n",
       " 'yq': 692,\n",
       " 'yr': 693,\n",
       " 'ys': 694,\n",
       " 'yt': 695,\n",
       " 'yu': 696,\n",
       " 'yv': 697,\n",
       " 'yw': 698,\n",
       " 'yx': 699,\n",
       " 'yy': 700,\n",
       " 'yz': 701,\n",
       " 'z.': 702,\n",
       " 'za': 703,\n",
       " 'zb': 704,\n",
       " 'zc': 705,\n",
       " 'zd': 706,\n",
       " 'ze': 707,\n",
       " 'zf': 708,\n",
       " 'zg': 709,\n",
       " 'zh': 710,\n",
       " 'zi': 711,\n",
       " 'zj': 712,\n",
       " 'zk': 713,\n",
       " 'zl': 714,\n",
       " 'zm': 715,\n",
       " 'zn': 716,\n",
       " 'zo': 717,\n",
       " 'zp': 718,\n",
       " 'zq': 719,\n",
       " 'zr': 720,\n",
       " 'zs': 721,\n",
       " 'zt': 722,\n",
       " 'zu': 723,\n",
       " 'zv': 724,\n",
       " 'zw': 725,\n",
       " 'zx': 726,\n",
       " 'zy': 727,\n",
       " 'zz': 728}"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = []\n",
    "for l in letters + ['.']:\n",
    "    for l2 in letters + ['.']:\n",
    "        pair = l + l2\n",
    "        pairs.append(pair)\n",
    "\n",
    "pairs = sorted(pairs)\n",
    "ptoi = {p:i for i, p in enumerate(pairs)}\n",
    "ptoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '..',\n",
       " 1: '.a',\n",
       " 2: '.b',\n",
       " 3: '.c',\n",
       " 4: '.d',\n",
       " 5: '.e',\n",
       " 6: '.f',\n",
       " 7: '.g',\n",
       " 8: '.h',\n",
       " 9: '.i',\n",
       " 10: '.j',\n",
       " 11: '.k',\n",
       " 12: '.l',\n",
       " 13: '.m',\n",
       " 14: '.n',\n",
       " 15: '.o',\n",
       " 16: '.p',\n",
       " 17: '.q',\n",
       " 18: '.r',\n",
       " 19: '.s',\n",
       " 20: '.t',\n",
       " 21: '.u',\n",
       " 22: '.v',\n",
       " 23: '.w',\n",
       " 24: '.x',\n",
       " 25: '.y',\n",
       " 26: '.z',\n",
       " 27: 'a.',\n",
       " 28: 'aa',\n",
       " 29: 'ab',\n",
       " 30: 'ac',\n",
       " 31: 'ad',\n",
       " 32: 'ae',\n",
       " 33: 'af',\n",
       " 34: 'ag',\n",
       " 35: 'ah',\n",
       " 36: 'ai',\n",
       " 37: 'aj',\n",
       " 38: 'ak',\n",
       " 39: 'al',\n",
       " 40: 'am',\n",
       " 41: 'an',\n",
       " 42: 'ao',\n",
       " 43: 'ap',\n",
       " 44: 'aq',\n",
       " 45: 'ar',\n",
       " 46: 'as',\n",
       " 47: 'at',\n",
       " 48: 'au',\n",
       " 49: 'av',\n",
       " 50: 'aw',\n",
       " 51: 'ax',\n",
       " 52: 'ay',\n",
       " 53: 'az',\n",
       " 54: 'b.',\n",
       " 55: 'ba',\n",
       " 56: 'bb',\n",
       " 57: 'bc',\n",
       " 58: 'bd',\n",
       " 59: 'be',\n",
       " 60: 'bf',\n",
       " 61: 'bg',\n",
       " 62: 'bh',\n",
       " 63: 'bi',\n",
       " 64: 'bj',\n",
       " 65: 'bk',\n",
       " 66: 'bl',\n",
       " 67: 'bm',\n",
       " 68: 'bn',\n",
       " 69: 'bo',\n",
       " 70: 'bp',\n",
       " 71: 'bq',\n",
       " 72: 'br',\n",
       " 73: 'bs',\n",
       " 74: 'bt',\n",
       " 75: 'bu',\n",
       " 76: 'bv',\n",
       " 77: 'bw',\n",
       " 78: 'bx',\n",
       " 79: 'by',\n",
       " 80: 'bz',\n",
       " 81: 'c.',\n",
       " 82: 'ca',\n",
       " 83: 'cb',\n",
       " 84: 'cc',\n",
       " 85: 'cd',\n",
       " 86: 'ce',\n",
       " 87: 'cf',\n",
       " 88: 'cg',\n",
       " 89: 'ch',\n",
       " 90: 'ci',\n",
       " 91: 'cj',\n",
       " 92: 'ck',\n",
       " 93: 'cl',\n",
       " 94: 'cm',\n",
       " 95: 'cn',\n",
       " 96: 'co',\n",
       " 97: 'cp',\n",
       " 98: 'cq',\n",
       " 99: 'cr',\n",
       " 100: 'cs',\n",
       " 101: 'ct',\n",
       " 102: 'cu',\n",
       " 103: 'cv',\n",
       " 104: 'cw',\n",
       " 105: 'cx',\n",
       " 106: 'cy',\n",
       " 107: 'cz',\n",
       " 108: 'd.',\n",
       " 109: 'da',\n",
       " 110: 'db',\n",
       " 111: 'dc',\n",
       " 112: 'dd',\n",
       " 113: 'de',\n",
       " 114: 'df',\n",
       " 115: 'dg',\n",
       " 116: 'dh',\n",
       " 117: 'di',\n",
       " 118: 'dj',\n",
       " 119: 'dk',\n",
       " 120: 'dl',\n",
       " 121: 'dm',\n",
       " 122: 'dn',\n",
       " 123: 'do',\n",
       " 124: 'dp',\n",
       " 125: 'dq',\n",
       " 126: 'dr',\n",
       " 127: 'ds',\n",
       " 128: 'dt',\n",
       " 129: 'du',\n",
       " 130: 'dv',\n",
       " 131: 'dw',\n",
       " 132: 'dx',\n",
       " 133: 'dy',\n",
       " 134: 'dz',\n",
       " 135: 'e.',\n",
       " 136: 'ea',\n",
       " 137: 'eb',\n",
       " 138: 'ec',\n",
       " 139: 'ed',\n",
       " 140: 'ee',\n",
       " 141: 'ef',\n",
       " 142: 'eg',\n",
       " 143: 'eh',\n",
       " 144: 'ei',\n",
       " 145: 'ej',\n",
       " 146: 'ek',\n",
       " 147: 'el',\n",
       " 148: 'em',\n",
       " 149: 'en',\n",
       " 150: 'eo',\n",
       " 151: 'ep',\n",
       " 152: 'eq',\n",
       " 153: 'er',\n",
       " 154: 'es',\n",
       " 155: 'et',\n",
       " 156: 'eu',\n",
       " 157: 'ev',\n",
       " 158: 'ew',\n",
       " 159: 'ex',\n",
       " 160: 'ey',\n",
       " 161: 'ez',\n",
       " 162: 'f.',\n",
       " 163: 'fa',\n",
       " 164: 'fb',\n",
       " 165: 'fc',\n",
       " 166: 'fd',\n",
       " 167: 'fe',\n",
       " 168: 'ff',\n",
       " 169: 'fg',\n",
       " 170: 'fh',\n",
       " 171: 'fi',\n",
       " 172: 'fj',\n",
       " 173: 'fk',\n",
       " 174: 'fl',\n",
       " 175: 'fm',\n",
       " 176: 'fn',\n",
       " 177: 'fo',\n",
       " 178: 'fp',\n",
       " 179: 'fq',\n",
       " 180: 'fr',\n",
       " 181: 'fs',\n",
       " 182: 'ft',\n",
       " 183: 'fu',\n",
       " 184: 'fv',\n",
       " 185: 'fw',\n",
       " 186: 'fx',\n",
       " 187: 'fy',\n",
       " 188: 'fz',\n",
       " 189: 'g.',\n",
       " 190: 'ga',\n",
       " 191: 'gb',\n",
       " 192: 'gc',\n",
       " 193: 'gd',\n",
       " 194: 'ge',\n",
       " 195: 'gf',\n",
       " 196: 'gg',\n",
       " 197: 'gh',\n",
       " 198: 'gi',\n",
       " 199: 'gj',\n",
       " 200: 'gk',\n",
       " 201: 'gl',\n",
       " 202: 'gm',\n",
       " 203: 'gn',\n",
       " 204: 'go',\n",
       " 205: 'gp',\n",
       " 206: 'gq',\n",
       " 207: 'gr',\n",
       " 208: 'gs',\n",
       " 209: 'gt',\n",
       " 210: 'gu',\n",
       " 211: 'gv',\n",
       " 212: 'gw',\n",
       " 213: 'gx',\n",
       " 214: 'gy',\n",
       " 215: 'gz',\n",
       " 216: 'h.',\n",
       " 217: 'ha',\n",
       " 218: 'hb',\n",
       " 219: 'hc',\n",
       " 220: 'hd',\n",
       " 221: 'he',\n",
       " 222: 'hf',\n",
       " 223: 'hg',\n",
       " 224: 'hh',\n",
       " 225: 'hi',\n",
       " 226: 'hj',\n",
       " 227: 'hk',\n",
       " 228: 'hl',\n",
       " 229: 'hm',\n",
       " 230: 'hn',\n",
       " 231: 'ho',\n",
       " 232: 'hp',\n",
       " 233: 'hq',\n",
       " 234: 'hr',\n",
       " 235: 'hs',\n",
       " 236: 'ht',\n",
       " 237: 'hu',\n",
       " 238: 'hv',\n",
       " 239: 'hw',\n",
       " 240: 'hx',\n",
       " 241: 'hy',\n",
       " 242: 'hz',\n",
       " 243: 'i.',\n",
       " 244: 'ia',\n",
       " 245: 'ib',\n",
       " 246: 'ic',\n",
       " 247: 'id',\n",
       " 248: 'ie',\n",
       " 249: 'if',\n",
       " 250: 'ig',\n",
       " 251: 'ih',\n",
       " 252: 'ii',\n",
       " 253: 'ij',\n",
       " 254: 'ik',\n",
       " 255: 'il',\n",
       " 256: 'im',\n",
       " 257: 'in',\n",
       " 258: 'io',\n",
       " 259: 'ip',\n",
       " 260: 'iq',\n",
       " 261: 'ir',\n",
       " 262: 'is',\n",
       " 263: 'it',\n",
       " 264: 'iu',\n",
       " 265: 'iv',\n",
       " 266: 'iw',\n",
       " 267: 'ix',\n",
       " 268: 'iy',\n",
       " 269: 'iz',\n",
       " 270: 'j.',\n",
       " 271: 'ja',\n",
       " 272: 'jb',\n",
       " 273: 'jc',\n",
       " 274: 'jd',\n",
       " 275: 'je',\n",
       " 276: 'jf',\n",
       " 277: 'jg',\n",
       " 278: 'jh',\n",
       " 279: 'ji',\n",
       " 280: 'jj',\n",
       " 281: 'jk',\n",
       " 282: 'jl',\n",
       " 283: 'jm',\n",
       " 284: 'jn',\n",
       " 285: 'jo',\n",
       " 286: 'jp',\n",
       " 287: 'jq',\n",
       " 288: 'jr',\n",
       " 289: 'js',\n",
       " 290: 'jt',\n",
       " 291: 'ju',\n",
       " 292: 'jv',\n",
       " 293: 'jw',\n",
       " 294: 'jx',\n",
       " 295: 'jy',\n",
       " 296: 'jz',\n",
       " 297: 'k.',\n",
       " 298: 'ka',\n",
       " 299: 'kb',\n",
       " 300: 'kc',\n",
       " 301: 'kd',\n",
       " 302: 'ke',\n",
       " 303: 'kf',\n",
       " 304: 'kg',\n",
       " 305: 'kh',\n",
       " 306: 'ki',\n",
       " 307: 'kj',\n",
       " 308: 'kk',\n",
       " 309: 'kl',\n",
       " 310: 'km',\n",
       " 311: 'kn',\n",
       " 312: 'ko',\n",
       " 313: 'kp',\n",
       " 314: 'kq',\n",
       " 315: 'kr',\n",
       " 316: 'ks',\n",
       " 317: 'kt',\n",
       " 318: 'ku',\n",
       " 319: 'kv',\n",
       " 320: 'kw',\n",
       " 321: 'kx',\n",
       " 322: 'ky',\n",
       " 323: 'kz',\n",
       " 324: 'l.',\n",
       " 325: 'la',\n",
       " 326: 'lb',\n",
       " 327: 'lc',\n",
       " 328: 'ld',\n",
       " 329: 'le',\n",
       " 330: 'lf',\n",
       " 331: 'lg',\n",
       " 332: 'lh',\n",
       " 333: 'li',\n",
       " 334: 'lj',\n",
       " 335: 'lk',\n",
       " 336: 'll',\n",
       " 337: 'lm',\n",
       " 338: 'ln',\n",
       " 339: 'lo',\n",
       " 340: 'lp',\n",
       " 341: 'lq',\n",
       " 342: 'lr',\n",
       " 343: 'ls',\n",
       " 344: 'lt',\n",
       " 345: 'lu',\n",
       " 346: 'lv',\n",
       " 347: 'lw',\n",
       " 348: 'lx',\n",
       " 349: 'ly',\n",
       " 350: 'lz',\n",
       " 351: 'm.',\n",
       " 352: 'ma',\n",
       " 353: 'mb',\n",
       " 354: 'mc',\n",
       " 355: 'md',\n",
       " 356: 'me',\n",
       " 357: 'mf',\n",
       " 358: 'mg',\n",
       " 359: 'mh',\n",
       " 360: 'mi',\n",
       " 361: 'mj',\n",
       " 362: 'mk',\n",
       " 363: 'ml',\n",
       " 364: 'mm',\n",
       " 365: 'mn',\n",
       " 366: 'mo',\n",
       " 367: 'mp',\n",
       " 368: 'mq',\n",
       " 369: 'mr',\n",
       " 370: 'ms',\n",
       " 371: 'mt',\n",
       " 372: 'mu',\n",
       " 373: 'mv',\n",
       " 374: 'mw',\n",
       " 375: 'mx',\n",
       " 376: 'my',\n",
       " 377: 'mz',\n",
       " 378: 'n.',\n",
       " 379: 'na',\n",
       " 380: 'nb',\n",
       " 381: 'nc',\n",
       " 382: 'nd',\n",
       " 383: 'ne',\n",
       " 384: 'nf',\n",
       " 385: 'ng',\n",
       " 386: 'nh',\n",
       " 387: 'ni',\n",
       " 388: 'nj',\n",
       " 389: 'nk',\n",
       " 390: 'nl',\n",
       " 391: 'nm',\n",
       " 392: 'nn',\n",
       " 393: 'no',\n",
       " 394: 'np',\n",
       " 395: 'nq',\n",
       " 396: 'nr',\n",
       " 397: 'ns',\n",
       " 398: 'nt',\n",
       " 399: 'nu',\n",
       " 400: 'nv',\n",
       " 401: 'nw',\n",
       " 402: 'nx',\n",
       " 403: 'ny',\n",
       " 404: 'nz',\n",
       " 405: 'o.',\n",
       " 406: 'oa',\n",
       " 407: 'ob',\n",
       " 408: 'oc',\n",
       " 409: 'od',\n",
       " 410: 'oe',\n",
       " 411: 'of',\n",
       " 412: 'og',\n",
       " 413: 'oh',\n",
       " 414: 'oi',\n",
       " 415: 'oj',\n",
       " 416: 'ok',\n",
       " 417: 'ol',\n",
       " 418: 'om',\n",
       " 419: 'on',\n",
       " 420: 'oo',\n",
       " 421: 'op',\n",
       " 422: 'oq',\n",
       " 423: 'or',\n",
       " 424: 'os',\n",
       " 425: 'ot',\n",
       " 426: 'ou',\n",
       " 427: 'ov',\n",
       " 428: 'ow',\n",
       " 429: 'ox',\n",
       " 430: 'oy',\n",
       " 431: 'oz',\n",
       " 432: 'p.',\n",
       " 433: 'pa',\n",
       " 434: 'pb',\n",
       " 435: 'pc',\n",
       " 436: 'pd',\n",
       " 437: 'pe',\n",
       " 438: 'pf',\n",
       " 439: 'pg',\n",
       " 440: 'ph',\n",
       " 441: 'pi',\n",
       " 442: 'pj',\n",
       " 443: 'pk',\n",
       " 444: 'pl',\n",
       " 445: 'pm',\n",
       " 446: 'pn',\n",
       " 447: 'po',\n",
       " 448: 'pp',\n",
       " 449: 'pq',\n",
       " 450: 'pr',\n",
       " 451: 'ps',\n",
       " 452: 'pt',\n",
       " 453: 'pu',\n",
       " 454: 'pv',\n",
       " 455: 'pw',\n",
       " 456: 'px',\n",
       " 457: 'py',\n",
       " 458: 'pz',\n",
       " 459: 'q.',\n",
       " 460: 'qa',\n",
       " 461: 'qb',\n",
       " 462: 'qc',\n",
       " 463: 'qd',\n",
       " 464: 'qe',\n",
       " 465: 'qf',\n",
       " 466: 'qg',\n",
       " 467: 'qh',\n",
       " 468: 'qi',\n",
       " 469: 'qj',\n",
       " 470: 'qk',\n",
       " 471: 'ql',\n",
       " 472: 'qm',\n",
       " 473: 'qn',\n",
       " 474: 'qo',\n",
       " 475: 'qp',\n",
       " 476: 'qq',\n",
       " 477: 'qr',\n",
       " 478: 'qs',\n",
       " 479: 'qt',\n",
       " 480: 'qu',\n",
       " 481: 'qv',\n",
       " 482: 'qw',\n",
       " 483: 'qx',\n",
       " 484: 'qy',\n",
       " 485: 'qz',\n",
       " 486: 'r.',\n",
       " 487: 'ra',\n",
       " 488: 'rb',\n",
       " 489: 'rc',\n",
       " 490: 'rd',\n",
       " 491: 're',\n",
       " 492: 'rf',\n",
       " 493: 'rg',\n",
       " 494: 'rh',\n",
       " 495: 'ri',\n",
       " 496: 'rj',\n",
       " 497: 'rk',\n",
       " 498: 'rl',\n",
       " 499: 'rm',\n",
       " 500: 'rn',\n",
       " 501: 'ro',\n",
       " 502: 'rp',\n",
       " 503: 'rq',\n",
       " 504: 'rr',\n",
       " 505: 'rs',\n",
       " 506: 'rt',\n",
       " 507: 'ru',\n",
       " 508: 'rv',\n",
       " 509: 'rw',\n",
       " 510: 'rx',\n",
       " 511: 'ry',\n",
       " 512: 'rz',\n",
       " 513: 's.',\n",
       " 514: 'sa',\n",
       " 515: 'sb',\n",
       " 516: 'sc',\n",
       " 517: 'sd',\n",
       " 518: 'se',\n",
       " 519: 'sf',\n",
       " 520: 'sg',\n",
       " 521: 'sh',\n",
       " 522: 'si',\n",
       " 523: 'sj',\n",
       " 524: 'sk',\n",
       " 525: 'sl',\n",
       " 526: 'sm',\n",
       " 527: 'sn',\n",
       " 528: 'so',\n",
       " 529: 'sp',\n",
       " 530: 'sq',\n",
       " 531: 'sr',\n",
       " 532: 'ss',\n",
       " 533: 'st',\n",
       " 534: 'su',\n",
       " 535: 'sv',\n",
       " 536: 'sw',\n",
       " 537: 'sx',\n",
       " 538: 'sy',\n",
       " 539: 'sz',\n",
       " 540: 't.',\n",
       " 541: 'ta',\n",
       " 542: 'tb',\n",
       " 543: 'tc',\n",
       " 544: 'td',\n",
       " 545: 'te',\n",
       " 546: 'tf',\n",
       " 547: 'tg',\n",
       " 548: 'th',\n",
       " 549: 'ti',\n",
       " 550: 'tj',\n",
       " 551: 'tk',\n",
       " 552: 'tl',\n",
       " 553: 'tm',\n",
       " 554: 'tn',\n",
       " 555: 'to',\n",
       " 556: 'tp',\n",
       " 557: 'tq',\n",
       " 558: 'tr',\n",
       " 559: 'ts',\n",
       " 560: 'tt',\n",
       " 561: 'tu',\n",
       " 562: 'tv',\n",
       " 563: 'tw',\n",
       " 564: 'tx',\n",
       " 565: 'ty',\n",
       " 566: 'tz',\n",
       " 567: 'u.',\n",
       " 568: 'ua',\n",
       " 569: 'ub',\n",
       " 570: 'uc',\n",
       " 571: 'ud',\n",
       " 572: 'ue',\n",
       " 573: 'uf',\n",
       " 574: 'ug',\n",
       " 575: 'uh',\n",
       " 576: 'ui',\n",
       " 577: 'uj',\n",
       " 578: 'uk',\n",
       " 579: 'ul',\n",
       " 580: 'um',\n",
       " 581: 'un',\n",
       " 582: 'uo',\n",
       " 583: 'up',\n",
       " 584: 'uq',\n",
       " 585: 'ur',\n",
       " 586: 'us',\n",
       " 587: 'ut',\n",
       " 588: 'uu',\n",
       " 589: 'uv',\n",
       " 590: 'uw',\n",
       " 591: 'ux',\n",
       " 592: 'uy',\n",
       " 593: 'uz',\n",
       " 594: 'v.',\n",
       " 595: 'va',\n",
       " 596: 'vb',\n",
       " 597: 'vc',\n",
       " 598: 'vd',\n",
       " 599: 've',\n",
       " 600: 'vf',\n",
       " 601: 'vg',\n",
       " 602: 'vh',\n",
       " 603: 'vi',\n",
       " 604: 'vj',\n",
       " 605: 'vk',\n",
       " 606: 'vl',\n",
       " 607: 'vm',\n",
       " 608: 'vn',\n",
       " 609: 'vo',\n",
       " 610: 'vp',\n",
       " 611: 'vq',\n",
       " 612: 'vr',\n",
       " 613: 'vs',\n",
       " 614: 'vt',\n",
       " 615: 'vu',\n",
       " 616: 'vv',\n",
       " 617: 'vw',\n",
       " 618: 'vx',\n",
       " 619: 'vy',\n",
       " 620: 'vz',\n",
       " 621: 'w.',\n",
       " 622: 'wa',\n",
       " 623: 'wb',\n",
       " 624: 'wc',\n",
       " 625: 'wd',\n",
       " 626: 'we',\n",
       " 627: 'wf',\n",
       " 628: 'wg',\n",
       " 629: 'wh',\n",
       " 630: 'wi',\n",
       " 631: 'wj',\n",
       " 632: 'wk',\n",
       " 633: 'wl',\n",
       " 634: 'wm',\n",
       " 635: 'wn',\n",
       " 636: 'wo',\n",
       " 637: 'wp',\n",
       " 638: 'wq',\n",
       " 639: 'wr',\n",
       " 640: 'ws',\n",
       " 641: 'wt',\n",
       " 642: 'wu',\n",
       " 643: 'wv',\n",
       " 644: 'ww',\n",
       " 645: 'wx',\n",
       " 646: 'wy',\n",
       " 647: 'wz',\n",
       " 648: 'x.',\n",
       " 649: 'xa',\n",
       " 650: 'xb',\n",
       " 651: 'xc',\n",
       " 652: 'xd',\n",
       " 653: 'xe',\n",
       " 654: 'xf',\n",
       " 655: 'xg',\n",
       " 656: 'xh',\n",
       " 657: 'xi',\n",
       " 658: 'xj',\n",
       " 659: 'xk',\n",
       " 660: 'xl',\n",
       " 661: 'xm',\n",
       " 662: 'xn',\n",
       " 663: 'xo',\n",
       " 664: 'xp',\n",
       " 665: 'xq',\n",
       " 666: 'xr',\n",
       " 667: 'xs',\n",
       " 668: 'xt',\n",
       " 669: 'xu',\n",
       " 670: 'xv',\n",
       " 671: 'xw',\n",
       " 672: 'xx',\n",
       " 673: 'xy',\n",
       " 674: 'xz',\n",
       " 675: 'y.',\n",
       " 676: 'ya',\n",
       " 677: 'yb',\n",
       " 678: 'yc',\n",
       " 679: 'yd',\n",
       " 680: 'ye',\n",
       " 681: 'yf',\n",
       " 682: 'yg',\n",
       " 683: 'yh',\n",
       " 684: 'yi',\n",
       " 685: 'yj',\n",
       " 686: 'yk',\n",
       " 687: 'yl',\n",
       " 688: 'ym',\n",
       " 689: 'yn',\n",
       " 690: 'yo',\n",
       " 691: 'yp',\n",
       " 692: 'yq',\n",
       " 693: 'yr',\n",
       " 694: 'ys',\n",
       " 695: 'yt',\n",
       " 696: 'yu',\n",
       " 697: 'yv',\n",
       " 698: 'yw',\n",
       " 699: 'yx',\n",
       " 700: 'yy',\n",
       " 701: 'yz',\n",
       " 702: 'z.',\n",
       " 703: 'za',\n",
       " 704: 'zb',\n",
       " 705: 'zc',\n",
       " 706: 'zd',\n",
       " 707: 'ze',\n",
       " 708: 'zf',\n",
       " 709: 'zg',\n",
       " 710: 'zh',\n",
       " 711: 'zi',\n",
       " 712: 'zj',\n",
       " 713: 'zk',\n",
       " 714: 'zl',\n",
       " 715: 'zm',\n",
       " 716: 'zn',\n",
       " 717: 'zo',\n",
       " 718: 'zp',\n",
       " 719: 'zq',\n",
       " 720: 'zr',\n",
       " 721: 'zs',\n",
       " 722: 'zt',\n",
       " 723: 'zu',\n",
       " 724: 'zv',\n",
       " 725: 'zw',\n",
       " 726: 'zx',\n",
       " 727: 'zy',\n",
       " 728: 'zz'}"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itop = {i:p for p, i in ptoi.items()}\n",
    "itop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ptoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5,\n",
       "  148,\n",
       "  364,\n",
       "  352,\n",
       "  15,\n",
       "  417,\n",
       "  333,\n",
       "  265,\n",
       "  603,\n",
       "  244,\n",
       "  1,\n",
       "  49,\n",
       "  595,\n",
       "  9,\n",
       "  262,\n",
       "  514,\n",
       "  29,\n",
       "  59,\n",
       "  147,\n",
       "  336,\n",
       "  325,\n",
       "  19,\n",
       "  528,\n",
       "  421,\n",
       "  440,\n",
       "  225,\n",
       "  244,\n",
       "  3,\n",
       "  89,\n",
       "  217,\n",
       "  45,\n",
       "  498,\n",
       "  339,\n",
       "  425,\n",
       "  560,\n",
       "  545,\n",
       "  13,\n",
       "  360,\n",
       "  244,\n",
       "  1,\n",
       "  40,\n",
       "  356,\n",
       "  147,\n",
       "  333,\n",
       "  244,\n",
       "  8,\n",
       "  217,\n",
       "  45,\n",
       "  502,\n",
       "  437,\n",
       "  153,\n",
       "  5,\n",
       "  157,\n",
       "  599,\n",
       "  147,\n",
       "  349,\n",
       "  689,\n",
       "  1,\n",
       "  29,\n",
       "  63,\n",
       "  250,\n",
       "  190,\n",
       "  36,\n",
       "  255,\n",
       "  5,\n",
       "  148,\n",
       "  360,\n",
       "  255,\n",
       "  349,\n",
       "  5,\n",
       "  147,\n",
       "  333,\n",
       "  269,\n",
       "  703,\n",
       "  29,\n",
       "  59,\n",
       "  155,\n",
       "  548,\n",
       "  13,\n",
       "  360,\n",
       "  255,\n",
       "  325,\n",
       "  5,\n",
       "  147,\n",
       "  336,\n",
       "  325,\n",
       "  1,\n",
       "  49,\n",
       "  599,\n",
       "  153,\n",
       "  511,\n",
       "  19,\n",
       "  528,\n",
       "  411,\n",
       "  171,\n",
       "  244,\n",
       "  3,\n",
       "  82,\n",
       "  40,\n",
       "  360,\n",
       "  255,\n",
       "  325,\n",
       "  1,\n",
       "  45,\n",
       "  495,\n",
       "  244,\n",
       "  19,\n",
       "  516,\n",
       "  82,\n",
       "  45,\n",
       "  498,\n",
       "  329,\n",
       "  155,\n",
       "  560,\n",
       "  22,\n",
       "  603,\n",
       "  246,\n",
       "  101,\n",
       "  555,\n",
       "  423,\n",
       "  495,\n",
       "  244,\n",
       "  13,\n",
       "  352,\n",
       "  31,\n",
       "  117,\n",
       "  262,\n",
       "  528,\n",
       "  419,\n",
       "  12,\n",
       "  345,\n",
       "  581,\n",
       "  379,\n",
       "  7,\n",
       "  207,\n",
       "  487,\n",
       "  30,\n",
       "  86,\n",
       "  3,\n",
       "  89,\n",
       "  228,\n",
       "  339,\n",
       "  410,\n",
       "  16,\n",
       "  437,\n",
       "  149,\n",
       "  383,\n",
       "  147,\n",
       "  339,\n",
       "  421,\n",
       "  437,\n",
       "  12,\n",
       "  325,\n",
       "  52,\n",
       "  687,\n",
       "  325,\n",
       "  18,\n",
       "  495,\n",
       "  255,\n",
       "  329,\n",
       "  160,\n",
       "  26,\n",
       "  717,\n",
       "  410,\n",
       "  160,\n",
       "  14,\n",
       "  393,\n",
       "  423,\n",
       "  487,\n",
       "  12,\n",
       "  333,\n",
       "  255,\n",
       "  349,\n",
       "  5,\n",
       "  147,\n",
       "  329,\n",
       "  136,\n",
       "  41,\n",
       "  393,\n",
       "  423,\n",
       "  8,\n",
       "  217,\n",
       "  41,\n",
       "  392,\n",
       "  379,\n",
       "  35,\n",
       "  12,\n",
       "  333,\n",
       "  255,\n",
       "  336,\n",
       "  333,\n",
       "  244,\n",
       "  41,\n",
       "  1,\n",
       "  31,\n",
       "  112,\n",
       "  117,\n",
       "  262,\n",
       "  528,\n",
       "  419,\n",
       "  1,\n",
       "  48,\n",
       "  569,\n",
       "  72,\n",
       "  491,\n",
       "  160,\n",
       "  5,\n",
       "  147,\n",
       "  336,\n",
       "  333,\n",
       "  248,\n",
       "  19,\n",
       "  533,\n",
       "  545,\n",
       "  147,\n",
       "  336,\n",
       "  325,\n",
       "  14,\n",
       "  379,\n",
       "  47,\n",
       "  541,\n",
       "  39,\n",
       "  333,\n",
       "  248,\n",
       "  26,\n",
       "  717,\n",
       "  410,\n",
       "  12,\n",
       "  329,\n",
       "  136,\n",
       "  35,\n",
       "  8,\n",
       "  217,\n",
       "  53,\n",
       "  707,\n",
       "  147,\n",
       "  22,\n",
       "  603,\n",
       "  258,\n",
       "  417,\n",
       "  329,\n",
       "  155,\n",
       "  1,\n",
       "  48,\n",
       "  585,\n",
       "  501,\n",
       "  423,\n",
       "  487,\n",
       "  19,\n",
       "  514,\n",
       "  49,\n",
       "  595,\n",
       "  41,\n",
       "  392,\n",
       "  379,\n",
       "  35,\n",
       "  1,\n",
       "  48,\n",
       "  571,\n",
       "  126,\n",
       "  491,\n",
       "  160,\n",
       "  2,\n",
       "  72,\n",
       "  501,\n",
       "  420,\n",
       "  416,\n",
       "  309,\n",
       "  349,\n",
       "  689,\n",
       "  2,\n",
       "  59,\n",
       "  147,\n",
       "  336,\n",
       "  325,\n",
       "  3,\n",
       "  93,\n",
       "  325,\n",
       "  36,\n",
       "  261,\n",
       "  491,\n",
       "  19,\n",
       "  524,\n",
       "  322,\n",
       "  687,\n",
       "  325,\n",
       "  45,\n",
       "  12,\n",
       "  345,\n",
       "  570,\n",
       "  106,\n",
       "  16,\n",
       "  433,\n",
       "  36,\n",
       "  262,\n",
       "  525,\n",
       "  329,\n",
       "  160,\n",
       "  5,\n",
       "  157,\n",
       "  599,\n",
       "  153,\n",
       "  498,\n",
       "  349,\n",
       "  1,\n",
       "  41,\n",
       "  392,\n",
       "  379,\n",
       "  3,\n",
       "  82,\n",
       "  45,\n",
       "  501,\n",
       "  417,\n",
       "  333,\n",
       "  257,\n",
       "  383,\n",
       "  14,\n",
       "  393,\n",
       "  427,\n",
       "  595,\n",
       "  7,\n",
       "  194,\n",
       "  149,\n",
       "  383,\n",
       "  154,\n",
       "  522,\n",
       "  262,\n",
       "  5,\n",
       "  148,\n",
       "  360,\n",
       "  255,\n",
       "  333,\n",
       "  244,\n",
       "  11,\n",
       "  302,\n",
       "  149,\n",
       "  392,\n",
       "  383,\n",
       "  139,\n",
       "  133,\n",
       "  19,\n",
       "  514,\n",
       "  40,\n",
       "  352,\n",
       "  41,\n",
       "  398,\n",
       "  548,\n",
       "  217,\n",
       "  13,\n",
       "  352,\n",
       "  52,\n",
       "  676,\n",
       "  23,\n",
       "  630,\n",
       "  255,\n",
       "  336,\n",
       "  339,\n",
       "  428,\n",
       "  11,\n",
       "  306,\n",
       "  257,\n",
       "  397,\n",
       "  525,\n",
       "  329,\n",
       "  160,\n",
       "  14,\n",
       "  379,\n",
       "  42,\n",
       "  418,\n",
       "  360,\n",
       "  1,\n",
       "  28,\n",
       "  39,\n",
       "  333,\n",
       "  268,\n",
       "  676,\n",
       "  35,\n",
       "  5,\n",
       "  147,\n",
       "  329,\n",
       "  149,\n",
       "  379,\n",
       "  19,\n",
       "  514,\n",
       "  45,\n",
       "  487,\n",
       "  35,\n",
       "  1,\n",
       "  45,\n",
       "  495,\n",
       "  244,\n",
       "  41,\n",
       "  379,\n",
       "  1,\n",
       "  39,\n",
       "  336,\n",
       "  333,\n",
       "  262,\n",
       "  528,\n",
       "  419,\n",
       "  7,\n",
       "  190,\n",
       "  29,\n",
       "  72,\n",
       "  495,\n",
       "  248,\n",
       "  147,\n",
       "  336,\n",
       "  325,\n",
       "  1,\n",
       "  39,\n",
       "  333,\n",
       "  246,\n",
       "  86,\n",
       "  13,\n",
       "  352,\n",
       "  31,\n",
       "  113,\n",
       "  147,\n",
       "  349,\n",
       "  689,\n",
       "  3,\n",
       "  96,\n",
       "  423,\n",
       "  487,\n",
       "  18,\n",
       "  507,\n",
       "  569,\n",
       "  79,\n",
       "  5,\n",
       "  157,\n",
       "  595,\n",
       "  19,\n",
       "  518,\n",
       "  153,\n",
       "  491,\n",
       "  149,\n",
       "  387,\n",
       "  263,\n",
       "  565,\n",
       "  1,\n",
       "  48,\n",
       "  587,\n",
       "  561,\n",
       "  580,\n",
       "  365,\n",
       "  1,\n",
       "  31,\n",
       "  113,\n",
       "  147,\n",
       "  333,\n",
       "  257,\n",
       "  383,\n",
       "  8,\n",
       "  217,\n",
       "  36,\n",
       "  255,\n",
       "  329,\n",
       "  160,\n",
       "  7,\n",
       "  198,\n",
       "  244,\n",
       "  41,\n",
       "  392,\n",
       "  379,\n",
       "  22,\n",
       "  595,\n",
       "  39,\n",
       "  329,\n",
       "  149,\n",
       "  398,\n",
       "  549,\n",
       "  257,\n",
       "  379,\n",
       "  9,\n",
       "  262,\n",
       "  525,\n",
       "  325,\n",
       "  5,\n",
       "  147,\n",
       "  333,\n",
       "  244,\n",
       "  41,\n",
       "  379,\n",
       "  17,\n",
       "  480,\n",
       "  576,\n",
       "  257,\n",
       "  392,\n",
       "  14,\n",
       "  383,\n",
       "  157,\n",
       "  595,\n",
       "  32,\n",
       "  143,\n",
       "  9,\n",
       "  265,\n",
       "  619,\n",
       "  19,\n",
       "  514,\n",
       "  31,\n",
       "  117,\n",
       "  248,\n",
       "  16,\n",
       "  441,\n",
       "  259,\n",
       "  437,\n",
       "  153,\n",
       "  12,\n",
       "  349,\n",
       "  679,\n",
       "  117,\n",
       "  244,\n",
       "  1,\n",
       "  39,\n",
       "  329,\n",
       "  159,\n",
       "  649,\n",
       "  10,\n",
       "  285,\n",
       "  424,\n",
       "  518,\n",
       "  151,\n",
       "  440,\n",
       "  225,\n",
       "  257,\n",
       "  383,\n",
       "  5,\n",
       "  148,\n",
       "  356,\n",
       "  153,\n",
       "  511,\n",
       "  10,\n",
       "  291,\n",
       "  579,\n",
       "  333,\n",
       "  244,\n",
       "  4,\n",
       "  113,\n",
       "  147,\n",
       "  333,\n",
       "  255,\n",
       "  325,\n",
       "  35,\n",
       "  1,\n",
       "  45,\n",
       "  495,\n",
       "  244,\n",
       "  41,\n",
       "  392,\n",
       "  379,\n",
       "  22,\n",
       "  603,\n",
       "  265,\n",
       "  603,\n",
       "  244,\n",
       "  41,\n",
       "  11,\n",
       "  298,\n",
       "  52,\n",
       "  687,\n",
       "  329,\n",
       "  140,\n",
       "  19,\n",
       "  528,\n",
       "  421,\n",
       "  440,\n",
       "  225,\n",
       "  248,\n",
       "  2,\n",
       "  72,\n",
       "  495,\n",
       "  248,\n",
       "  147,\n",
       "  336,\n",
       "  329,\n",
       "  13,\n",
       "  352,\n",
       "  31,\n",
       "  113,\n",
       "  147,\n",
       "  333,\n",
       "  257,\n",
       "  383,\n",
       "  16,\n",
       "  437,\n",
       "  160,\n",
       "  695,\n",
       "  555,\n",
       "  419,\n",
       "  18,\n",
       "  511,\n",
       "  687,\n",
       "  329,\n",
       "  140,\n",
       "  3,\n",
       "  93,\n",
       "  325,\n",
       "  45,\n",
       "  487,\n",
       "  8,\n",
       "  217,\n",
       "  31,\n",
       "  120,\n",
       "  329,\n",
       "  160,\n",
       "  13,\n",
       "  356,\n",
       "  147,\n",
       "  325,\n",
       "  41,\n",
       "  387,\n",
       "  248,\n",
       "  13,\n",
       "  352,\n",
       "  30,\n",
       "  92,\n",
       "  302,\n",
       "  149,\n",
       "  404,\n",
       "  711,\n",
       "  248,\n",
       "  18,\n",
       "  491,\n",
       "  136,\n",
       "  34,\n",
       "  190,\n",
       "  41,\n",
       "  1,\n",
       "  31,\n",
       "  109,\n",
       "  39,\n",
       "  349,\n",
       "  689,\n",
       "  392,\n",
       "  12,\n",
       "  333,\n",
       "  255,\n",
       "  333,\n",
       "  244,\n",
       "  41,\n",
       "  379,\n",
       "  1,\n",
       "  48,\n",
       "  569,\n",
       "  72,\n",
       "  491,\n",
       "  140,\n",
       "  10,\n",
       "  271,\n",
       "  31,\n",
       "  113,\n",
       "  11,\n",
       "  298,\n",
       "  47,\n",
       "  548,\n",
       "  221,\n",
       "  153,\n",
       "  495,\n",
       "  257,\n",
       "  383,\n",
       "  9,\n",
       "  262,\n",
       "  514,\n",
       "  29,\n",
       "  59,\n",
       "  147,\n",
       "  336,\n",
       "  329,\n",
       "  14,\n",
       "  379,\n",
       "  47,\n",
       "  541,\n",
       "  39,\n",
       "  333,\n",
       "  244,\n",
       "  18,\n",
       "  487,\n",
       "  32,\n",
       "  147,\n",
       "  349,\n",
       "  689,\n",
       "  392,\n",
       "  13,\n",
       "  352,\n",
       "  45,\n",
       "  495,\n",
       "  244,\n",
       "  1,\n",
       "  47,\n",
       "  548,\n",
       "  221,\n",
       "  149,\n",
       "  379,\n",
       "  24,\n",
       "  657,\n",
       "  256,\n",
       "  356,\n",
       "  149,\n",
       "  379,\n",
       "  1,\n",
       "  45,\n",
       "  511,\n",
       "  676,\n",
       "  12,\n",
       "  329,\n",
       "  144,\n",
       "  255,\n",
       "  325,\n",
       "  41,\n",
       "  387,\n",
       "  20,\n",
       "  541,\n",
       "  52,\n",
       "  687,\n",
       "  339,\n",
       "  423,\n",
       "  6,\n",
       "  163,\n",
       "  36,\n",
       "  263,\n",
       "  548,\n",
       "  18,\n",
       "  501,\n",
       "  424,\n",
       "  518,\n",
       "  11,\n",
       "  322,\n",
       "  687,\n",
       "  333,\n",
       "  248,\n",
       "  1,\n",
       "  39,\n",
       "  329,\n",
       "  159,\n",
       "  649,\n",
       "  41,\n",
       "  382,\n",
       "  126,\n",
       "  487,\n",
       "  13,\n",
       "  352,\n",
       "  45,\n",
       "  511,\n",
       "  13,\n",
       "  352,\n",
       "  45,\n",
       "  493,\n",
       "  190,\n",
       "  45,\n",
       "  491,\n",
       "  155,\n",
       "  12,\n",
       "  349,\n",
       "  687,\n",
       "  325,\n",
       "  1,\n",
       "  46,\n",
       "  521,\n",
       "  228,\n",
       "  329,\n",
       "  160,\n",
       "  1,\n",
       "  40,\n",
       "  352,\n",
       "  52,\n",
       "  676,\n",
       "  5,\n",
       "  147,\n",
       "  333,\n",
       "  269,\n",
       "  703,\n",
       "  2,\n",
       "  72,\n",
       "  495,\n",
       "  244,\n",
       "  41,\n",
       "  392,\n",
       "  379,\n",
       "  2,\n",
       "  55,\n",
       "  36,\n",
       "  255,\n",
       "  329,\n",
       "  160,\n",
       "  1,\n",
       "  41,\n",
       "  382,\n",
       "  126,\n",
       "  491,\n",
       "  136,\n",
       "  11,\n",
       "  305,\n",
       "  228,\n",
       "  339,\n",
       "  410,\n",
       "  10,\n",
       "  271,\n",
       "  46,\n",
       "  526,\n",
       "  360,\n",
       "  257,\n",
       "  383,\n",
       "  13,\n",
       "  356,\n",
       "  147,\n",
       "  339,\n",
       "  409,\n",
       "  133,\n",
       "  9,\n",
       "  261,\n",
       "  495,\n",
       "  262,\n",
       "  9,\n",
       "  262,\n",
       "  514,\n",
       "  29,\n",
       "  59,\n",
       "  147,\n",
       "  14,\n",
       "  393,\n",
       "  423,\n",
       "  487,\n",
       "  35,\n",
       "  1,\n",
       "  41,\n",
       "  392,\n",
       "  379,\n",
       "  29,\n",
       "  59,\n",
       "  147,\n",
       "  336,\n",
       "  329,\n",
       "  22,\n",
       "  595,\n",
       "  39,\n",
       "  329,\n",
       "  153,\n",
       "  495,\n",
       "  244,\n",
       "  5,\n",
       "  148,\n",
       "  356,\n",
       "  153,\n",
       "  505,\n",
       "  528,\n",
       "  419,\n",
       "  1,\n",
       "  31,\n",
       "  109,\n",
       "  39,\n",
       "  349,\n",
       "  689,\n",
       "  18,\n",
       "  511,\n",
       "  687,\n",
       "  329,\n",
       "  144,\n",
       "  250,\n",
       "  197,\n",
       "  5,\n",
       "  139,\n",
       "  113,\n",
       "  149,\n",
       "  5,\n",
       "  148,\n",
       "  356,\n",
       "  153,\n",
       "  505,\n",
       "  538,\n",
       "  689,\n",
       "  1,\n",
       "  41,\n",
       "  379,\n",
       "  46,\n",
       "  533,\n",
       "  541,\n",
       "  46,\n",
       "  522,\n",
       "  244,\n",
       "  11,\n",
       "  298,\n",
       "  52,\n",
       "  687,\n",
       "  325,\n",
       "  1,\n",
       "  39,\n",
       "  349,\n",
       "  694,\n",
       "  532,\n",
       "  514,\n",
       "  10,\n",
       "  291,\n",
       "  579,\n",
       "  333,\n",
       "  244,\n",
       "  41,\n",
       "  379,\n",
       "  3,\n",
       "  89,\n",
       "  217,\n",
       "  45,\n",
       "  498,\n",
       "  333,\n",
       "  248,\n",
       "  5,\n",
       "  154,\n",
       "  533,\n",
       "  548,\n",
       "  221,\n",
       "  153,\n",
       "  1,\n",
       "  45,\n",
       "  495,\n",
       "  248,\n",
       "  147,\n",
       "  3,\n",
       "  86,\n",
       "  138,\n",
       "  90,\n",
       "  255,\n",
       "  333,\n",
       "  244,\n",
       "  22,\n",
       "  595,\n",
       "  39,\n",
       "  329,\n",
       "  153,\n",
       "  495,\n",
       "  248,\n",
       "  1,\n",
       "  39,\n",
       "  333,\n",
       "  257,\n",
       "  379,\n",
       "  13,\n",
       "  366,\n",
       "  417,\n",
       "  336,\n",
       "  349,\n",
       "  18,\n",
       "  491,\n",
       "  140,\n",
       "  154,\n",
       "  518,\n",
       "  1,\n",
       "  39,\n",
       "  333,\n",
       "  268,\n",
       "  676,\n",
       "  35,\n",
       "  12,\n",
       "  333,\n",
       "  255,\n",
       "  336,\n",
       "  349,\n",
       "  16,\n",
       "  433,\n",
       "  45,\n",
       "  497,\n",
       "  302,\n",
       "  153,\n",
       "  6,\n",
       "  171,\n",
       "  257,\n",
       "  390,\n",
       "  329,\n",
       "  160,\n",
       "  13,\n",
       "  366,\n",
       "  423,\n",
       "  493,\n",
       "  190,\n",
       "  41,\n",
       "  19,\n",
       "  538,\n",
       "  679,\n",
       "  122,\n",
       "  383,\n",
       "  160,\n",
       "  10,\n",
       "  285,\n",
       "  423,\n",
       "  490,\n",
       "  133,\n",
       "  689,\n",
       "  5,\n",
       "  147,\n",
       "  339,\n",
       "  414,\n",
       "  262,\n",
       "  518,\n",
       "  20,\n",
       "  558,\n",
       "  495,\n",
       "  257,\n",
       "  387,\n",
       "  263,\n",
       "  565,\n",
       "  4,\n",
       "  ...],\n",
       " [13,\n",
       "  13,\n",
       "  1,\n",
       "  0,\n",
       "  12,\n",
       "  9,\n",
       "  22,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  22,\n",
       "  1,\n",
       "  0,\n",
       "  19,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  12,\n",
       "  12,\n",
       "  1,\n",
       "  0,\n",
       "  15,\n",
       "  16,\n",
       "  8,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  8,\n",
       "  1,\n",
       "  18,\n",
       "  12,\n",
       "  15,\n",
       "  20,\n",
       "  20,\n",
       "  5,\n",
       "  0,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  13,\n",
       "  5,\n",
       "  12,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  18,\n",
       "  16,\n",
       "  5,\n",
       "  18,\n",
       "  0,\n",
       "  22,\n",
       "  5,\n",
       "  12,\n",
       "  25,\n",
       "  14,\n",
       "  0,\n",
       "  2,\n",
       "  9,\n",
       "  7,\n",
       "  1,\n",
       "  9,\n",
       "  12,\n",
       "  0,\n",
       "  13,\n",
       "  9,\n",
       "  12,\n",
       "  25,\n",
       "  0,\n",
       "  12,\n",
       "  9,\n",
       "  26,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  20,\n",
       "  8,\n",
       "  0,\n",
       "  9,\n",
       "  12,\n",
       "  1,\n",
       "  0,\n",
       "  12,\n",
       "  12,\n",
       "  1,\n",
       "  0,\n",
       "  22,\n",
       "  5,\n",
       "  18,\n",
       "  25,\n",
       "  0,\n",
       "  15,\n",
       "  6,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  13,\n",
       "  9,\n",
       "  12,\n",
       "  1,\n",
       "  0,\n",
       "  18,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  18,\n",
       "  12,\n",
       "  5,\n",
       "  20,\n",
       "  20,\n",
       "  0,\n",
       "  9,\n",
       "  3,\n",
       "  20,\n",
       "  15,\n",
       "  18,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  9,\n",
       "  19,\n",
       "  15,\n",
       "  14,\n",
       "  0,\n",
       "  21,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  18,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  8,\n",
       "  12,\n",
       "  15,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  14,\n",
       "  5,\n",
       "  12,\n",
       "  15,\n",
       "  16,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  25,\n",
       "  12,\n",
       "  1,\n",
       "  0,\n",
       "  9,\n",
       "  12,\n",
       "  5,\n",
       "  25,\n",
       "  0,\n",
       "  15,\n",
       "  5,\n",
       "  25,\n",
       "  0,\n",
       "  15,\n",
       "  18,\n",
       "  1,\n",
       "  0,\n",
       "  9,\n",
       "  12,\n",
       "  25,\n",
       "  0,\n",
       "  12,\n",
       "  5,\n",
       "  1,\n",
       "  14,\n",
       "  15,\n",
       "  18,\n",
       "  0,\n",
       "  1,\n",
       "  14,\n",
       "  14,\n",
       "  1,\n",
       "  8,\n",
       "  0,\n",
       "  9,\n",
       "  12,\n",
       "  12,\n",
       "  9,\n",
       "  1,\n",
       "  14,\n",
       "  0,\n",
       "  4,\n",
       "  4,\n",
       "  9,\n",
       "  19,\n",
       "  15,\n",
       "  14,\n",
       "  0,\n",
       "  21,\n",
       "  2,\n",
       "  18,\n",
       "  5,\n",
       "  25,\n",
       "  0,\n",
       "  12,\n",
       "  12,\n",
       "  9,\n",
       "  5,\n",
       "  0,\n",
       "  20,\n",
       "  5,\n",
       "  12,\n",
       "  12,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  20,\n",
       "  1,\n",
       "  12,\n",
       "  9,\n",
       "  5,\n",
       "  0,\n",
       "  15,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  8,\n",
       "  0,\n",
       "  1,\n",
       "  26,\n",
       "  5,\n",
       "  12,\n",
       "  0,\n",
       "  9,\n",
       "  15,\n",
       "  12,\n",
       "  5,\n",
       "  20,\n",
       "  0,\n",
       "  21,\n",
       "  18,\n",
       "  15,\n",
       "  18,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  22,\n",
       "  1,\n",
       "  14,\n",
       "  14,\n",
       "  1,\n",
       "  8,\n",
       "  0,\n",
       "  21,\n",
       "  4,\n",
       "  18,\n",
       "  5,\n",
       "  25,\n",
       "  0,\n",
       "  18,\n",
       "  15,\n",
       "  15,\n",
       "  11,\n",
       "  12,\n",
       "  25,\n",
       "  14,\n",
       "  0,\n",
       "  5,\n",
       "  12,\n",
       "  12,\n",
       "  1,\n",
       "  0,\n",
       "  12,\n",
       "  1,\n",
       "  9,\n",
       "  18,\n",
       "  5,\n",
       "  0,\n",
       "  11,\n",
       "  25,\n",
       "  12,\n",
       "  1,\n",
       "  18,\n",
       "  0,\n",
       "  21,\n",
       "  3,\n",
       "  25,\n",
       "  0,\n",
       "  1,\n",
       "  9,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  25,\n",
       "  0,\n",
       "  22,\n",
       "  5,\n",
       "  18,\n",
       "  12,\n",
       "  25,\n",
       "  0,\n",
       "  14,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  18,\n",
       "  15,\n",
       "  12,\n",
       "  9,\n",
       "  14,\n",
       "  5,\n",
       "  0,\n",
       "  15,\n",
       "  22,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  14,\n",
       "  5,\n",
       "  19,\n",
       "  9,\n",
       "  19,\n",
       "  0,\n",
       "  13,\n",
       "  9,\n",
       "  12,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  14,\n",
       "  14,\n",
       "  5,\n",
       "  4,\n",
       "  25,\n",
       "  0,\n",
       "  1,\n",
       "  13,\n",
       "  1,\n",
       "  14,\n",
       "  20,\n",
       "  8,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  25,\n",
       "  1,\n",
       "  0,\n",
       "  9,\n",
       "  12,\n",
       "  12,\n",
       "  15,\n",
       "  23,\n",
       "  0,\n",
       "  9,\n",
       "  14,\n",
       "  19,\n",
       "  12,\n",
       "  5,\n",
       "  25,\n",
       "  0,\n",
       "  1,\n",
       "  15,\n",
       "  13,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  12,\n",
       "  9,\n",
       "  25,\n",
       "  1,\n",
       "  8,\n",
       "  0,\n",
       "  12,\n",
       "  5,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  18,\n",
       "  1,\n",
       "  8,\n",
       "  0,\n",
       "  18,\n",
       "  9,\n",
       "  1,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  12,\n",
       "  12,\n",
       "  9,\n",
       "  19,\n",
       "  15,\n",
       "  14,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  18,\n",
       "  9,\n",
       "  5,\n",
       "  12,\n",
       "  12,\n",
       "  1,\n",
       "  0,\n",
       "  12,\n",
       "  9,\n",
       "  3,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  12,\n",
       "  25,\n",
       "  14,\n",
       "  0,\n",
       "  15,\n",
       "  18,\n",
       "  1,\n",
       "  0,\n",
       "  21,\n",
       "  2,\n",
       "  25,\n",
       "  0,\n",
       "  22,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  18,\n",
       "  5,\n",
       "  14,\n",
       "  9,\n",
       "  20,\n",
       "  25,\n",
       "  0,\n",
       "  21,\n",
       "  20,\n",
       "  21,\n",
       "  13,\n",
       "  14,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  12,\n",
       "  9,\n",
       "  14,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  9,\n",
       "  12,\n",
       "  5,\n",
       "  25,\n",
       "  0,\n",
       "  9,\n",
       "  1,\n",
       "  14,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  12,\n",
       "  5,\n",
       "  14,\n",
       "  20,\n",
       "  9,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  19,\n",
       "  12,\n",
       "  1,\n",
       "  0,\n",
       "  12,\n",
       "  9,\n",
       "  1,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  21,\n",
       "  9,\n",
       "  14,\n",
       "  14,\n",
       "  0,\n",
       "  5,\n",
       "  22,\n",
       "  1,\n",
       "  5,\n",
       "  8,\n",
       "  0,\n",
       "  22,\n",
       "  25,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  9,\n",
       "  5,\n",
       "  0,\n",
       "  9,\n",
       "  16,\n",
       "  5,\n",
       "  18,\n",
       "  0,\n",
       "  25,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  12,\n",
       "  5,\n",
       "  24,\n",
       "  1,\n",
       "  0,\n",
       "  15,\n",
       "  19,\n",
       "  5,\n",
       "  16,\n",
       "  8,\n",
       "  9,\n",
       "  14,\n",
       "  5,\n",
       "  0,\n",
       "  13,\n",
       "  5,\n",
       "  18,\n",
       "  25,\n",
       "  0,\n",
       "  21,\n",
       "  12,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  12,\n",
       "  9,\n",
       "  12,\n",
       "  1,\n",
       "  8,\n",
       "  0,\n",
       "  18,\n",
       "  9,\n",
       "  1,\n",
       "  14,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  9,\n",
       "  22,\n",
       "  9,\n",
       "  1,\n",
       "  14,\n",
       "  0,\n",
       "  1,\n",
       "  25,\n",
       "  12,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  15,\n",
       "  16,\n",
       "  8,\n",
       "  9,\n",
       "  5,\n",
       "  0,\n",
       "  18,\n",
       "  9,\n",
       "  5,\n",
       "  12,\n",
       "  12,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  12,\n",
       "  9,\n",
       "  14,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  25,\n",
       "  20,\n",
       "  15,\n",
       "  14,\n",
       "  0,\n",
       "  25,\n",
       "  12,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  12,\n",
       "  1,\n",
       "  18,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  12,\n",
       "  5,\n",
       "  25,\n",
       "  0,\n",
       "  5,\n",
       "  12,\n",
       "  1,\n",
       "  14,\n",
       "  9,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  11,\n",
       "  5,\n",
       "  14,\n",
       "  26,\n",
       "  9,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  14,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  12,\n",
       "  25,\n",
       "  14,\n",
       "  14,\n",
       "  0,\n",
       "  9,\n",
       "  12,\n",
       "  9,\n",
       "  1,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  21,\n",
       "  2,\n",
       "  18,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  20,\n",
       "  8,\n",
       "  5,\n",
       "  18,\n",
       "  9,\n",
       "  14,\n",
       "  5,\n",
       "  0,\n",
       "  19,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  12,\n",
       "  12,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  20,\n",
       "  1,\n",
       "  12,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  12,\n",
       "  25,\n",
       "  14,\n",
       "  14,\n",
       "  0,\n",
       "  1,\n",
       "  18,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  20,\n",
       "  8,\n",
       "  5,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  9,\n",
       "  13,\n",
       "  5,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  18,\n",
       "  25,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  9,\n",
       "  12,\n",
       "  1,\n",
       "  14,\n",
       "  9,\n",
       "  0,\n",
       "  1,\n",
       "  25,\n",
       "  12,\n",
       "  15,\n",
       "  18,\n",
       "  0,\n",
       "  1,\n",
       "  9,\n",
       "  20,\n",
       "  8,\n",
       "  0,\n",
       "  15,\n",
       "  19,\n",
       "  5,\n",
       "  0,\n",
       "  25,\n",
       "  12,\n",
       "  9,\n",
       "  5,\n",
       "  0,\n",
       "  12,\n",
       "  5,\n",
       "  24,\n",
       "  1,\n",
       "  14,\n",
       "  4,\n",
       "  18,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  18,\n",
       "  25,\n",
       "  0,\n",
       "  1,\n",
       "  18,\n",
       "  7,\n",
       "  1,\n",
       "  18,\n",
       "  5,\n",
       "  20,\n",
       "  0,\n",
       "  25,\n",
       "  12,\n",
       "  1,\n",
       "  0,\n",
       "  19,\n",
       "  8,\n",
       "  12,\n",
       "  5,\n",
       "  25,\n",
       "  0,\n",
       "  13,\n",
       "  1,\n",
       "  25,\n",
       "  1,\n",
       "  0,\n",
       "  12,\n",
       "  9,\n",
       "  26,\n",
       "  1,\n",
       "  0,\n",
       "  18,\n",
       "  9,\n",
       "  1,\n",
       "  14,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  9,\n",
       "  12,\n",
       "  5,\n",
       "  25,\n",
       "  0,\n",
       "  14,\n",
       "  4,\n",
       "  18,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  8,\n",
       "  12,\n",
       "  15,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  19,\n",
       "  13,\n",
       "  9,\n",
       "  14,\n",
       "  5,\n",
       "  0,\n",
       "  5,\n",
       "  12,\n",
       "  15,\n",
       "  4,\n",
       "  25,\n",
       "  0,\n",
       "  18,\n",
       "  9,\n",
       "  19,\n",
       "  0,\n",
       "  19,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  12,\n",
       "  0,\n",
       "  15,\n",
       "  18,\n",
       "  1,\n",
       "  8,\n",
       "  0,\n",
       "  14,\n",
       "  14,\n",
       "  1,\n",
       "  2,\n",
       "  5,\n",
       "  12,\n",
       "  12,\n",
       "  5,\n",
       "  0,\n",
       "  1,\n",
       "  12,\n",
       "  5,\n",
       "  18,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  13,\n",
       "  5,\n",
       "  18,\n",
       "  19,\n",
       "  15,\n",
       "  14,\n",
       "  0,\n",
       "  4,\n",
       "  1,\n",
       "  12,\n",
       "  25,\n",
       "  14,\n",
       "  0,\n",
       "  25,\n",
       "  12,\n",
       "  5,\n",
       "  9,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  14,\n",
       "  0,\n",
       "  13,\n",
       "  5,\n",
       "  18,\n",
       "  19,\n",
       "  25,\n",
       "  14,\n",
       "  0,\n",
       "  14,\n",
       "  1,\n",
       "  19,\n",
       "  20,\n",
       "  1,\n",
       "  19,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  25,\n",
       "  12,\n",
       "  1,\n",
       "  0,\n",
       "  12,\n",
       "  25,\n",
       "  19,\n",
       "  19,\n",
       "  1,\n",
       "  0,\n",
       "  21,\n",
       "  12,\n",
       "  9,\n",
       "  1,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  8,\n",
       "  1,\n",
       "  18,\n",
       "  12,\n",
       "  9,\n",
       "  5,\n",
       "  0,\n",
       "  19,\n",
       "  20,\n",
       "  8,\n",
       "  5,\n",
       "  18,\n",
       "  0,\n",
       "  18,\n",
       "  9,\n",
       "  5,\n",
       "  12,\n",
       "  0,\n",
       "  5,\n",
       "  3,\n",
       "  9,\n",
       "  12,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  12,\n",
       "  5,\n",
       "  18,\n",
       "  9,\n",
       "  5,\n",
       "  0,\n",
       "  12,\n",
       "  9,\n",
       "  14,\n",
       "  1,\n",
       "  0,\n",
       "  15,\n",
       "  12,\n",
       "  12,\n",
       "  25,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  19,\n",
       "  5,\n",
       "  0,\n",
       "  12,\n",
       "  9,\n",
       "  25,\n",
       "  1,\n",
       "  8,\n",
       "  0,\n",
       "  9,\n",
       "  12,\n",
       "  12,\n",
       "  25,\n",
       "  0,\n",
       "  1,\n",
       "  18,\n",
       "  11,\n",
       "  5,\n",
       "  18,\n",
       "  0,\n",
       "  9,\n",
       "  14,\n",
       "  12,\n",
       "  5,\n",
       "  25,\n",
       "  0,\n",
       "  15,\n",
       "  18,\n",
       "  7,\n",
       "  1,\n",
       "  14,\n",
       "  0,\n",
       "  25,\n",
       "  4,\n",
       "  14,\n",
       "  5,\n",
       "  25,\n",
       "  0,\n",
       "  15,\n",
       "  18,\n",
       "  4,\n",
       "  25,\n",
       "  14,\n",
       "  0,\n",
       "  12,\n",
       "  15,\n",
       "  9,\n",
       "  19,\n",
       "  5,\n",
       "  0,\n",
       "  18,\n",
       "  9,\n",
       "  14,\n",
       "  9,\n",
       "  20,\n",
       "  25,\n",
       "  0,\n",
       "  1,\n",
       "  ...])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for w in words:\n",
    "    wdot = f'.{w}.'\n",
    "    for i in range(len(wdot) - 2):\n",
    "        pair = wdot[i] + wdot[i+1]\n",
    "        xs.append(ptoi[pair])\n",
    "        ys.append(stoi[wdot[i+2]])\n",
    "\n",
    "xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.tensor(xs).float()\n",
    "ys = torch.tensor(ys).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.3091, grad_fn=<DivBackward1>)\n",
      "tensor(3.1411, grad_fn=<DivBackward1>)\n",
      "tensor(3.0107, grad_fn=<DivBackward1>)\n",
      "tensor(2.9063, grad_fn=<DivBackward1>)\n",
      "tensor(2.8301, grad_fn=<DivBackward1>)\n",
      "tensor(2.7835, grad_fn=<DivBackward1>)\n",
      "tensor(2.7566, grad_fn=<DivBackward1>)\n",
      "tensor(2.7404, grad_fn=<DivBackward1>)\n",
      "tensor(2.7300, grad_fn=<DivBackward1>)\n",
      "tensor(2.7231, grad_fn=<DivBackward1>)\n",
      "tensor(2.7183, grad_fn=<DivBackward1>)\n",
      "tensor(2.7148, grad_fn=<DivBackward1>)\n",
      "tensor(2.7121, grad_fn=<DivBackward1>)\n",
      "tensor(2.7101, grad_fn=<DivBackward1>)\n",
      "tensor(2.7084, grad_fn=<DivBackward1>)\n",
      "tensor(2.7071, grad_fn=<DivBackward1>)\n",
      "tensor(2.7059, grad_fn=<DivBackward1>)\n",
      "tensor(2.7050, grad_fn=<DivBackward1>)\n",
      "tensor(2.7041, grad_fn=<DivBackward1>)\n",
      "tensor(2.7034, grad_fn=<DivBackward1>)\n",
      "tensor(2.7027, grad_fn=<DivBackward1>)\n",
      "tensor(2.7021, grad_fn=<DivBackward1>)\n",
      "tensor(2.7015, grad_fn=<DivBackward1>)\n",
      "tensor(2.7010, grad_fn=<DivBackward1>)\n",
      "tensor(2.7004, grad_fn=<DivBackward1>)\n",
      "tensor(2.6999, grad_fn=<DivBackward1>)\n",
      "tensor(2.6994, grad_fn=<DivBackward1>)\n",
      "tensor(2.6990, grad_fn=<DivBackward1>)\n",
      "tensor(2.6985, grad_fn=<DivBackward1>)\n",
      "tensor(2.6981, grad_fn=<DivBackward1>)\n",
      "tensor(2.6976, grad_fn=<DivBackward1>)\n",
      "tensor(2.6972, grad_fn=<DivBackward1>)\n",
      "tensor(2.6967, grad_fn=<DivBackward1>)\n",
      "tensor(2.6965, grad_fn=<DivBackward1>)\n",
      "tensor(2.6961, grad_fn=<DivBackward1>)\n",
      "tensor(2.6962, grad_fn=<DivBackward1>)\n",
      "tensor(2.6964, grad_fn=<DivBackward1>)\n",
      "tensor(2.6986, grad_fn=<DivBackward1>)\n",
      "tensor(2.7017, grad_fn=<DivBackward1>)\n",
      "tensor(2.7132, grad_fn=<DivBackward1>)\n",
      "tensor(2.7232, grad_fn=<DivBackward1>)\n",
      "tensor(2.7536, grad_fn=<DivBackward1>)\n",
      "tensor(2.7388, grad_fn=<DivBackward1>)\n",
      "tensor(2.7424, grad_fn=<DivBackward1>)\n",
      "tensor(2.7180, grad_fn=<DivBackward1>)\n",
      "tensor(2.7164, grad_fn=<DivBackward1>)\n",
      "tensor(2.7082, grad_fn=<DivBackward1>)\n",
      "tensor(2.7103, grad_fn=<DivBackward1>)\n",
      "tensor(2.7050, grad_fn=<DivBackward1>)\n",
      "tensor(2.7085, grad_fn=<DivBackward1>)\n",
      "tensor(2.7041, grad_fn=<DivBackward1>)\n",
      "tensor(2.7087, grad_fn=<DivBackward1>)\n",
      "tensor(2.7043, grad_fn=<DivBackward1>)\n",
      "tensor(2.7099, grad_fn=<DivBackward1>)\n",
      "tensor(2.7048, grad_fn=<DivBackward1>)\n",
      "tensor(2.7108, grad_fn=<DivBackward1>)\n",
      "tensor(2.7049, grad_fn=<DivBackward1>)\n",
      "tensor(2.7110, grad_fn=<DivBackward1>)\n",
      "tensor(2.7044, grad_fn=<DivBackward1>)\n",
      "tensor(2.7104, grad_fn=<DivBackward1>)\n",
      "tensor(2.7035, grad_fn=<DivBackward1>)\n",
      "tensor(2.7095, grad_fn=<DivBackward1>)\n",
      "tensor(2.7027, grad_fn=<DivBackward1>)\n",
      "tensor(2.7087, grad_fn=<DivBackward1>)\n",
      "tensor(2.7018, grad_fn=<DivBackward1>)\n",
      "tensor(2.7080, grad_fn=<DivBackward1>)\n",
      "tensor(2.7013, grad_fn=<DivBackward1>)\n",
      "tensor(2.7078, grad_fn=<DivBackward1>)\n",
      "tensor(2.7007, grad_fn=<DivBackward1>)\n",
      "tensor(2.7075, grad_fn=<DivBackward1>)\n",
      "tensor(2.7003, grad_fn=<DivBackward1>)\n",
      "tensor(2.7071, grad_fn=<DivBackward1>)\n",
      "tensor(2.6997, grad_fn=<DivBackward1>)\n",
      "tensor(2.7066, grad_fn=<DivBackward1>)\n",
      "tensor(2.6992, grad_fn=<DivBackward1>)\n",
      "tensor(2.7063, grad_fn=<DivBackward1>)\n",
      "tensor(2.6984, grad_fn=<DivBackward1>)\n",
      "tensor(2.7056, grad_fn=<DivBackward1>)\n",
      "tensor(2.6980, grad_fn=<DivBackward1>)\n",
      "tensor(2.7054, grad_fn=<DivBackward1>)\n",
      "tensor(2.6974, grad_fn=<DivBackward1>)\n",
      "tensor(2.7050, grad_fn=<DivBackward1>)\n",
      "tensor(2.6969, grad_fn=<DivBackward1>)\n",
      "tensor(2.7045, grad_fn=<DivBackward1>)\n",
      "tensor(2.6963, grad_fn=<DivBackward1>)\n",
      "tensor(2.7039, grad_fn=<DivBackward1>)\n",
      "tensor(2.6958, grad_fn=<DivBackward1>)\n",
      "tensor(2.7035, grad_fn=<DivBackward1>)\n",
      "tensor(2.6951, grad_fn=<DivBackward1>)\n",
      "tensor(2.7028, grad_fn=<DivBackward1>)\n",
      "tensor(2.6946, grad_fn=<DivBackward1>)\n",
      "tensor(2.7026, grad_fn=<DivBackward1>)\n",
      "tensor(2.6941, grad_fn=<DivBackward1>)\n",
      "tensor(2.7019, grad_fn=<DivBackward1>)\n",
      "tensor(2.6936, grad_fn=<DivBackward1>)\n",
      "tensor(2.7015, grad_fn=<DivBackward1>)\n",
      "tensor(2.6930, grad_fn=<DivBackward1>)\n",
      "tensor(2.7010, grad_fn=<DivBackward1>)\n",
      "tensor(2.6925, grad_fn=<DivBackward1>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[437], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     31\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 32\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_pairs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictable_chars\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# for batch in dls.train:\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m#     xb, yb = batch\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m#     xb = to_bw_flattened(xb)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# print(f\"Avg loss: {tot_loss / valid_batches}, Avg acc: {tot_acc / valid_batches}\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[437], line 17\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(xb, yb)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(xb, yb):\n\u001b[0;32m---> 17\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(preds, yb)\n\u001b[1;32m     20\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/ai-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/ai-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/ai-base/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/ai-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/ai-base/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/ai-base/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_neurons = 100\n",
    "predictable_chars = len(letters) + 1\n",
    "total_pairs = len(ptoi)\n",
    "\n",
    "epochs = 100\n",
    "lr = 3\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(total_pairs, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, predictable_chars),\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr, weight_decay=0.01)\n",
    "\n",
    "def train_step(xb, yb):\n",
    "    preds = model(xb)\n",
    "    loss = loss_fn(preds, yb)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss\n",
    "\n",
    "# def valid_step(xb):\n",
    "#     preds = model(xb)\n",
    "#     loss = loss_fn(preds)\n",
    "#     return loss\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    loss = train_step(\n",
    "        F.one_hot(xs.to(torch.int64), total_pairs).float(), \n",
    "        F.one_hot(ys.to(torch.int64), predictable_chars).float()\n",
    "    )\n",
    "    print(loss)\n",
    "    # for batch in dls.train:\n",
    "    #     xb, yb = batch\n",
    "    #     xb = to_bw_flattened(xb)\n",
    "    #     xb, yb = to_torch_tensor(xb, yb)\n",
    "    #     loss, acc = train_step(xb, yb)\n",
    "\n",
    "    # print(f\"Avg loss: {tot_loss / valid_batches}, Avg acc: {tot_acc / valid_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.a',\n",
       " '.b',\n",
       " '.c',\n",
       " '.d',\n",
       " '.e',\n",
       " '.f',\n",
       " '.g',\n",
       " '.h',\n",
       " '.i',\n",
       " '.j',\n",
       " '.k',\n",
       " '.l',\n",
       " '.m',\n",
       " '.n',\n",
       " '.o',\n",
       " '.p',\n",
       " '.q',\n",
       " '.r',\n",
       " '.s',\n",
       " '.t',\n",
       " '.u',\n",
       " '.v',\n",
       " '.w',\n",
       " '.x',\n",
       " '.y',\n",
       " '.z']"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starters = [p for p in pairs if p[0] == '.' and p != '..']\n",
    "starters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xeeoimoavnbask\n",
      "kl\n",
      "bwa\n",
      "hahihgalf\n",
      "badjapnilen\n",
      "gaaitnaue\n",
      "vuhyiarngya\n",
      "wdainadiabturs\n",
      "kslmyianeauhla\n",
      "msnvoinennerga\n",
      "keahmceavaptay\n",
      "cyxoeseiarasan\n",
      "fcllua\n",
      "kreeanneqneaaa\n",
      "ee\n",
      "heai\n",
      "llayzaf\n",
      "mrylaxlnonlt\n",
      "eeeayro\n",
      "keaelnnha\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "words_to_gen = 20\n",
    "for wi in range(words_to_gen):\n",
    "    # word_len = torch.randint(min(word_lens), max(word_lens), (1,)).item()\n",
    "    # for i in range(int(word_len)):\n",
    "    li = 0\n",
    "    next_letter = ''\n",
    "    # e.g. \".a\"\n",
    "    genned_word = starters[random.randint(0, len(starters) - 1)]\n",
    "    while next_letter != '.' and len(genned_word) < max(word_lens):\n",
    "        prior_pair = genned_word[li] + genned_word[li+1]\n",
    "        prior_pair_i = ptoi[prior_pair]\n",
    "        prior_pair_i_one_hot = F.one_hot(\n",
    "            torch.tensor(prior_pair_i), total_pairs\n",
    "        ).float()\n",
    "\n",
    "        probs = torch.nn.Softmax()(model(prior_pair_i_one_hot))\n",
    "        pred = torch.multinomial(probs, 1, replacement=True).item()\n",
    "        next_letter = itos[int(pred)]\n",
    "\n",
    "        # next_sample_p = P[prior_letter_i]\n",
    "        # next_letter_idx = torch.multinomial(\n",
    "        #         next_sample_p, 1, replacement=True, generator=g\n",
    "        #     ).item()\n",
    "        # next_letter = itos[next_letter_idx]\n",
    "        genned_word += next_letter\n",
    "        li += 1\n",
    "    print(genned_word.strip('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Test Split\n",
    "\n",
    "E02: split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordsDataset(Dataset):\n",
    "    def __init__(self, words_file_dir):\n",
    "        self.words_file_dir = words_file_dir\n",
    "        self.words = open(words_file_dir).read().splitlines()\n",
    "        \n",
    "        xs = []\n",
    "        ys = []\n",
    "        for w in self.words:\n",
    "            wdot = f'.{w}.'\n",
    "            for i in range(len(wdot) - 2):\n",
    "                pair = wdot[i] + wdot[i+1]\n",
    "                xs.append(ptoi[pair])\n",
    "                ys.append(stoi[wdot[i+2]])\n",
    "\n",
    "        self.xs = torch.tensor(xs)\n",
    "        self.ys = torch.tensor(ys)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # return F.one_hot(self.xs[idx], total_pairs).float(), F.one_hot(self.ys[idx], predictable_chars).float()\n",
    "        return F.one_hot(self.xs[idx], total_pairs).float(), self.ys[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156891, 19611, 19611)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = WordsDataset('names.txt')\n",
    "train_data, dev_data, test_data = torch.utils.data.random_split(\n",
    "    full_data, [0.8, 0.1, 0.1]\n",
    ")\n",
    "len(train_data), len(dev_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "dev_dl = DataLoader(dev_data, batch_size=256, shuffle=True)\n",
    "test_dl = DataLoader(test_data, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1; Train loss: 2.478865760380059; Valid loss: 2.3297139112051433\n",
      "Epoch: 2; Train loss: 2.240069600147291; Valid loss: 2.2234733507230686\n",
      "Epoch: 3; Train loss: 2.1854187545729693; Valid loss: 2.195639046755704\n",
      "Epoch: 4; Train loss: 2.1607985934075487; Valid loss: 2.176535850995547\n",
      "Epoch: 5; Train loss: 2.146448504088559; Valid loss: 2.1770438095191857\n",
      "Epoch: 6; Train loss: 2.1334736592228998; Valid loss: 2.1644874176421722\n",
      "Epoch: 7; Train loss: 2.126377756599501; Valid loss: 2.158960958579918\n",
      "Epoch: 8; Train loss: 2.11990780931507; Valid loss: 2.152849623135158\n",
      "Epoch: 9; Train loss: 2.115403890609741; Valid loss: 2.1530039852315728\n",
      "Epoch: 10; Train loss: 2.112162614335438; Valid loss: 2.163072694431652\n",
      "Epoch: 11; Train loss: 2.108507923745409; Valid loss: 2.1507596567079617\n",
      "Epoch: 12; Train loss: 2.1063981013430273; Valid loss: 2.164969112965968\n",
      "Epoch: 13; Train loss: 2.1039171353055446; Valid loss: 2.1443202077568353\n",
      "Epoch: 14; Train loss: 2.102816231682483; Valid loss: 2.143884626301852\n",
      "Epoch: 15; Train loss: 2.0999715205701297; Valid loss: 2.1414537878779623\n",
      "Epoch: 16; Train loss: 2.0992738691084147; Valid loss: 2.138731772249395\n",
      "Epoch: 17; Train loss: 2.097322661374949; Valid loss: 2.1471016190268775\n",
      "Epoch: 18; Train loss: 2.096865316977509; Valid loss: 2.1535281159661035\n",
      "Epoch: 19; Train loss: 2.0952138278457118; Valid loss: 2.1389693207555003\n",
      "Epoch: 20; Train loss: 2.09471922928124; Valid loss: 2.1490364059225304\n",
      "Test loss: 2.1206584549569465\n"
     ]
    }
   ],
   "source": [
    "hidden_neurons = 100\n",
    "predictable_chars = len(letters) + 1\n",
    "total_pairs = len(ptoi)\n",
    "\n",
    "epochs = 20\n",
    "lr = 0.9\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(total_pairs, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_neurons, predictable_chars),\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr, weight_decay=0.00001)\n",
    "\n",
    "def train_step(xb, yb):\n",
    "    preds = model(xb)\n",
    "    loss = loss_fn(preds, yb)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss\n",
    "\n",
    "def valid_step(xb, yb):\n",
    "    preds = model(xb)\n",
    "    loss = loss_fn(preds, yb)\n",
    "    return loss\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    tot_train_loss = 0\n",
    "    for batch in train_dl:\n",
    "        xb, yb = batch\n",
    "        loss = train_step(xb, yb)\n",
    "        tot_train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    tot_dev_loss = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch in dev_dl:\n",
    "            xb, yb = batch\n",
    "            loss = valid_step(xb, yb)\n",
    "            tot_dev_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}; Train loss: {tot_train_loss / len(train_dl)}; Valid loss: {tot_dev_loss / len(dev_dl)}\")\n",
    "\n",
    "model.eval()\n",
    "tot_test_loss = 0\n",
    "with torch.inference_mode():\n",
    "    for batch in test_dl:\n",
    "        xb, yb = batch\n",
    "        loss = valid_step(xb, yb)\n",
    "        tot_test_loss += loss.item()\n",
    "\n",
    "print(f\"Test loss: {tot_test_loss / len(test_dl)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test loss with 10 epochs:\n",
    "* lr 0.5 and weight_decay 0.01 = 2.58\n",
    "* lr 0.5 and weight_decay 0.05 = 2.76 (basically didn't train)\n",
    "* lr 0.5 and weight_decay 0.005 = 2.44 (way better)\n",
    "* lr 0.5 and weight_decay 0.001 = 2.16 (still improving)\n",
    "* lr 0.5 and weight_decay 0.0001 = 2.15 (marginal gain)\n",
    "* lr 0.5 and weight_decay 0.00001 = 2.13\n",
    "* lr 0.5 and weight_decay 0.000001 = 2.13 (sticking with prior)\n",
    "* lr 0.9 and weight_decay 0.00001 = 2.12 **best**\n",
    "* lr 1.5 and weight_decay 0.00001 = 2.135 (starting to overfit? train was still going down)\n",
    "* lr 1.5 and weight_decay 0.0001 = 2.130 (lower lr was better)\n",
    "\n",
    "Test loss with 20 epochs at best settings:\n",
    "2.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ter\n",
      "maxona\n",
      "riazah\n",
      "gus\n",
      "ka\n",
      "jaxlesh\n",
      "arucrohermi\n",
      "wa\n",
      "bra\n",
      "farielyn\n",
      "dee\n",
      "lukand\n",
      "eli\n",
      "kyn\n",
      "nasi\n",
      "jabenn\n",
      "bramarsyra\n",
      "araemai\n",
      "kia\n",
      "wilayzriyah\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "words_to_gen = 20\n",
    "for wi in range(words_to_gen):\n",
    "    li = 0\n",
    "    next_letter = ''\n",
    "    # e.g. \".a\"\n",
    "    genned_word = starters[random.randint(0, len(starters) - 1)]\n",
    "    while next_letter != '.' and len(genned_word) < max(word_lens):\n",
    "        prior_pair = genned_word[li] + genned_word[li+1]\n",
    "        prior_pair_i = ptoi[prior_pair]\n",
    "        prior_pair_i_one_hot = F.one_hot(\n",
    "            torch.tensor(prior_pair_i), total_pairs\n",
    "        ).float()\n",
    "\n",
    "        probs = torch.nn.Softmax()(model(prior_pair_i_one_hot))\n",
    "        pred = torch.multinomial(probs, 1, replacement=True).item()\n",
    "        next_letter = itos[int(pred)]\n",
    "\n",
    "        genned_word += next_letter\n",
    "        li += 1\n",
    "    print(genned_word.strip('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "- Rebuild training set to take 3 letter inputs and predict next letter\n",
    "    - Build using raw pytorch without their model (i.e. do own matrix multiplies, initialize own weights, etc make sure to call requires_grad=True)\n",
    "    - Note, he includes \"...\", \"..a\", etc., so \".\" can occur more than once\n",
    "    - Can I improve the model without these? Try after the rest is done.\n",
    "- Create an embedding lookup table (he started with 2 dimensional embedding, one for each of the 27 characters, so was able to plot them before increasing embedding size)\n",
    "- Create the full model based on the paper\n",
    "    - He used cross entropy loss\n",
    "    - Use mini batches (he started with batches of 32, and instead of partitioning them out evenly, just shuffled via torch.randint)\n",
    "- Determine best learning rate (create pool of lrs from 0-1000 with torch.linspace, run training from lowest to highest training via batches, plot learn rate vs loss, best LR around where loss stops decreasing, and definitely before it explodes/starts increasing or being unstable)\n",
    "- After training stops/slows down at optimal learning rate, try some learning rate decay to learn some more (decrease lr by factor of 10)\n",
    "- Split into train/dev/test since we'll be tuning hyperparameters\n",
    "- Once we've optimized our model on learning rate, we can try increasing the hidden layer size (he used 300) and train again, then try increasing embedding dimensions\n",
    "- Try to beat his dev loss of 2.17 (or my prior one of 2.12 with the prior model)\n",
    "- Read Paper Bengio et al. 2003 (MLP langauge model)\n",
    "\n",
    "### Exercises\n",
    "\n",
    "E01: Tune the hyperparameters of the training to beat my best validation loss of 2.2\n",
    "E02: I was not careful with the intialization of the network in this video. (1) What is the loss you'd get if the predicted probabilities at initialization were perfectly uniform? What loss do we achieve? (2) Can you tune the initialization to get a starting loss that is much more similar to (1)?\n",
    "E03: Read the Bengio et al 2003 paper (link above), implement and try any idea from the paper. Did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters + ['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'...': 0,\n",
       " '..a': 1,\n",
       " '..b': 2,\n",
       " '..c': 3,\n",
       " '..d': 4,\n",
       " '..e': 5,\n",
       " '..f': 6,\n",
       " '..g': 7,\n",
       " '..h': 8,\n",
       " '..i': 9,\n",
       " '..j': 10,\n",
       " '..k': 11,\n",
       " '..l': 12,\n",
       " '..m': 13,\n",
       " '..n': 14,\n",
       " '..o': 15,\n",
       " '..p': 16,\n",
       " '..q': 17,\n",
       " '..r': 18,\n",
       " '..s': 19,\n",
       " '..t': 20,\n",
       " '..u': 21,\n",
       " '..v': 22,\n",
       " '..w': 23,\n",
       " '..x': 24,\n",
       " '..y': 25,\n",
       " '..z': 26,\n",
       " '.a.': 27,\n",
       " '.aa': 28,\n",
       " '.ab': 29,\n",
       " '.ac': 30,\n",
       " '.ad': 31,\n",
       " '.ae': 32,\n",
       " '.af': 33,\n",
       " '.ag': 34,\n",
       " '.ah': 35,\n",
       " '.ai': 36,\n",
       " '.aj': 37,\n",
       " '.ak': 38,\n",
       " '.al': 39,\n",
       " '.am': 40,\n",
       " '.an': 41,\n",
       " '.ao': 42,\n",
       " '.ap': 43,\n",
       " '.aq': 44,\n",
       " '.ar': 45,\n",
       " '.as': 46,\n",
       " '.at': 47,\n",
       " '.au': 48,\n",
       " '.av': 49,\n",
       " '.aw': 50,\n",
       " '.ax': 51,\n",
       " '.ay': 52,\n",
       " '.az': 53,\n",
       " '.b.': 54,\n",
       " '.ba': 55,\n",
       " '.bb': 56,\n",
       " '.bc': 57,\n",
       " '.bd': 58,\n",
       " '.be': 59,\n",
       " '.bf': 60,\n",
       " '.bg': 61,\n",
       " '.bh': 62,\n",
       " '.bi': 63,\n",
       " '.bj': 64,\n",
       " '.bk': 65,\n",
       " '.bl': 66,\n",
       " '.bm': 67,\n",
       " '.bn': 68,\n",
       " '.bo': 69,\n",
       " '.bp': 70,\n",
       " '.bq': 71,\n",
       " '.br': 72,\n",
       " '.bs': 73,\n",
       " '.bt': 74,\n",
       " '.bu': 75,\n",
       " '.bv': 76,\n",
       " '.bw': 77,\n",
       " '.bx': 78,\n",
       " '.by': 79,\n",
       " '.bz': 80,\n",
       " '.c.': 81,\n",
       " '.ca': 82,\n",
       " '.cb': 83,\n",
       " '.cc': 84,\n",
       " '.cd': 85,\n",
       " '.ce': 86,\n",
       " '.cf': 87,\n",
       " '.cg': 88,\n",
       " '.ch': 89,\n",
       " '.ci': 90,\n",
       " '.cj': 91,\n",
       " '.ck': 92,\n",
       " '.cl': 93,\n",
       " '.cm': 94,\n",
       " '.cn': 95,\n",
       " '.co': 96,\n",
       " '.cp': 97,\n",
       " '.cq': 98,\n",
       " '.cr': 99,\n",
       " '.cs': 100,\n",
       " '.ct': 101,\n",
       " '.cu': 102,\n",
       " '.cv': 103,\n",
       " '.cw': 104,\n",
       " '.cx': 105,\n",
       " '.cy': 106,\n",
       " '.cz': 107,\n",
       " '.d.': 108,\n",
       " '.da': 109,\n",
       " '.db': 110,\n",
       " '.dc': 111,\n",
       " '.dd': 112,\n",
       " '.de': 113,\n",
       " '.df': 114,\n",
       " '.dg': 115,\n",
       " '.dh': 116,\n",
       " '.di': 117,\n",
       " '.dj': 118,\n",
       " '.dk': 119,\n",
       " '.dl': 120,\n",
       " '.dm': 121,\n",
       " '.dn': 122,\n",
       " '.do': 123,\n",
       " '.dp': 124,\n",
       " '.dq': 125,\n",
       " '.dr': 126,\n",
       " '.ds': 127,\n",
       " '.dt': 128,\n",
       " '.du': 129,\n",
       " '.dv': 130,\n",
       " '.dw': 131,\n",
       " '.dx': 132,\n",
       " '.dy': 133,\n",
       " '.dz': 134,\n",
       " '.e.': 135,\n",
       " '.ea': 136,\n",
       " '.eb': 137,\n",
       " '.ec': 138,\n",
       " '.ed': 139,\n",
       " '.ee': 140,\n",
       " '.ef': 141,\n",
       " '.eg': 142,\n",
       " '.eh': 143,\n",
       " '.ei': 144,\n",
       " '.ej': 145,\n",
       " '.ek': 146,\n",
       " '.el': 147,\n",
       " '.em': 148,\n",
       " '.en': 149,\n",
       " '.eo': 150,\n",
       " '.ep': 151,\n",
       " '.eq': 152,\n",
       " '.er': 153,\n",
       " '.es': 154,\n",
       " '.et': 155,\n",
       " '.eu': 156,\n",
       " '.ev': 157,\n",
       " '.ew': 158,\n",
       " '.ex': 159,\n",
       " '.ey': 160,\n",
       " '.ez': 161,\n",
       " '.f.': 162,\n",
       " '.fa': 163,\n",
       " '.fb': 164,\n",
       " '.fc': 165,\n",
       " '.fd': 166,\n",
       " '.fe': 167,\n",
       " '.ff': 168,\n",
       " '.fg': 169,\n",
       " '.fh': 170,\n",
       " '.fi': 171,\n",
       " '.fj': 172,\n",
       " '.fk': 173,\n",
       " '.fl': 174,\n",
       " '.fm': 175,\n",
       " '.fn': 176,\n",
       " '.fo': 177,\n",
       " '.fp': 178,\n",
       " '.fq': 179,\n",
       " '.fr': 180,\n",
       " '.fs': 181,\n",
       " '.ft': 182,\n",
       " '.fu': 183,\n",
       " '.fv': 184,\n",
       " '.fw': 185,\n",
       " '.fx': 186,\n",
       " '.fy': 187,\n",
       " '.fz': 188,\n",
       " '.g.': 189,\n",
       " '.ga': 190,\n",
       " '.gb': 191,\n",
       " '.gc': 192,\n",
       " '.gd': 193,\n",
       " '.ge': 194,\n",
       " '.gf': 195,\n",
       " '.gg': 196,\n",
       " '.gh': 197,\n",
       " '.gi': 198,\n",
       " '.gj': 199,\n",
       " '.gk': 200,\n",
       " '.gl': 201,\n",
       " '.gm': 202,\n",
       " '.gn': 203,\n",
       " '.go': 204,\n",
       " '.gp': 205,\n",
       " '.gq': 206,\n",
       " '.gr': 207,\n",
       " '.gs': 208,\n",
       " '.gt': 209,\n",
       " '.gu': 210,\n",
       " '.gv': 211,\n",
       " '.gw': 212,\n",
       " '.gx': 213,\n",
       " '.gy': 214,\n",
       " '.gz': 215,\n",
       " '.h.': 216,\n",
       " '.ha': 217,\n",
       " '.hb': 218,\n",
       " '.hc': 219,\n",
       " '.hd': 220,\n",
       " '.he': 221,\n",
       " '.hf': 222,\n",
       " '.hg': 223,\n",
       " '.hh': 224,\n",
       " '.hi': 225,\n",
       " '.hj': 226,\n",
       " '.hk': 227,\n",
       " '.hl': 228,\n",
       " '.hm': 229,\n",
       " '.hn': 230,\n",
       " '.ho': 231,\n",
       " '.hp': 232,\n",
       " '.hq': 233,\n",
       " '.hr': 234,\n",
       " '.hs': 235,\n",
       " '.ht': 236,\n",
       " '.hu': 237,\n",
       " '.hv': 238,\n",
       " '.hw': 239,\n",
       " '.hx': 240,\n",
       " '.hy': 241,\n",
       " '.hz': 242,\n",
       " '.i.': 243,\n",
       " '.ia': 244,\n",
       " '.ib': 245,\n",
       " '.ic': 246,\n",
       " '.id': 247,\n",
       " '.ie': 248,\n",
       " '.if': 249,\n",
       " '.ig': 250,\n",
       " '.ih': 251,\n",
       " '.ii': 252,\n",
       " '.ij': 253,\n",
       " '.ik': 254,\n",
       " '.il': 255,\n",
       " '.im': 256,\n",
       " '.in': 257,\n",
       " '.io': 258,\n",
       " '.ip': 259,\n",
       " '.iq': 260,\n",
       " '.ir': 261,\n",
       " '.is': 262,\n",
       " '.it': 263,\n",
       " '.iu': 264,\n",
       " '.iv': 265,\n",
       " '.iw': 266,\n",
       " '.ix': 267,\n",
       " '.iy': 268,\n",
       " '.iz': 269,\n",
       " '.j.': 270,\n",
       " '.ja': 271,\n",
       " '.jb': 272,\n",
       " '.jc': 273,\n",
       " '.jd': 274,\n",
       " '.je': 275,\n",
       " '.jf': 276,\n",
       " '.jg': 277,\n",
       " '.jh': 278,\n",
       " '.ji': 279,\n",
       " '.jj': 280,\n",
       " '.jk': 281,\n",
       " '.jl': 282,\n",
       " '.jm': 283,\n",
       " '.jn': 284,\n",
       " '.jo': 285,\n",
       " '.jp': 286,\n",
       " '.jq': 287,\n",
       " '.jr': 288,\n",
       " '.js': 289,\n",
       " '.jt': 290,\n",
       " '.ju': 291,\n",
       " '.jv': 292,\n",
       " '.jw': 293,\n",
       " '.jx': 294,\n",
       " '.jy': 295,\n",
       " '.jz': 296,\n",
       " '.k.': 297,\n",
       " '.ka': 298,\n",
       " '.kb': 299,\n",
       " '.kc': 300,\n",
       " '.kd': 301,\n",
       " '.ke': 302,\n",
       " '.kf': 303,\n",
       " '.kg': 304,\n",
       " '.kh': 305,\n",
       " '.ki': 306,\n",
       " '.kj': 307,\n",
       " '.kk': 308,\n",
       " '.kl': 309,\n",
       " '.km': 310,\n",
       " '.kn': 311,\n",
       " '.ko': 312,\n",
       " '.kp': 313,\n",
       " '.kq': 314,\n",
       " '.kr': 315,\n",
       " '.ks': 316,\n",
       " '.kt': 317,\n",
       " '.ku': 318,\n",
       " '.kv': 319,\n",
       " '.kw': 320,\n",
       " '.kx': 321,\n",
       " '.ky': 322,\n",
       " '.kz': 323,\n",
       " '.l.': 324,\n",
       " '.la': 325,\n",
       " '.lb': 326,\n",
       " '.lc': 327,\n",
       " '.ld': 328,\n",
       " '.le': 329,\n",
       " '.lf': 330,\n",
       " '.lg': 331,\n",
       " '.lh': 332,\n",
       " '.li': 333,\n",
       " '.lj': 334,\n",
       " '.lk': 335,\n",
       " '.ll': 336,\n",
       " '.lm': 337,\n",
       " '.ln': 338,\n",
       " '.lo': 339,\n",
       " '.lp': 340,\n",
       " '.lq': 341,\n",
       " '.lr': 342,\n",
       " '.ls': 343,\n",
       " '.lt': 344,\n",
       " '.lu': 345,\n",
       " '.lv': 346,\n",
       " '.lw': 347,\n",
       " '.lx': 348,\n",
       " '.ly': 349,\n",
       " '.lz': 350,\n",
       " '.m.': 351,\n",
       " '.ma': 352,\n",
       " '.mb': 353,\n",
       " '.mc': 354,\n",
       " '.md': 355,\n",
       " '.me': 356,\n",
       " '.mf': 357,\n",
       " '.mg': 358,\n",
       " '.mh': 359,\n",
       " '.mi': 360,\n",
       " '.mj': 361,\n",
       " '.mk': 362,\n",
       " '.ml': 363,\n",
       " '.mm': 364,\n",
       " '.mn': 365,\n",
       " '.mo': 366,\n",
       " '.mp': 367,\n",
       " '.mq': 368,\n",
       " '.mr': 369,\n",
       " '.ms': 370,\n",
       " '.mt': 371,\n",
       " '.mu': 372,\n",
       " '.mv': 373,\n",
       " '.mw': 374,\n",
       " '.mx': 375,\n",
       " '.my': 376,\n",
       " '.mz': 377,\n",
       " '.n.': 378,\n",
       " '.na': 379,\n",
       " '.nb': 380,\n",
       " '.nc': 381,\n",
       " '.nd': 382,\n",
       " '.ne': 383,\n",
       " '.nf': 384,\n",
       " '.ng': 385,\n",
       " '.nh': 386,\n",
       " '.ni': 387,\n",
       " '.nj': 388,\n",
       " '.nk': 389,\n",
       " '.nl': 390,\n",
       " '.nm': 391,\n",
       " '.nn': 392,\n",
       " '.no': 393,\n",
       " '.np': 394,\n",
       " '.nq': 395,\n",
       " '.nr': 396,\n",
       " '.ns': 397,\n",
       " '.nt': 398,\n",
       " '.nu': 399,\n",
       " '.nv': 400,\n",
       " '.nw': 401,\n",
       " '.nx': 402,\n",
       " '.ny': 403,\n",
       " '.nz': 404,\n",
       " '.o.': 405,\n",
       " '.oa': 406,\n",
       " '.ob': 407,\n",
       " '.oc': 408,\n",
       " '.od': 409,\n",
       " '.oe': 410,\n",
       " '.of': 411,\n",
       " '.og': 412,\n",
       " '.oh': 413,\n",
       " '.oi': 414,\n",
       " '.oj': 415,\n",
       " '.ok': 416,\n",
       " '.ol': 417,\n",
       " '.om': 418,\n",
       " '.on': 419,\n",
       " '.oo': 420,\n",
       " '.op': 421,\n",
       " '.oq': 422,\n",
       " '.or': 423,\n",
       " '.os': 424,\n",
       " '.ot': 425,\n",
       " '.ou': 426,\n",
       " '.ov': 427,\n",
       " '.ow': 428,\n",
       " '.ox': 429,\n",
       " '.oy': 430,\n",
       " '.oz': 431,\n",
       " '.p.': 432,\n",
       " '.pa': 433,\n",
       " '.pb': 434,\n",
       " '.pc': 435,\n",
       " '.pd': 436,\n",
       " '.pe': 437,\n",
       " '.pf': 438,\n",
       " '.pg': 439,\n",
       " '.ph': 440,\n",
       " '.pi': 441,\n",
       " '.pj': 442,\n",
       " '.pk': 443,\n",
       " '.pl': 444,\n",
       " '.pm': 445,\n",
       " '.pn': 446,\n",
       " '.po': 447,\n",
       " '.pp': 448,\n",
       " '.pq': 449,\n",
       " '.pr': 450,\n",
       " '.ps': 451,\n",
       " '.pt': 452,\n",
       " '.pu': 453,\n",
       " '.pv': 454,\n",
       " '.pw': 455,\n",
       " '.px': 456,\n",
       " '.py': 457,\n",
       " '.pz': 458,\n",
       " '.q.': 459,\n",
       " '.qa': 460,\n",
       " '.qb': 461,\n",
       " '.qc': 462,\n",
       " '.qd': 463,\n",
       " '.qe': 464,\n",
       " '.qf': 465,\n",
       " '.qg': 466,\n",
       " '.qh': 467,\n",
       " '.qi': 468,\n",
       " '.qj': 469,\n",
       " '.qk': 470,\n",
       " '.ql': 471,\n",
       " '.qm': 472,\n",
       " '.qn': 473,\n",
       " '.qo': 474,\n",
       " '.qp': 475,\n",
       " '.qq': 476,\n",
       " '.qr': 477,\n",
       " '.qs': 478,\n",
       " '.qt': 479,\n",
       " '.qu': 480,\n",
       " '.qv': 481,\n",
       " '.qw': 482,\n",
       " '.qx': 483,\n",
       " '.qy': 484,\n",
       " '.qz': 485,\n",
       " '.r.': 486,\n",
       " '.ra': 487,\n",
       " '.rb': 488,\n",
       " '.rc': 489,\n",
       " '.rd': 490,\n",
       " '.re': 491,\n",
       " '.rf': 492,\n",
       " '.rg': 493,\n",
       " '.rh': 494,\n",
       " '.ri': 495,\n",
       " '.rj': 496,\n",
       " '.rk': 497,\n",
       " '.rl': 498,\n",
       " '.rm': 499,\n",
       " '.rn': 500,\n",
       " '.ro': 501,\n",
       " '.rp': 502,\n",
       " '.rq': 503,\n",
       " '.rr': 504,\n",
       " '.rs': 505,\n",
       " '.rt': 506,\n",
       " '.ru': 507,\n",
       " '.rv': 508,\n",
       " '.rw': 509,\n",
       " '.rx': 510,\n",
       " '.ry': 511,\n",
       " '.rz': 512,\n",
       " '.s.': 513,\n",
       " '.sa': 514,\n",
       " '.sb': 515,\n",
       " '.sc': 516,\n",
       " '.sd': 517,\n",
       " '.se': 518,\n",
       " '.sf': 519,\n",
       " '.sg': 520,\n",
       " '.sh': 521,\n",
       " '.si': 522,\n",
       " '.sj': 523,\n",
       " '.sk': 524,\n",
       " '.sl': 525,\n",
       " '.sm': 526,\n",
       " '.sn': 527,\n",
       " '.so': 528,\n",
       " '.sp': 529,\n",
       " '.sq': 530,\n",
       " '.sr': 531,\n",
       " '.ss': 532,\n",
       " '.st': 533,\n",
       " '.su': 534,\n",
       " '.sv': 535,\n",
       " '.sw': 536,\n",
       " '.sx': 537,\n",
       " '.sy': 538,\n",
       " '.sz': 539,\n",
       " '.t.': 540,\n",
       " '.ta': 541,\n",
       " '.tb': 542,\n",
       " '.tc': 543,\n",
       " '.td': 544,\n",
       " '.te': 545,\n",
       " '.tf': 546,\n",
       " '.tg': 547,\n",
       " '.th': 548,\n",
       " '.ti': 549,\n",
       " '.tj': 550,\n",
       " '.tk': 551,\n",
       " '.tl': 552,\n",
       " '.tm': 553,\n",
       " '.tn': 554,\n",
       " '.to': 555,\n",
       " '.tp': 556,\n",
       " '.tq': 557,\n",
       " '.tr': 558,\n",
       " '.ts': 559,\n",
       " '.tt': 560,\n",
       " '.tu': 561,\n",
       " '.tv': 562,\n",
       " '.tw': 563,\n",
       " '.tx': 564,\n",
       " '.ty': 565,\n",
       " '.tz': 566,\n",
       " '.u.': 567,\n",
       " '.ua': 568,\n",
       " '.ub': 569,\n",
       " '.uc': 570,\n",
       " '.ud': 571,\n",
       " '.ue': 572,\n",
       " '.uf': 573,\n",
       " '.ug': 574,\n",
       " '.uh': 575,\n",
       " '.ui': 576,\n",
       " '.uj': 577,\n",
       " '.uk': 578,\n",
       " '.ul': 579,\n",
       " '.um': 580,\n",
       " '.un': 581,\n",
       " '.uo': 582,\n",
       " '.up': 583,\n",
       " '.uq': 584,\n",
       " '.ur': 585,\n",
       " '.us': 586,\n",
       " '.ut': 587,\n",
       " '.uu': 588,\n",
       " '.uv': 589,\n",
       " '.uw': 590,\n",
       " '.ux': 591,\n",
       " '.uy': 592,\n",
       " '.uz': 593,\n",
       " '.v.': 594,\n",
       " '.va': 595,\n",
       " '.vb': 596,\n",
       " '.vc': 597,\n",
       " '.vd': 598,\n",
       " '.ve': 599,\n",
       " '.vf': 600,\n",
       " '.vg': 601,\n",
       " '.vh': 602,\n",
       " '.vi': 603,\n",
       " '.vj': 604,\n",
       " '.vk': 605,\n",
       " '.vl': 606,\n",
       " '.vm': 607,\n",
       " '.vn': 608,\n",
       " '.vo': 609,\n",
       " '.vp': 610,\n",
       " '.vq': 611,\n",
       " '.vr': 612,\n",
       " '.vs': 613,\n",
       " '.vt': 614,\n",
       " '.vu': 615,\n",
       " '.vv': 616,\n",
       " '.vw': 617,\n",
       " '.vx': 618,\n",
       " '.vy': 619,\n",
       " '.vz': 620,\n",
       " '.w.': 621,\n",
       " '.wa': 622,\n",
       " '.wb': 623,\n",
       " '.wc': 624,\n",
       " '.wd': 625,\n",
       " '.we': 626,\n",
       " '.wf': 627,\n",
       " '.wg': 628,\n",
       " '.wh': 629,\n",
       " '.wi': 630,\n",
       " '.wj': 631,\n",
       " '.wk': 632,\n",
       " '.wl': 633,\n",
       " '.wm': 634,\n",
       " '.wn': 635,\n",
       " '.wo': 636,\n",
       " '.wp': 637,\n",
       " '.wq': 638,\n",
       " '.wr': 639,\n",
       " '.ws': 640,\n",
       " '.wt': 641,\n",
       " '.wu': 642,\n",
       " '.wv': 643,\n",
       " '.ww': 644,\n",
       " '.wx': 645,\n",
       " '.wy': 646,\n",
       " '.wz': 647,\n",
       " '.x.': 648,\n",
       " '.xa': 649,\n",
       " '.xb': 650,\n",
       " '.xc': 651,\n",
       " '.xd': 652,\n",
       " '.xe': 653,\n",
       " '.xf': 654,\n",
       " '.xg': 655,\n",
       " '.xh': 656,\n",
       " '.xi': 657,\n",
       " '.xj': 658,\n",
       " '.xk': 659,\n",
       " '.xl': 660,\n",
       " '.xm': 661,\n",
       " '.xn': 662,\n",
       " '.xo': 663,\n",
       " '.xp': 664,\n",
       " '.xq': 665,\n",
       " '.xr': 666,\n",
       " '.xs': 667,\n",
       " '.xt': 668,\n",
       " '.xu': 669,\n",
       " '.xv': 670,\n",
       " '.xw': 671,\n",
       " '.xx': 672,\n",
       " '.xy': 673,\n",
       " '.xz': 674,\n",
       " '.y.': 675,\n",
       " '.ya': 676,\n",
       " '.yb': 677,\n",
       " '.yc': 678,\n",
       " '.yd': 679,\n",
       " '.ye': 680,\n",
       " '.yf': 681,\n",
       " '.yg': 682,\n",
       " '.yh': 683,\n",
       " '.yi': 684,\n",
       " '.yj': 685,\n",
       " '.yk': 686,\n",
       " '.yl': 687,\n",
       " '.ym': 688,\n",
       " '.yn': 689,\n",
       " '.yo': 690,\n",
       " '.yp': 691,\n",
       " '.yq': 692,\n",
       " '.yr': 693,\n",
       " '.ys': 694,\n",
       " '.yt': 695,\n",
       " '.yu': 696,\n",
       " '.yv': 697,\n",
       " '.yw': 698,\n",
       " '.yx': 699,\n",
       " '.yy': 700,\n",
       " '.yz': 701,\n",
       " '.z.': 702,\n",
       " '.za': 703,\n",
       " '.zb': 704,\n",
       " '.zc': 705,\n",
       " '.zd': 706,\n",
       " '.ze': 707,\n",
       " '.zf': 708,\n",
       " '.zg': 709,\n",
       " '.zh': 710,\n",
       " '.zi': 711,\n",
       " '.zj': 712,\n",
       " '.zk': 713,\n",
       " '.zl': 714,\n",
       " '.zm': 715,\n",
       " '.zn': 716,\n",
       " '.zo': 717,\n",
       " '.zp': 718,\n",
       " '.zq': 719,\n",
       " '.zr': 720,\n",
       " '.zs': 721,\n",
       " '.zt': 722,\n",
       " '.zu': 723,\n",
       " '.zv': 724,\n",
       " '.zw': 725,\n",
       " '.zx': 726,\n",
       " '.zy': 727,\n",
       " '.zz': 728,\n",
       " 'a..': 729,\n",
       " 'a.a': 730,\n",
       " 'a.b': 731,\n",
       " 'a.c': 732,\n",
       " 'a.d': 733,\n",
       " 'a.e': 734,\n",
       " 'a.f': 735,\n",
       " 'a.g': 736,\n",
       " 'a.h': 737,\n",
       " 'a.i': 738,\n",
       " 'a.j': 739,\n",
       " 'a.k': 740,\n",
       " 'a.l': 741,\n",
       " 'a.m': 742,\n",
       " 'a.n': 743,\n",
       " 'a.o': 744,\n",
       " 'a.p': 745,\n",
       " 'a.q': 746,\n",
       " 'a.r': 747,\n",
       " 'a.s': 748,\n",
       " 'a.t': 749,\n",
       " 'a.u': 750,\n",
       " 'a.v': 751,\n",
       " 'a.w': 752,\n",
       " 'a.x': 753,\n",
       " 'a.y': 754,\n",
       " 'a.z': 755,\n",
       " 'aa.': 756,\n",
       " 'aaa': 757,\n",
       " 'aab': 758,\n",
       " 'aac': 759,\n",
       " 'aad': 760,\n",
       " 'aae': 761,\n",
       " 'aaf': 762,\n",
       " 'aag': 763,\n",
       " 'aah': 764,\n",
       " 'aai': 765,\n",
       " 'aaj': 766,\n",
       " 'aak': 767,\n",
       " 'aal': 768,\n",
       " 'aam': 769,\n",
       " 'aan': 770,\n",
       " 'aao': 771,\n",
       " 'aap': 772,\n",
       " 'aaq': 773,\n",
       " 'aar': 774,\n",
       " 'aas': 775,\n",
       " 'aat': 776,\n",
       " 'aau': 777,\n",
       " 'aav': 778,\n",
       " 'aaw': 779,\n",
       " 'aax': 780,\n",
       " 'aay': 781,\n",
       " 'aaz': 782,\n",
       " 'ab.': 783,\n",
       " 'aba': 784,\n",
       " 'abb': 785,\n",
       " 'abc': 786,\n",
       " 'abd': 787,\n",
       " 'abe': 788,\n",
       " 'abf': 789,\n",
       " 'abg': 790,\n",
       " 'abh': 791,\n",
       " 'abi': 792,\n",
       " 'abj': 793,\n",
       " 'abk': 794,\n",
       " 'abl': 795,\n",
       " 'abm': 796,\n",
       " 'abn': 797,\n",
       " 'abo': 798,\n",
       " 'abp': 799,\n",
       " 'abq': 800,\n",
       " 'abr': 801,\n",
       " 'abs': 802,\n",
       " 'abt': 803,\n",
       " 'abu': 804,\n",
       " 'abv': 805,\n",
       " 'abw': 806,\n",
       " 'abx': 807,\n",
       " 'aby': 808,\n",
       " 'abz': 809,\n",
       " 'ac.': 810,\n",
       " 'aca': 811,\n",
       " 'acb': 812,\n",
       " 'acc': 813,\n",
       " 'acd': 814,\n",
       " 'ace': 815,\n",
       " 'acf': 816,\n",
       " 'acg': 817,\n",
       " 'ach': 818,\n",
       " 'aci': 819,\n",
       " 'acj': 820,\n",
       " 'ack': 821,\n",
       " 'acl': 822,\n",
       " 'acm': 823,\n",
       " 'acn': 824,\n",
       " 'aco': 825,\n",
       " 'acp': 826,\n",
       " 'acq': 827,\n",
       " 'acr': 828,\n",
       " 'acs': 829,\n",
       " 'act': 830,\n",
       " 'acu': 831,\n",
       " 'acv': 832,\n",
       " 'acw': 833,\n",
       " 'acx': 834,\n",
       " 'acy': 835,\n",
       " 'acz': 836,\n",
       " 'ad.': 837,\n",
       " 'ada': 838,\n",
       " 'adb': 839,\n",
       " 'adc': 840,\n",
       " 'add': 841,\n",
       " 'ade': 842,\n",
       " 'adf': 843,\n",
       " 'adg': 844,\n",
       " 'adh': 845,\n",
       " 'adi': 846,\n",
       " 'adj': 847,\n",
       " 'adk': 848,\n",
       " 'adl': 849,\n",
       " 'adm': 850,\n",
       " 'adn': 851,\n",
       " 'ado': 852,\n",
       " 'adp': 853,\n",
       " 'adq': 854,\n",
       " 'adr': 855,\n",
       " 'ads': 856,\n",
       " 'adt': 857,\n",
       " 'adu': 858,\n",
       " 'adv': 859,\n",
       " 'adw': 860,\n",
       " 'adx': 861,\n",
       " 'ady': 862,\n",
       " 'adz': 863,\n",
       " 'ae.': 864,\n",
       " 'aea': 865,\n",
       " 'aeb': 866,\n",
       " 'aec': 867,\n",
       " 'aed': 868,\n",
       " 'aee': 869,\n",
       " 'aef': 870,\n",
       " 'aeg': 871,\n",
       " 'aeh': 872,\n",
       " 'aei': 873,\n",
       " 'aej': 874,\n",
       " 'aek': 875,\n",
       " 'ael': 876,\n",
       " 'aem': 877,\n",
       " 'aen': 878,\n",
       " 'aeo': 879,\n",
       " 'aep': 880,\n",
       " 'aeq': 881,\n",
       " 'aer': 882,\n",
       " 'aes': 883,\n",
       " 'aet': 884,\n",
       " 'aeu': 885,\n",
       " 'aev': 886,\n",
       " 'aew': 887,\n",
       " 'aex': 888,\n",
       " 'aey': 889,\n",
       " 'aez': 890,\n",
       " 'af.': 891,\n",
       " 'afa': 892,\n",
       " 'afb': 893,\n",
       " 'afc': 894,\n",
       " 'afd': 895,\n",
       " 'afe': 896,\n",
       " 'aff': 897,\n",
       " 'afg': 898,\n",
       " 'afh': 899,\n",
       " 'afi': 900,\n",
       " 'afj': 901,\n",
       " 'afk': 902,\n",
       " 'afl': 903,\n",
       " 'afm': 904,\n",
       " 'afn': 905,\n",
       " 'afo': 906,\n",
       " 'afp': 907,\n",
       " 'afq': 908,\n",
       " 'afr': 909,\n",
       " 'afs': 910,\n",
       " 'aft': 911,\n",
       " 'afu': 912,\n",
       " 'afv': 913,\n",
       " 'afw': 914,\n",
       " 'afx': 915,\n",
       " 'afy': 916,\n",
       " 'afz': 917,\n",
       " 'ag.': 918,\n",
       " 'aga': 919,\n",
       " 'agb': 920,\n",
       " 'agc': 921,\n",
       " 'agd': 922,\n",
       " 'age': 923,\n",
       " 'agf': 924,\n",
       " 'agg': 925,\n",
       " 'agh': 926,\n",
       " 'agi': 927,\n",
       " 'agj': 928,\n",
       " 'agk': 929,\n",
       " 'agl': 930,\n",
       " 'agm': 931,\n",
       " 'agn': 932,\n",
       " 'ago': 933,\n",
       " 'agp': 934,\n",
       " 'agq': 935,\n",
       " 'agr': 936,\n",
       " 'ags': 937,\n",
       " 'agt': 938,\n",
       " 'agu': 939,\n",
       " 'agv': 940,\n",
       " 'agw': 941,\n",
       " 'agx': 942,\n",
       " 'agy': 943,\n",
       " 'agz': 944,\n",
       " 'ah.': 945,\n",
       " 'aha': 946,\n",
       " 'ahb': 947,\n",
       " 'ahc': 948,\n",
       " 'ahd': 949,\n",
       " 'ahe': 950,\n",
       " 'ahf': 951,\n",
       " 'ahg': 952,\n",
       " 'ahh': 953,\n",
       " 'ahi': 954,\n",
       " 'ahj': 955,\n",
       " 'ahk': 956,\n",
       " 'ahl': 957,\n",
       " 'ahm': 958,\n",
       " 'ahn': 959,\n",
       " 'aho': 960,\n",
       " 'ahp': 961,\n",
       " 'ahq': 962,\n",
       " 'ahr': 963,\n",
       " 'ahs': 964,\n",
       " 'aht': 965,\n",
       " 'ahu': 966,\n",
       " 'ahv': 967,\n",
       " 'ahw': 968,\n",
       " 'ahx': 969,\n",
       " 'ahy': 970,\n",
       " 'ahz': 971,\n",
       " 'ai.': 972,\n",
       " 'aia': 973,\n",
       " 'aib': 974,\n",
       " 'aic': 975,\n",
       " 'aid': 976,\n",
       " 'aie': 977,\n",
       " 'aif': 978,\n",
       " 'aig': 979,\n",
       " 'aih': 980,\n",
       " 'aii': 981,\n",
       " 'aij': 982,\n",
       " 'aik': 983,\n",
       " 'ail': 984,\n",
       " 'aim': 985,\n",
       " 'ain': 986,\n",
       " 'aio': 987,\n",
       " 'aip': 988,\n",
       " 'aiq': 989,\n",
       " 'air': 990,\n",
       " 'ais': 991,\n",
       " 'ait': 992,\n",
       " 'aiu': 993,\n",
       " 'aiv': 994,\n",
       " 'aiw': 995,\n",
       " 'aix': 996,\n",
       " 'aiy': 997,\n",
       " 'aiz': 998,\n",
       " 'aj.': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_groups = []\n",
    "for l in letters + ['.']:\n",
    "    for l2 in letters + ['.']:\n",
    "        for l3 in letters + ['.']:\n",
    "            i = l + l2 + l3\n",
    "            letter_groups.append(i)\n",
    "\n",
    "letter_groups = sorted(letter_groups)\n",
    "lgtoi = {p:i for i, p in enumerate(letter_groups)}\n",
    "lgtoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  5, 13],\n",
       "         [ 5, 13, 13],\n",
       "         [13, 13,  1]]),\n",
       " tensor([13,  1,  0]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "for w in words:\n",
    "    wdot = f'.{w}.'\n",
    "    for i in range(len(wdot) - 3):\n",
    "        xs.append([stoi[wdot[i]], stoi[wdot[i+1]], stoi[wdot[i+2]]])\n",
    "        ys.append(stoi[wdot[i+3]])\n",
    "\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "xs[:3], ys[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0631, -0.2029],\n",
       "        [ 2.8766, -0.7994],\n",
       "        [-1.6427,  0.2011],\n",
       "        [-0.8726, -2.6461],\n",
       "        [-0.2279,  0.4190],\n",
       "        [-0.2730,  1.0746],\n",
       "        [ 0.0260,  1.4665],\n",
       "        [-0.5551, -1.1855],\n",
       "        [-0.6583, -0.2567],\n",
       "        [ 0.0440,  2.8808],\n",
       "        [-0.5162,  3.0270],\n",
       "        [-0.7207,  0.4204],\n",
       "        [-0.4111, -0.1048],\n",
       "        [ 0.0774, -0.1515],\n",
       "        [ 1.3203, -0.0547],\n",
       "        [-0.3013,  0.4203],\n",
       "        [-0.8684, -0.1510],\n",
       "        [-0.3079, -0.0278],\n",
       "        [-1.9435, -1.0159],\n",
       "        [ 0.9335, -1.6403],\n",
       "        [ 1.2955,  0.8649],\n",
       "        [-0.7816,  0.7840],\n",
       "        [-0.1503,  1.6820],\n",
       "        [ 1.0821, -2.4105],\n",
       "        [ 0.8483, -0.1123],\n",
       "        [-0.1654, -1.8554],\n",
       "        [-0.2905, -1.0411]], requires_grad=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding matrix: 2 dimensions for each of our 27 letters and .\n",
    "C = torch.randn(len(letters) + 1, 2, requires_grad=True)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0631, -0.2029],\n",
       "         [-0.2730,  1.0746],\n",
       "         [ 0.0774, -0.1515]],\n",
       "\n",
       "        [[-0.2730,  1.0746],\n",
       "         [ 0.0774, -0.1515],\n",
       "         [ 0.0774, -0.1515]],\n",
       "\n",
       "        [[ 0.0774, -0.1515],\n",
       "         [ 0.0774, -0.1515],\n",
       "         [ 2.8766, -0.7994]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.2905, -1.0411],\n",
       "         [-0.2905, -1.0411],\n",
       "         [-0.1654, -1.8554]],\n",
       "\n",
       "        [[-0.2905, -1.0411],\n",
       "         [-0.1654, -1.8554],\n",
       "         [-0.2905, -1.0411]],\n",
       "\n",
       "        [[-0.1654, -1.8554],\n",
       "         [-0.2905, -1.0411],\n",
       "         [ 0.8483, -0.1123]]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the embedding of each sample simultaneously\n",
    "# Each of the 3 letters in the sample gets its embedding pulled in\n",
    "C[xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([164080, 3])\n",
      "tensor([ 0,  5, 13])\n",
      "m\n",
      "tensor([ 0.0774, -0.1515], grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0774, -0.1515], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Here we prove out our method of getting all the embeddings of all the samples simultaneously\n",
    "# We have a tensor of shape datasetsize, 3 - 3 letters per sample\n",
    "print(xs.shape)\n",
    "print(xs[0])\n",
    "# Plucking an individual letter from the first sample (emm -> m) and getting its embedding\n",
    "print(itos[xs[0, 2].item()])\n",
    "print(C[xs[0, 2]])\n",
    "# We can prove this works and the embedding indexing is correct by manually pulling out the embedding\n",
    "print(C[stoi['m']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([164080, 3, 2])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have our dataset and embeddings, we can create our model\n",
    "# What shape does the embedding matmul layer need to be?\n",
    "# For each sample, we have 3 letters, each of which has a 2 dimensional embedding\n",
    "C[xs].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([164080, 6])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[xs].view(-1, 6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0631, -0.2029],\n",
       "         [-0.2730,  1.0746],\n",
       "         [ 0.0774, -0.1515]], grad_fn=<SelectBackward0>),\n",
       " tensor([ 0.0631, -0.2029, -0.2730,  1.0746,  0.0774, -0.1515],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " torch.Size([164080, 6]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In order to matmul against a weights layer, we need to adjust the view to \n",
    "# squeeze together the weights for each sample into 1 array\n",
    "# .view is extremely efficient for this.\n",
    "# -1 indicates torch should infer the remainder - since we say 6, \n",
    "# it knows what's left is just the sample size\n",
    "C[xs][0], C[xs].view(-1, 6)[0], C[xs].view(-1, 6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matmul rules = columns in mat1 must match rows of mat2\n",
    "W1 = torch.randn(3 * 2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([164080, 6]), torch.Size([6, 100]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[xs].view(-1, 6).shape, W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8130,  0.5567, -0.8454,  ...,  0.2220, -0.8572, -0.8659],\n",
       "        [-0.2813, -0.2873, -0.0758,  ...,  0.8181, -0.8381, -0.1628],\n",
       "        [ 0.4101, -0.9823,  0.9907,  ...,  0.9825, -0.9856, -0.6687],\n",
       "        ...,\n",
       "        [ 0.8378, -0.7639,  0.8282,  ...,  0.9997,  0.9962, -1.0000],\n",
       "        [ 0.7021, -0.7984,  0.9368,  ...,  0.9979,  0.9929, -0.9999],\n",
       "        [-0.1550, -0.8173,  0.9516,  ...,  0.7609,  0.6267, -0.9993]],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, instead of feeding in an index for every item in the vocab (each of the 3 letter combos)\n",
    "# we feed in the embeddings - one for each letter\n",
    "emb = C[xs].view(-1, 6)\n",
    "W1 = torch.randn(3*2, 100, requires_grad=True)\n",
    "B1 = torch.randn(1, 100, requires_grad=True)\n",
    "h = torch.tanh((emb @ W1) + B1)\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.1993,   7.8002, -17.5028,  ...,  -3.8611,  -8.4735,  -0.7769],\n",
       "         [  0.8250,  12.4768,  -8.3885,  ...,  12.0273,  12.3067,   3.7830],\n",
       "         [ -3.0201,  12.7769,  -6.0181,  ...,   8.3125,  11.0352, -12.1264],\n",
       "         ...,\n",
       "         [ -7.6937,   4.9222,   3.3658,  ..., -10.0868,  18.0513,  11.7578],\n",
       "         [-13.8144,   6.1876,  15.5580,  ...,  -5.4705,  15.6050,   6.1973],\n",
       "         [-11.3170,   3.0962,   4.9012,  ...,  -4.1695,   2.8165,  -3.4197]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " torch.Size([164080, 27]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a hidden layer, inputs mach outputs of prior\n",
    "W2 = torch.randn(100, len(letters) + 1, requires_grad=True)\n",
    "B2 = torch.randn(1, len(letters) + 1, requires_grad=True)\n",
    "logits = (h @ W2) + B2\n",
    "logits, logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6526e-11, 4.1417e-07, 7.0393e-15, 7.9912e-06, 8.4777e-18, 1.6341e-11,\n",
       "        7.4169e-18, 6.8404e-06, 7.7683e-09, 2.5394e-11, 1.3825e-18, 1.7038e-11,\n",
       "        2.7575e-07, 2.9313e-03, 1.2123e-05, 1.6497e-10, 4.0219e-06, 9.9704e-01,\n",
       "        6.5281e-19, 2.3154e-08, 7.1088e-09, 4.7216e-10, 7.6960e-14, 7.7146e-17,\n",
       "        2.6018e-17, 5.8048e-17, 1.0003e-09], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.1203, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss\n",
    "F.cross_entropy(logits, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  9.8757,   6.8974,  -0.6721,  ...,  17.8811,   8.6039,  12.5137],\n",
       "        [ 11.1974,  11.0013,  -4.2726,  ...,   9.7281,   5.2552,   7.4368],\n",
       "        [  7.9302,   3.0886,   4.0240,  ...,   7.1671,  -8.4007,   9.4945],\n",
       "        ...,\n",
       "        [ 11.4861,  -9.3848,  -9.5869,  ...,  -6.5863,  -1.4888,  -3.5241],\n",
       "        [ 10.8306,  -6.1538, -12.2600,  ...,  -0.6697,   0.4025,  -0.0759],\n",
       "        [ 14.7355,  -7.6178,  -4.6745,  ...,  12.1386,  -2.5125,   9.8109]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining all of the above, this is our model\n",
    "# First layer is the embeddings, second is a hidden layer with 100 neurons, last is the output layer\n",
    "emb = C[xs].view(-1, 6)\n",
    "W1 = torch.randn(3*2, 100, requires_grad=True)\n",
    "B1 = torch.randn(1, 100, requires_grad=True)\n",
    "h = torch.tanh((emb @ W1) + B1)\n",
    "W2 = torch.randn(100, len(letters) + 1, requires_grad=True)\n",
    "B2 = torch.randn(1, len(letters) + 1, requires_grad=True)\n",
    "logits = (h @ W2) + B2\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careful with broadcasting semantics.\n",
    "I realized I made a mistake in the shape of the bias, should be just 2, not 1,2.\n",
    "Will need to practice this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3197, -1.8988],\n",
       "         [ 1.3503,  0.5139],\n",
       "         [ 1.4483,  0.7237],\n",
       "         [-0.5174, -0.3881],\n",
       "         [-0.2633,  1.2137],\n",
       "         [ 1.0323,  0.8259]]),\n",
       " tensor([[-0.2194, -0.8094]]),\n",
       " torch.Size([6, 2]),\n",
       " torch.Size([1, 2]),\n",
       " tensor([[ 0.1002, -2.7082],\n",
       "         [ 1.1309, -0.2955],\n",
       "         [ 1.2288, -0.0857],\n",
       "         [-0.7368, -1.1976],\n",
       "         [-0.4828,  0.4043],\n",
       "         [ 0.8128,  0.0165]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_w1 = torch.randn(6, 2)\n",
    "test_b1 = torch.randn(1, 2)\n",
    "# 6, 2\n",
    "# 1, 2\n",
    "test_w1, test_b1, test_w1.shape, test_b1.shape, test_w1 + test_b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9454, -2.0285],\n",
       "         [-0.8637, -1.6595],\n",
       "         [ 2.4227, -1.2493],\n",
       "         [ 0.0531, -1.6711],\n",
       "         [-1.0206,  0.6913],\n",
       "         [-2.7342, -2.6559]]),\n",
       " tensor([ 0.4342, -0.2416]),\n",
       " torch.Size([6, 2]),\n",
       " torch.Size([2]),\n",
       " tensor([[-0.5112, -2.2700],\n",
       "         [-0.4295, -1.9011],\n",
       "         [ 2.8569, -1.4908],\n",
       "         [ 0.4872, -1.9127],\n",
       "         [-0.5864,  0.4497],\n",
       "         [-2.3000, -2.8974]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_w2 = torch.randn(6, 2)\n",
    "test_b2 = torch.randn(2)\n",
    "# 6, 2\n",
    "#    2\n",
    "test_w2, test_b2, test_w2.shape, test_b2.shape, test_w2 + test_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate param initialization\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.randn((len(letters) + 1, 2), generator=g)\n",
    "W1 = torch.randn(3*2, 100, generator=g)\n",
    "B1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn(100, len(letters) + 1, generator=g)\n",
    "B2 = torch.randn(len(letters) + 1, generator=g)\n",
    "parameters = [C, W1, B1, W2, B2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total model size\n",
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.0936, grad_fn=<NllLossBackward0>)\n",
      "tensor(14.3958, grad_fn=<NllLossBackward0>)\n",
      "tensor(13.7687, grad_fn=<NllLossBackward0>)\n",
      "tensor(13.2041, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.6962, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.2365, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.8148, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.4224, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.0534, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.7043, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.3727, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.0573, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.7573, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.4721, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.2013, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.9447, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.7022, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.4734, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.2578, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0542, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.8613, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.6776, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.5017, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3329, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.1703, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0137, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.8628, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.7174, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.5774, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.4428, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.3132, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.1888, grad_fn=<NllLossBackward0>)\n",
      "tensor(6.0692, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.9544, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8443, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.7386, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.6375, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.5407, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.4482, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.3599, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.2757, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1955, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.1193, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.0467, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9776, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.9119, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.8491, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7891, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.7316, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6764, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.6233, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5721, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5228, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4751, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.4291, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3845, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3413, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2996, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2591, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2200, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1820, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1453, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1097, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0753, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0419, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0095, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9781, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9476, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9181, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8895, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8617, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8346, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8084, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7829, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7582, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7341, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7108, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6880, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6660, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6445, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6236, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6034, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5837, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5645, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5459, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5278, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5103, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4932, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4766, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4604, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4448, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4295, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4147, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4003, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3863, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3727, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3595, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3467, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3342, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3220, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    emb = C[xs].view(-1, 6)\n",
    "    h = torch.tanh((emb @ W1) + B1)\n",
    "    logits = (h @ W2) + B2\n",
    "\n",
    "    loss = F.cross_entropy(logits, ys)\n",
    "\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    lr = 0.1\n",
    "    for p in parameters:\n",
    "        p.data -= lr * p.grad\n",
    "\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordsDataset(Dataset):\n",
    "    def __init__(self, words_file_dir):\n",
    "        self.words_file_dir = words_file_dir\n",
    "        self.words = open(words_file_dir).read().splitlines()\n",
    "        \n",
    "        xs = []\n",
    "        ys = []\n",
    "        for w in self.words:\n",
    "            wdot = f'.{w}.'\n",
    "            for i in range(len(wdot) - 3):\n",
    "                xs.append([stoi[wdot[i]], stoi[wdot[i+1]], stoi[wdot[i+2]]])\n",
    "                ys.append(stoi[wdot[i+3]])\n",
    "\n",
    "        self.xs = torch.tensor(xs)\n",
    "        self.ys = torch.tensor(ys)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.xs[idx], self.ys[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131264 16408 16408\n"
     ]
    }
   ],
   "source": [
    "full_data = WordsDataset('names.txt')\n",
    "train_data, dev_data, test_data = torch.utils.data.random_split(\n",
    "    full_data, [0.8, 0.1, 0.1]\n",
    ")\n",
    "print(len(train_data), len(dev_data), len(test_data))\n",
    "train_dl = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "dev_dl = DataLoader(dev_data, batch_size=16, shuffle=True)\n",
    "test_dl = DataLoader(test_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb: torch.Tensor):\n",
    "    emb = C[xb].view(-1, 6)\n",
    "    h = torch.tanh((emb @ W1) + B1)\n",
    "    return (h @ W2) + B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8204"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_b = []\n",
    "batches = []\n",
    "\n",
    "batch_i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    for batch in train_dl:\n",
    "        xb, yb = batch\n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(preds, yb)\n",
    "\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        loss.backward()\n",
    "\n",
    "        # lr = 0.1\n",
    "        lr = 0.01\n",
    "        for p in parameters:\n",
    "            p.data -= lr * p.grad\n",
    "\n",
    "        losses_b.append(loss.log10().item())\n",
    "        batches.append(batch_i)\n",
    "        batch_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd97843e750>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(batches, losses_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4600, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg dev loss: 2.302677301286954\n"
     ]
    }
   ],
   "source": [
    "tot_loss = 0\n",
    "for batch in dev_dl:\n",
    "    xb, yb = batch\n",
    "    preds = model(xb)\n",
    "    loss = F.cross_entropy(preds, yb)\n",
    "    tot_loss += loss.item()\n",
    "\n",
    "print(f\"Avg dev loss: {tot_loss / len(dev_dl)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize dimensions 0 and 1 of the embedding matrix C for all characters\n",
    "# vowels are clustered, especially aeio\n",
    "# .is totally separate\n",
    "# Model has learned these patterns via embedding\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color='white')\n",
    "plt.grid('minor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_size = 20\n",
    "hidden_neurons = 200\n",
    "batch_size = 16\n",
    "weight_decay = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=True, generator=g)\n",
    "dev_dl = DataLoader(dev_data, batch_size=batch_size, shuffle=True, generator=g)\n",
    "test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate param initialization\n",
    "C = torch.randn((len(letters) + 1, embedding_size), generator=g)\n",
    "# is num chars we picked per group\n",
    "W1 = torch.randn(3*embedding_size, hidden_neurons, generator=g)\n",
    "B1 = torch.randn(hidden_neurons, generator=g)\n",
    "W2 = torch.randn(hidden_neurons, len(letters) + 1, generator=g)\n",
    "B2 = torch.randn(len(letters) + 1, generator=g)\n",
    "parameters = [C, W1, B1, W2, B2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18167"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total model size\n",
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb: torch.Tensor):\n",
    "    emb = C[xb].view(-1, 3*embedding_size)\n",
    "    h = torch.tanh((emb @ W1) + B1)\n",
    "    return (h @ W2) + B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_b = []\n",
    "batches = []\n",
    "\n",
    "batch_i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    for batch in train_dl:\n",
    "        xb, yb = batch\n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(preds, yb)\n",
    "\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        loss.backward()\n",
    "\n",
    "        lr = 0.1\n",
    "        if i > 5 and i < 10:\n",
    "            lr = 0.01\n",
    "        if i >= 10 and i < 15:\n",
    "            lr = 0.001\n",
    "        if i >= 15:\n",
    "            lr = 0.0005\n",
    "        for p in parameters:\n",
    "            p.data -= lr * (p.grad + weight_decay * p.data)\n",
    "\n",
    "        losses_b.append(loss.log10().item())\n",
    "        batches.append(batch_i)\n",
    "        batch_i += 1\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.8800212144851685\n",
      "Avg dev loss: 2.0314954585499234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6a74e8ea10>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Train loss: {loss}\")\n",
    "\n",
    "tot_loss = 0\n",
    "for batch in dev_dl:\n",
    "    xb, yb = batch\n",
    "    preds = model(xb)\n",
    "    loss = F.cross_entropy(preds, yb)\n",
    "    tot_loss += loss.item()\n",
    "\n",
    "print(f\"Avg dev loss: {tot_loss / len(dev_dl)}\")\n",
    "\n",
    "plt.plot(batches, losses_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best dev loss:\n",
    "\n",
    "2.42\n",
    "embedding_size = 20\n",
    "hidden_neurons = 200\n",
    "batch_size = 16\n",
    "weight_decay = 0.01\n",
    "adding a weight decay made things a lot worse\n",
    "\n",
    "2.200\n",
    "embedding_size = 10\n",
    "hidden_neurons = 200\n",
    "batch_size = 64\n",
    "\n",
    "2.11\n",
    "embedding_size = 10\n",
    "hidden_neurons = 200\n",
    "batch_size = 16\n",
    "\n",
    "2.1022\n",
    "embedding_size = 20\n",
    "hidden_neurons = 200\n",
    "batch_size = 16\n",
    "\n",
    "2.03\n",
    "embedding_size = 20\n",
    "hidden_neurons = 200\n",
    "batch_size = 16\n",
    "weight_decay = 0.0001\n",
    "reducing weight decay produced a significant improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daysen\n",
      "dadomayslee\n",
      "daria\n",
      "day\n",
      "datiya\n",
      "daveli\n",
      "dairanie\n",
      "dae\n",
      "daxlandronah\n",
      "darietan\n",
      "dalla\n",
      "dana\n",
      "dar\n",
      "danthel\n",
      "daryanna\n",
      "daih\n",
      "dalayannah\n",
      "dagitte\n",
      "daig\n",
      "daw\n"
     ]
    }
   ],
   "source": [
    "words_to_gen = 20\n",
    "for wi in range(words_to_gen):\n",
    "    li = 0\n",
    "    next_letter = ''\n",
    "    genned_word = '.da'\n",
    "    while next_letter != '.' and len(genned_word) < 20:\n",
    "        prior_group = []\n",
    "        prior_group.append(stoi[genned_word[li]])\n",
    "        prior_group.append(stoi[genned_word[li+1]])\n",
    "        prior_group.append(stoi[genned_word[li+2]])\n",
    "\n",
    "        probs = F.softmax(model(torch.tensor(prior_group)), dim=1)\n",
    "        pred = torch.multinomial(probs, 1, replacement=True, generator=g).item()\n",
    "        next_letter = itos[int(pred)]\n",
    "\n",
    "        genned_word += next_letter\n",
    "        li += 1\n",
    "    print(genned_word.strip('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Param Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_size = 20\n",
    "hidden_neurons = 200\n",
    "batch_size = 16\n",
    "weight_decay = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=True, generator=g)\n",
    "dev_dl = DataLoader(dev_data, batch_size=batch_size, shuffle=True, generator=g)\n",
    "test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18367\n"
     ]
    }
   ],
   "source": [
    "# Separate param initialization\n",
    "C = torch.randn((len(letters) + 1, embedding_size), generator=g)\n",
    "# 3 is num chars we picked per group\n",
    "# kaiming init - avoid weights too high\n",
    "W1 = torch.randn(3*embedding_size, hidden_neurons, generator=g) * (5/3)/((3 * embedding_size)**0.5)\n",
    "# For layers followed by batch norm, no bias is needed\n",
    "# B1 = torch.randn(hidden_neurons, generator=g)\n",
    "# Reduce weights to avoid overconfident initial logits\n",
    "W2 = torch.randn(hidden_neurons, len(letters) + 1, generator=g) * 0.01\n",
    "B2 = torch.randn(len(letters) + 1, generator=g) * 0.01\n",
    "\n",
    "# BatchNorm Params\n",
    "bngain = torch.ones((1, hidden_neurons))\n",
    "bnbias = torch.zeros((1, hidden_neurons))\n",
    "bnmean_running = torch.zeros((1, hidden_neurons))\n",
    "bnstd_running = torch.ones((1, hidden_neurons))\n",
    "\n",
    "parameters = [C, W1, W2, B2, bngain, bnbias]\n",
    "# Total model size\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_b = []\n",
    "batches = []\n",
    "\n",
    "batch_i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    for batch in train_dl:\n",
    "        xb, yb = batch\n",
    "        \n",
    "        # Forward pass\n",
    "        # Split model\n",
    "        emb = C[xb] # embed characters to vectors\n",
    "        embcat = emb.view(-1, 3*embedding_size) # concat to match shapes\n",
    "        hpreact = (embcat @ W1) #+ B1 # hidden layer pre activation\n",
    "\n",
    "        # BatchNorm Layer\n",
    "        # ---------------\n",
    "        bnmeani = hpreact.mean(0, keepdim=True)\n",
    "        bnstdi = hpreact.std(0, keepdim=True)\n",
    "        hpreact = bngain * (hpreact - bnmeani) / bnstdi * bnbias\n",
    "        # keep a running mean/std so we don't have to do it at the end\n",
    "        # We need these in order to do a forward pass over a single sample\n",
    "        with torch.no_grad():\n",
    "            bnmean_running = 0.999 * bnmean_running + 0.001 * bnmeani\n",
    "            bnstd_running = 0.999 * bnstd_running + 0.001 * bnstdi\n",
    "        # ---------------\n",
    "\n",
    "        h = torch.tanh(hpreact) # hidden layer\n",
    "        preds = (h @ W2) + B2 # output layer\n",
    "\n",
    "        loss = F.cross_entropy(preds, yb)\n",
    "\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        loss.backward()\n",
    "\n",
    "        lr = 0.1\n",
    "        if i > 5 and i < 10:\n",
    "            lr = 0.01\n",
    "        if i >= 10 and i < 15:\n",
    "            lr = 0.001\n",
    "        if i >= 15:\n",
    "            lr = 0.0005\n",
    "        for p in parameters:\n",
    "            # p.data -= lr * (p.grad + weight_decay * p.data)\n",
    "            p.data -= lr * p.grad\n",
    "\n",
    "        losses_b.append(loss.log10().item())\n",
    "        batches.append(batch_i)\n",
    "        batch_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9270780086517334\n",
      "Avg dev loss: 3.700505769973145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2bc81ffc50>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Train loss: {loss}\")\n",
    "tot_loss = 0\n",
    "with torch.no_grad():\n",
    "  for batch in dev_dl:\n",
    "    xb, yb = batch\n",
    "    emb = C[xb] # embed characters to vectors\n",
    "    embcat = emb.view(-1, 3*embedding_size) # concat to match shapes\n",
    "    hpreact = (embcat @ W1) #+ B1 # hidden layer pre activation\n",
    "    hpreact = bngain * (hpreact - bnmean_running) / bnstd_running + bnbias\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    preds = (h @ W2) + B2 # output layer\n",
    "    loss = F.cross_entropy(preds, yb)\n",
    "    tot_loss += loss.item()\n",
    "\n",
    "print(f\"Avg dev loss: {tot_loss / len(dev_dl)}\")\n",
    "\n",
    "plt.plot(batches, losses_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
